{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75634d7",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc7367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from utils.utils_model import get_llama_3_8B\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f47be9",
   "metadata": {},
   "source": [
    "## Define utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hellaswag_jsonl(file_path):\n",
    "    \"\"\"Load HellaSwag data from local jsonl file\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "def load_interference_files(results_dir, n_files=10):\n",
    "    \"\"\"Load random interference result files\"\"\"\n",
    "    print(f\"Looking for interference files in: {results_dir}\")\n",
    "    \n",
    "    if not os.path.exists(results_dir):\n",
    "        print(f\"Error: Directory {results_dir} does not exist!\")\n",
    "        return []\n",
    "    \n",
    "    all_files = []\n",
    "    for file in os.listdir(results_dir):\n",
    "        if file.endswith('.json') and 'sentence' in file:\n",
    "            all_files.append(os.path.join(results_dir, file))\n",
    "    \n",
    "    print(f\"Found {len(all_files)} interference files\")\n",
    "    \n",
    "    if len(all_files) == 0:\n",
    "        print(\"Error: No interference files found!\")\n",
    "        return []\n",
    "    \n",
    "    if len(all_files) < n_files:\n",
    "        print(f\"Warning: Only found {len(all_files)} files, using all of them\")\n",
    "        selected_files = all_files\n",
    "    else:\n",
    "        selected_files = random.sample(all_files, n_files)\n",
    "    \n",
    "    interference_data = []\n",
    "    for file_path in selected_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                interference_data.append({\n",
    "                    'file_path': file_path,\n",
    "                    'data': data\n",
    "                })\n",
    "                print(f\"Successfully loaded: {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return interference_data\n",
    "\n",
    "def parse_interference_vectors(interference_info):\n",
    "    \"\"\"Parse all interference vectors from loaded files\"\"\"\n",
    "    vectors = []\n",
    "    \n",
    "    for interference_item in interference_info:\n",
    "        file_path = interference_item['file_path']\n",
    "        data = interference_item['data']\n",
    "        file_name = os.path.basename(file_path)\n",
    "        \n",
    "        # Parse count_increase vector\n",
    "        if 'count_increase' in data and data['count_increase'].get('success', False):\n",
    "            best_records = data['count_increase'].get('best_records', [])\n",
    "            if best_records:\n",
    "                record = best_records[0]  # Take the first record\n",
    "                hook_pos = record.get('hook_pos', [])\n",
    "                scale = record.get('scale', 1.0)\n",
    "                attack_vector = record.get('attack_vector', [])\n",
    "                \n",
    "                if hook_pos and attack_vector:\n",
    "                    # Parse hook_pos\n",
    "                    if len(hook_pos) == 2 and isinstance(hook_pos[0], int):\n",
    "                        layer_id = hook_pos[0]\n",
    "                        layer_type = hook_pos[1]\n",
    "                    elif len(hook_pos) == 1:\n",
    "                        layer_id = 0\n",
    "                        layer_type = hook_pos[0]\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate final interference vector\n",
    "                    final_vector = np.array(attack_vector) * scale\n",
    "                    \n",
    "                    vectors.append({\n",
    "                        'file_name': file_name,\n",
    "                        'vector_type': 'count_increase',\n",
    "                        'layer_id': layer_id,\n",
    "                        'layer_type': layer_type,\n",
    "                        'vector': final_vector,\n",
    "                        'scale': scale,\n",
    "                        'vector_norm': float(np.linalg.norm(final_vector))\n",
    "                    })\n",
    "        \n",
    "        # Parse prob_increase vector\n",
    "        if 'prob_increase' in data and data['prob_increase'].get('success', False):\n",
    "            record = data['prob_increase'].get('best_record', {})\n",
    "            if record:\n",
    "                hook_pos = record.get('hook_pos', [])\n",
    "                scale = record.get('scale', 1.0)\n",
    "                attack_vector = record.get('attack_vector', [])\n",
    "                \n",
    "                if hook_pos and attack_vector:\n",
    "                    # Parse hook_pos\n",
    "                    if len(hook_pos) == 2 and isinstance(hook_pos[0], int):\n",
    "                        layer_id = hook_pos[0]\n",
    "                        layer_type = hook_pos[1]\n",
    "                    elif len(hook_pos) == 1:\n",
    "                        layer_id = 0\n",
    "                        layer_type = hook_pos[0]\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate final interference vector\n",
    "                    final_vector = np.array(attack_vector) * scale\n",
    "                    \n",
    "                    vectors.append({\n",
    "                        'file_name': file_name,\n",
    "                        'vector_type': 'prob_increase',\n",
    "                        'layer_id': layer_id,\n",
    "                        'layer_type': layer_type,\n",
    "                        'vector': final_vector,\n",
    "                        'scale': scale,\n",
    "                        'vector_norm': float(np.linalg.norm(final_vector))\n",
    "                    })\n",
    "    \n",
    "    return vectors\n",
    "\n",
    "def register_interference_hook(model, vector_info, scale=1.0, interference_scale=0.25):\n",
    "    \"\"\"Register interference hook on model and return handle\"\"\"\n",
    "    layer_id = vector_info['layer_id']\n",
    "    layer_type = vector_info['layer_type']\n",
    "    vector = vector_info['vector']\n",
    "    \n",
    "    attack_vector_tensor = torch.tensor(vector, dtype=model.dtype).to(model.device)\n",
    "    \n",
    "    def attack_hook(module, input, output):\n",
    "        \"\"\"Attack hook function with scaling factor\"\"\"\n",
    "        if isinstance(output, tuple):\n",
    "            hidden_states = output[0]\n",
    "        else:\n",
    "            hidden_states = output\n",
    "        # Apply interference to all positions with scaling\n",
    "        hidden_states[0, :] += scale * attack_vector_tensor * interference_scale\n",
    "        return output\n",
    "    \n",
    "    # Register hook based on hook type\n",
    "    if layer_type == \"att\":\n",
    "        handle = model.model.layers[layer_id].self_attn.register_forward_hook(attack_hook)\n",
    "    elif layer_type == \"mlp\":\n",
    "        handle = model.model.layers[layer_id].mlp.register_forward_hook(attack_hook)\n",
    "    elif layer_type in [\"res\", \"res_post\"]:\n",
    "        handle = model.model.layers[layer_id].register_forward_hook(attack_hook)\n",
    "    elif layer_type == \"res_mid\":\n",
    "        handle = model.model.layers[layer_id].register_forward_hook(attack_hook)\n",
    "    else:\n",
    "        print(f\"Unknown hook type: {layer_type}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"  Registered hook at Layer {layer_id} {layer_type}\")\n",
    "    return handle\n",
    "\n",
    "def get_logprobs_for_choices(model, tokenizer, context, choices):\n",
    "    \"\"\"Calculate log probabilities for each choice\"\"\"\n",
    "    logprobs = []\n",
    "    \n",
    "    for choice in choices:\n",
    "        # Build complete text\n",
    "        full_text = context + \" \" + choice\n",
    "        \n",
    "        # Encode text\n",
    "        inputs = tokenizer(full_text, return_tensors=\"pt\").to(model.device)\n",
    "        context_inputs = tokenizer(context, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get model outputs\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits[0]  # [seq_len, vocab_size]\n",
    "            \n",
    "            # Calculate log probabilities\n",
    "            log_probs = torch.log_softmax(logits, dim=-1)\n",
    "            \n",
    "            # Only consider tokens from the choice part\n",
    "            context_len = context_inputs.input_ids.shape[1]\n",
    "            choice_token_ids = inputs.input_ids[0][context_len:]\n",
    "            \n",
    "            # Calculate cumulative log probability for the choice part\n",
    "            choice_logprob = 0.0\n",
    "            for i, token_id in enumerate(choice_token_ids):\n",
    "                if context_len + i < log_probs.shape[0]:\n",
    "                    choice_logprob += log_probs[context_len + i - 1, token_id].item()\n",
    "            \n",
    "            # Normalize by number of tokens\n",
    "            if len(choice_token_ids) > 0:\n",
    "                choice_logprob /= len(choice_token_ids)\n",
    "            \n",
    "            logprobs.append(choice_logprob)\n",
    "    \n",
    "    return logprobs\n",
    "\n",
    "def test_hellaswag_with_hook(model, tokenizer, test_samples, hook_handle=None, description=\"Testing\"):\n",
    "    \"\"\"Test HellaSwag accuracy with hook already registered (or no hook for baseline)\"\"\"\n",
    "    print(f\"{description}...\")\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for example in tqdm(test_samples, desc=description, leave=False):\n",
    "        try:\n",
    "            context = example[\"ctx\"]\n",
    "            choices = example[\"endings\"]\n",
    "            correct_answer = int(example[\"label\"])\n",
    "            \n",
    "            # Get probabilities (hook is already active if registered)\n",
    "            logprobs = get_logprobs_for_choices(model, tokenizer, context, choices)\n",
    "            predicted_answer = np.argmax(logprobs)\n",
    "            \n",
    "            if predicted_answer == correct_answer:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in test: {e}\")\n",
    "            total += 1\n",
    "            continue\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    print(f\"  {description} accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "    \n",
    "    return accuracy, correct, total\n",
    "\n",
    "def clean_up_memory():\n",
    "    \"\"\"Clean up GPU memory\"\"\"\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def load_specific_interference_vector(file_path, vector_type='count_increase'):\n",
    "    \"\"\"Load specific interference vector from a result file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get the specified vector type\n",
    "        if vector_type == 'count_increase' and 'count_increase' in data:\n",
    "            if data['count_increase'].get('success', False):\n",
    "                best_records = data['count_increase'].get('best_records', [])\n",
    "                if best_records:\n",
    "                    record = best_records[0]  # Take the first record\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "        elif vector_type == 'prob_increase' and 'prob_increase' in data:\n",
    "            if data['prob_increase'].get('success', False):\n",
    "                record = data['prob_increase'].get('best_record', {})\n",
    "                if not record:\n",
    "                    return None\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        hook_pos = record.get('hook_pos', [])\n",
    "        scale = record.get('scale', 1.0)\n",
    "        attack_vector = record.get('attack_vector', [])\n",
    "        \n",
    "        if not hook_pos or not attack_vector:\n",
    "            return None\n",
    "        \n",
    "        # Parse hook_pos\n",
    "        if len(hook_pos) == 2 and isinstance(hook_pos[0], int):\n",
    "            layer_id = hook_pos[0]\n",
    "            layer_type = hook_pos[1]\n",
    "        elif len(hook_pos) == 1:\n",
    "            layer_id = 0\n",
    "            layer_type = hook_pos[0]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        # Calculate final interference vector\n",
    "        final_vector = np.array(attack_vector) * scale\n",
    "        \n",
    "        # Get the sentence\n",
    "        sentence = data.get('sentence', 'Unknown sentence')\n",
    "        \n",
    "        vector_info = {\n",
    "            'file_name': os.path.basename(file_path),\n",
    "            'sentence': sentence,\n",
    "            'layer_id': layer_id,\n",
    "            'layer_type': layer_type,\n",
    "            'vector': final_vector,\n",
    "            'scale': scale,\n",
    "            'vector_type': vector_type,\n",
    "            'vector_norm': float(np.linalg.norm(final_vector))\n",
    "        }\n",
    "        \n",
    "        return vector_info\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_top_k_tokens(model, tokenizer, text, top_k=10):\n",
    "    \"\"\"Get top-k next token predictions\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get top-k tokens and their probabilities\n",
    "        top_probs, top_indices = torch.topk(probs, top_k)\n",
    "        \n",
    "        # Convert to float32 first, then to numpy to avoid bfloat16 issue\n",
    "        top_probs = top_probs.float().cpu().numpy()\n",
    "        top_indices = top_indices.cpu().numpy()\n",
    "        \n",
    "        results = []\n",
    "        for i, (prob, token_id) in enumerate(zip(top_probs, top_indices)):\n",
    "            token_str = tokenizer.decode([token_id])\n",
    "            results.append({\n",
    "                'rank': i + 1,\n",
    "                'token_id': int(token_id),\n",
    "                'token': token_str,\n",
    "                'probability': float(prob)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "def compare_top_tokens_before_after(model, tokenizer, sentence, vector_info, top_k=10):\n",
    "    \"\"\"Compare top-k tokens before and after applying interference vector\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Analyzing sentence: '{sentence}'\")\n",
    "    print(f\"File: {vector_info['file_name']}\")\n",
    "    print(f\"Vector: {vector_info['vector_type']} at Layer {vector_info['layer_id']} {vector_info['layer_type']}\")\n",
    "    print(f\"Vector norm: {vector_info['vector_norm']:.4f}\")\n",
    "    print(f\"Applied scaling: 1.0 * 0.25 = 0.25\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get baseline results (no interference)\n",
    "    baseline_results = get_top_k_tokens(model, tokenizer, sentence, top_k=top_k)\n",
    "    \n",
    "    # Register hook for interference\n",
    "    hook_handle = register_interference_hook(\n",
    "        model, vector_info, scale=1.0, interference_scale=0.25\n",
    "    )\n",
    "    \n",
    "    if hook_handle is None:\n",
    "        print(\"❌ Failed to register hook!\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Get results with interference\n",
    "        interference_results = get_top_k_tokens(model, tokenizer, sentence, top_k=top_k)\n",
    "        \n",
    "        # Print comparison table\n",
    "        print(f\"\\nTOP-{top_k} TOKEN COMPARISON:\")\n",
    "        print(f\"{'Rank':<4} {'Before Hook':<25} {'Prob':<12} {'After Hook':<25} {'Prob':<12} {'Change':<10}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for i in range(top_k):\n",
    "            baseline = baseline_results[i]\n",
    "            interference = interference_results[i]\n",
    "            \n",
    "            prob_change = interference['probability'] - baseline['probability']\n",
    "            change_indicator = \"↑\" if prob_change > 0 else \"↓\" if prob_change < 0 else \"=\"\n",
    "            \n",
    "            print(f\"{baseline['rank']:<4} {repr(baseline['token']):<25} {baseline['probability']:<12.6f} \"\n",
    "                  f\"{repr(interference['token']):<25} {interference['probability']:<12.6f} \"\n",
    "                  f\"{change_indicator} {prob_change:+.6f}\")\n",
    "        \n",
    "        # Analyze changes\n",
    "        print(f\"\\nCHANGE ANALYSIS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Check if top token changed\n",
    "        baseline_top = baseline_results[0]\n",
    "        interference_top = interference_results[0]\n",
    "        \n",
    "        if baseline_top['token_id'] != interference_top['token_id']:\n",
    "            print(f\"🔄 TOP TOKEN CHANGED:\")\n",
    "            print(f\"   Before Hook: {repr(baseline_top['token'])} (prob: {baseline_top['probability']:.6f})\")\n",
    "            print(f\"   After Hook:  {repr(interference_top['token'])} (prob: {interference_top['probability']:.6f})\")\n",
    "        else:\n",
    "            print(f\"✅ TOP TOKEN UNCHANGED: {repr(baseline_top['token'])}\")\n",
    "            prob_change = interference_top['probability'] - baseline_top['probability']\n",
    "            print(f\"   Probability change: {prob_change:+.6f}\")\n",
    "        \n",
    "        # Find tokens that appeared/disappeared in top-k\n",
    "        baseline_tokens = {r['token_id']: r for r in baseline_results}\n",
    "        interference_tokens = {r['token_id']: r for r in interference_results}\n",
    "        \n",
    "        new_tokens = set(interference_tokens.keys()) - set(baseline_tokens.keys())\n",
    "        lost_tokens = set(baseline_tokens.keys()) - set(interference_tokens.keys())\n",
    "        \n",
    "        if new_tokens:\n",
    "            print(f\"\\n📈 NEW TOKENS IN TOP-{top_k}:\")\n",
    "            for token_id in new_tokens:\n",
    "                token_info = interference_tokens[token_id]\n",
    "                print(f\"   Rank {token_info['rank']}: {repr(token_info['token'])} (prob: {token_info['probability']:.6f})\")\n",
    "        \n",
    "        if lost_tokens:\n",
    "            print(f\"\\n📉 TOKENS DROPPED FROM TOP-{top_k}:\")\n",
    "            for token_id in lost_tokens:\n",
    "                token_info = baseline_tokens[token_id]\n",
    "                print(f\"   Was rank {token_info['rank']}: {repr(token_info['token'])} (prob: {token_info['probability']:.6f})\")\n",
    "        \n",
    "        # Calculate overall distribution change\n",
    "        total_prob_change = sum(abs(interference_results[i]['probability'] - baseline_results[i]['probability']) \n",
    "                               for i in range(top_k))\n",
    "        \n",
    "        print(f\"\\n📊 OVERALL DISTRIBUTION METRICS:\")\n",
    "        print(f\"   Total absolute probability change in top-{top_k}: {total_prob_change:.6f}\")\n",
    "        print(f\"   Average absolute change per token: {total_prob_change/top_k:.6f}\")\n",
    "        print(f\"   New tokens in top-{top_k}: {len(new_tokens)}\")\n",
    "        print(f\"   Lost tokens from top-{top_k}: {len(lost_tokens)}\")\n",
    "        \n",
    "        return {\n",
    "            'baseline_results': baseline_results,\n",
    "            'interference_results': interference_results,\n",
    "            'top_token_changed': baseline_top['token_id'] != interference_top['token_id'],\n",
    "            'total_prob_change': total_prob_change,\n",
    "            'new_tokens': len(new_tokens),\n",
    "            'lost_tokens': len(lost_tokens)\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        # Remove hook\n",
    "        hook_handle.remove()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef553e",
   "metadata": {},
   "source": [
    "## Do baseline test on the raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da8f67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama 3.1-8B-Instruct model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5698d2a0f194d8793ea931948fd7985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HellaSwag data from ./dataset/hellaswag_val.jsonl...\n",
      "Loaded 10042 samples from HellaSwag\n",
      "Selected 500 random test samples\n",
      "\n",
      "==================================================\n",
      "BASELINE TESTING\n",
      "==================================================\n",
      "Baseline Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Baseline Test accuracy: 0.7720 (386/500)\n",
      "\n",
      "Baseline Results:\n",
      "  Accuracy: 0.7720 (77.20%)\n",
      "  Correct: 386 / 500\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "print(\"Loading Llama 3.1-8B-Instruct model...\")\n",
    "llama, tokenizer = get_llama_3_8B()\n",
    "\n",
    "# Load HellaSwag data\n",
    "jsonl_path = \"./dataset/hellaswag_val.jsonl\"\n",
    "print(f\"Loading HellaSwag data from {jsonl_path}...\")\n",
    "\n",
    "if not os.path.exists(jsonl_path):\n",
    "    print(f\"Error: {jsonl_path} does not exist!\")\n",
    "    raise FileNotFoundError(f\"{jsonl_path} not found\")\n",
    "\n",
    "all_data = load_hellaswag_jsonl(jsonl_path)\n",
    "print(f\"Loaded {len(all_data)} samples from HellaSwag\")\n",
    "\n",
    "# Randomly select test samples\n",
    "num_test_samples = 500  # Adjust this number as needed\n",
    "test_samples = random.sample(all_data, min(num_test_samples, len(all_data)))\n",
    "print(f\"Selected {len(test_samples)} random test samples\")\n",
    "\n",
    "# Test baseline accuracy (no hook)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE TESTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "baseline_accuracy, baseline_correct, baseline_total = test_hellaswag_with_hook(\n",
    "    llama, tokenizer, test_samples, hook_handle=None, description=\"Baseline Test\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBaseline Results:\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"  Correct: {baseline_correct} / {baseline_total}\")\n",
    "\n",
    "# Clean up memory after baseline test\n",
    "clean_up_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e82c78",
   "metadata": {},
   "source": [
    "## Test accuracy after intervention for each result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b657b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LOADING INTERFERENCE VECTORS\n",
      "==================================================\n",
      "Looking for interference files in: ./results/results_location\n",
      "Found 98 interference files\n",
      "Warning: Only found 98 files, using all of them\n",
      "Successfully loaded: location_sentence_52.json\n",
      "Successfully loaded: location_sentence_33.json\n",
      "Successfully loaded: location_sentence_31.json\n",
      "Successfully loaded: location_sentence_100.json\n",
      "Successfully loaded: location_sentence_59.json\n",
      "Successfully loaded: location_sentence_91.json\n",
      "Successfully loaded: location_sentence_53.json\n",
      "Successfully loaded: location_sentence_70.json\n",
      "Successfully loaded: location_sentence_62.json\n",
      "Successfully loaded: location_sentence_15.json\n",
      "Successfully loaded: location_sentence_7.json\n",
      "Successfully loaded: location_sentence_72.json\n",
      "Successfully loaded: location_sentence_27.json\n",
      "Successfully loaded: location_sentence_34.json\n",
      "Successfully loaded: location_sentence_30.json\n",
      "Successfully loaded: location_sentence_95.json\n",
      "Successfully loaded: location_sentence_60.json\n",
      "Successfully loaded: location_sentence_81.json\n",
      "Successfully loaded: location_sentence_47.json\n",
      "Successfully loaded: location_sentence_99.json\n",
      "Successfully loaded: location_sentence_69.json\n",
      "Successfully loaded: location_sentence_58.json\n",
      "Successfully loaded: location_sentence_6.json\n",
      "Successfully loaded: location_sentence_16.json\n",
      "Successfully loaded: location_sentence_84.json\n",
      "Successfully loaded: location_sentence_1.json\n",
      "Successfully loaded: location_sentence_44.json\n",
      "Successfully loaded: location_sentence_71.json\n",
      "Successfully loaded: location_sentence_88.json\n",
      "Successfully loaded: location_sentence_43.json\n",
      "Successfully loaded: location_sentence_46.json\n",
      "Successfully loaded: location_sentence_94.json\n",
      "Successfully loaded: location_sentence_40.json\n",
      "Successfully loaded: location_sentence_75.json\n",
      "Successfully loaded: location_sentence_98.json\n",
      "Successfully loaded: location_sentence_48.json\n",
      "Successfully loaded: location_sentence_97.json\n",
      "Successfully loaded: location_sentence_83.json\n",
      "Successfully loaded: location_sentence_57.json\n",
      "Successfully loaded: location_sentence_4.json\n",
      "Successfully loaded: location_sentence_49.json\n",
      "Successfully loaded: location_sentence_92.json\n",
      "Successfully loaded: location_sentence_10.json\n",
      "Successfully loaded: location_sentence_2.json\n",
      "Successfully loaded: location_sentence_50.json\n",
      "Successfully loaded: location_sentence_79.json\n",
      "Successfully loaded: location_sentence_42.json\n",
      "Successfully loaded: location_sentence_68.json\n",
      "Successfully loaded: location_sentence_38.json\n",
      "Successfully loaded: location_sentence_77.json\n",
      "Successfully loaded: location_sentence_9.json\n",
      "Successfully loaded: location_sentence_63.json\n",
      "Successfully loaded: location_sentence_23.json\n",
      "Successfully loaded: location_sentence_80.json\n",
      "Successfully loaded: location_sentence_93.json\n",
      "Successfully loaded: location_sentence_89.json\n",
      "Successfully loaded: location_sentence_37.json\n",
      "Successfully loaded: location_sentence_12.json\n",
      "Successfully loaded: location_sentence_19.json\n",
      "Successfully loaded: location_sentence_61.json\n",
      "Successfully loaded: location_sentence_96.json\n",
      "Successfully loaded: location_sentence_73.json\n",
      "Successfully loaded: location_sentence_36.json\n",
      "Successfully loaded: location_sentence_87.json\n",
      "Successfully loaded: location_sentence_56.json\n",
      "Successfully loaded: location_sentence_90.json\n",
      "Successfully loaded: location_sentence_32.json\n",
      "Successfully loaded: location_sentence_18.json\n",
      "Successfully loaded: location_sentence_67.json\n",
      "Successfully loaded: location_sentence_85.json\n",
      "Successfully loaded: location_sentence_35.json\n",
      "Successfully loaded: location_sentence_76.json\n",
      "Successfully loaded: location_sentence_3.json\n",
      "Successfully loaded: location_sentence_82.json\n",
      "Successfully loaded: location_sentence_41.json\n",
      "Successfully loaded: location_sentence_26.json\n",
      "Successfully loaded: location_sentence_54.json\n",
      "Successfully loaded: location_sentence_11.json\n",
      "Successfully loaded: location_sentence_21.json\n",
      "Successfully loaded: location_sentence_65.json\n",
      "Successfully loaded: location_sentence_86.json\n",
      "Successfully loaded: location_sentence_13.json\n",
      "Successfully loaded: location_sentence_17.json\n",
      "Successfully loaded: location_sentence_20.json\n",
      "Successfully loaded: location_sentence_55.json\n",
      "Successfully loaded: location_sentence_29.json\n",
      "Successfully loaded: location_sentence_25.json\n",
      "Successfully loaded: location_sentence_78.json\n",
      "Successfully loaded: location_sentence_45.json\n",
      "Successfully loaded: location_sentence_22.json\n",
      "Successfully loaded: location_sentence_39.json\n",
      "Successfully loaded: location_sentence_28.json\n",
      "Successfully loaded: location_sentence_14.json\n",
      "Successfully loaded: location_sentence_74.json\n",
      "Successfully loaded: location_sentence_51.json\n",
      "Successfully loaded: location_sentence_64.json\n",
      "Successfully loaded: location_sentence_66.json\n",
      "Successfully loaded: location_sentence_24.json\n",
      "Parsed 192 interference vectors\n",
      "\n",
      "==================================================\n",
      "INTERFERENCE TESTING\n",
      "==================================================\n",
      "\n",
      "--- Testing Vector 1/192 ---\n",
      "File: location_sentence_52.json\n",
      "Vector Type: count_increase\n",
      "Layer: 15 res\n",
      "Scale: 14\n",
      "Vector Norm: 14.0270\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_52.json\n",
      "\n",
      "--- Testing Vector 2/192 ---\n",
      "File: location_sentence_52.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 0 res\n",
      "Scale: -1.5\n",
      "Vector Norm: 1.5010\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_52.json\n",
      "\n",
      "--- Testing Vector 3/192 ---\n",
      "File: location_sentence_33.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: 3.5\n",
      "Vector Norm: 3.4977\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_33.json\n",
      "\n",
      "--- Testing Vector 4/192 ---\n",
      "File: location_sentence_33.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 14\n",
      "Vector Norm: 14.0109\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.6640 (332/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6640\n",
      "  Accuracy drop: 0.1080 (+10.80 percentage points)\n",
      "  Removed hook for location_sentence_33.json\n",
      "\n",
      "--- Testing Vector 5/192 ---\n",
      "File: location_sentence_31.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0379\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_31.json\n",
      "\n",
      "--- Testing Vector 6/192 ---\n",
      "File: location_sentence_31.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -10\n",
      "Vector Norm: 9.9865\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.6640 (332/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6640\n",
      "  Accuracy drop: 0.1080 (+10.80 percentage points)\n",
      "  Removed hook for location_sentence_31.json\n",
      "\n",
      "--- Testing Vector 7/192 ---\n",
      "File: location_sentence_100.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: -2\n",
      "Vector Norm: 1.9998\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_100.json\n",
      "\n",
      "--- Testing Vector 8/192 ---\n",
      "File: location_sentence_100.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: -4\n",
      "Vector Norm: 4.0079\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_100.json\n",
      "\n",
      "--- Testing Vector 9/192 ---\n",
      "File: location_sentence_59.json\n",
      "Vector Type: count_increase\n",
      "Layer: 11 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9807\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_59.json\n",
      "\n",
      "--- Testing Vector 10/192 ---\n",
      "File: location_sentence_59.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: 12\n",
      "Vector Norm: 12.0063\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_59.json\n",
      "\n",
      "--- Testing Vector 11/192 ---\n",
      "File: location_sentence_91.json\n",
      "Vector Type: count_increase\n",
      "Layer: 9 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9835\n",
      "  Registered hook at Layer 9 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_91.json\n",
      "\n",
      "--- Testing Vector 12/192 ---\n",
      "File: location_sentence_91.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: 4.5\n",
      "Vector Norm: 4.4929\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7780 (389/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7780\n",
      "  Accuracy drop: -0.0060 (-0.60 percentage points)\n",
      "  Removed hook for location_sentence_91.json\n",
      "\n",
      "--- Testing Vector 13/192 ---\n",
      "File: location_sentence_53.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: -8\n",
      "Vector Norm: 8.0149\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_53.json\n",
      "\n",
      "--- Testing Vector 14/192 ---\n",
      "File: location_sentence_53.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -8\n",
      "Vector Norm: 8.0149\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_53.json\n",
      "\n",
      "--- Testing Vector 15/192 ---\n",
      "File: location_sentence_70.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9796\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_70.json\n",
      "\n",
      "--- Testing Vector 16/192 ---\n",
      "File: location_sentence_70.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 10 res\n",
      "Scale: 17\n",
      "Vector Norm: 16.9514\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_70.json\n",
      "\n",
      "--- Testing Vector 17/192 ---\n",
      "File: location_sentence_62.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -4.5\n",
      "Vector Norm: 4.4930\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_62.json\n",
      "\n",
      "--- Testing Vector 18/192 ---\n",
      "File: location_sentence_62.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -4\n",
      "Vector Norm: 3.9938\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_62.json\n",
      "\n",
      "--- Testing Vector 19/192 ---\n",
      "File: location_sentence_15.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: -3.5\n",
      "Vector Norm: 3.5057\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_15.json\n",
      "\n",
      "--- Testing Vector 20/192 ---\n",
      "File: location_sentence_15.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0019\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7540 (377/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7540\n",
      "  Accuracy drop: 0.0180 (+1.80 percentage points)\n",
      "  Removed hook for location_sentence_15.json\n",
      "\n",
      "--- Testing Vector 21/192 ---\n",
      "File: location_sentence_7.json\n",
      "Vector Type: count_increase\n",
      "Layer: 12 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9593\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_7.json\n",
      "\n",
      "--- Testing Vector 22/192 ---\n",
      "File: location_sentence_7.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9926\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7340 (367/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7340\n",
      "  Accuracy drop: 0.0380 (+3.80 percentage points)\n",
      "  Removed hook for location_sentence_7.json\n",
      "\n",
      "--- Testing Vector 23/192 ---\n",
      "File: location_sentence_72.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: -2\n",
      "Vector Norm: 1.9961\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_72.json\n",
      "\n",
      "--- Testing Vector 24/192 ---\n",
      "File: location_sentence_72.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 14 res\n",
      "Scale: -20\n",
      "Vector Norm: 20.0369\n",
      "  Registered hook at Layer 14 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_72.json\n",
      "\n",
      "--- Testing Vector 25/192 ---\n",
      "File: location_sentence_27.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -5\n",
      "Vector Norm: 5.0115\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7820 (391/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7820\n",
      "  Accuracy drop: -0.0100 (-1.00 percentage points)\n",
      "  Removed hook for location_sentence_27.json\n",
      "\n",
      "--- Testing Vector 26/192 ---\n",
      "File: location_sentence_34.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: -10\n",
      "Vector Norm: 9.9921\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_34.json\n",
      "\n",
      "--- Testing Vector 27/192 ---\n",
      "File: location_sentence_34.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0071\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_34.json\n",
      "\n",
      "--- Testing Vector 28/192 ---\n",
      "File: location_sentence_30.json\n",
      "Vector Type: count_increase\n",
      "Layer: 12 res\n",
      "Scale: 10\n",
      "Vector Norm: 9.9982\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_30.json\n",
      "\n",
      "--- Testing Vector 29/192 ---\n",
      "File: location_sentence_30.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 14 res\n",
      "Scale: 12\n",
      "Vector Norm: 12.0175\n",
      "  Registered hook at Layer 14 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7560 (378/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7560\n",
      "  Accuracy drop: 0.0160 (+1.60 percentage points)\n",
      "  Removed hook for location_sentence_30.json\n",
      "\n",
      "--- Testing Vector 30/192 ---\n",
      "File: location_sentence_95.json\n",
      "Vector Type: count_increase\n",
      "Layer: 0 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.5017\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_95.json\n",
      "\n",
      "--- Testing Vector 31/192 ---\n",
      "File: location_sentence_95.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -20\n",
      "Vector Norm: 20.0486\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.5340 (267/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.5340\n",
      "  Accuracy drop: 0.2380 (+23.80 percentage points)\n",
      "  Removed hook for location_sentence_95.json\n",
      "\n",
      "--- Testing Vector 32/192 ---\n",
      "File: location_sentence_60.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -6.5\n",
      "Vector Norm: 6.4935\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7580 (379/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7580\n",
      "  Accuracy drop: 0.0140 (+1.40 percentage points)\n",
      "  Removed hook for location_sentence_60.json\n",
      "\n",
      "--- Testing Vector 33/192 ---\n",
      "File: location_sentence_60.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -5.5\n",
      "Vector Norm: 5.4945\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_60.json\n",
      "\n",
      "--- Testing Vector 34/192 ---\n",
      "File: location_sentence_81.json\n",
      "Vector Type: count_increase\n",
      "Layer: 12 res\n",
      "Scale: 14\n",
      "Vector Norm: 14.0407\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_81.json\n",
      "\n",
      "--- Testing Vector 35/192 ---\n",
      "File: location_sentence_81.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -20\n",
      "Vector Norm: 19.9398\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7000 (350/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7000\n",
      "  Accuracy drop: 0.0720 (+7.20 percentage points)\n",
      "  Removed hook for location_sentence_81.json\n",
      "\n",
      "--- Testing Vector 36/192 ---\n",
      "File: location_sentence_47.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: 1\n",
      "Vector Norm: 0.9995\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_47.json\n",
      "\n",
      "--- Testing Vector 37/192 ---\n",
      "File: location_sentence_47.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9634\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7060 (353/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7060\n",
      "  Accuracy drop: 0.0660 (+6.60 percentage points)\n",
      "  Removed hook for location_sentence_47.json\n",
      "\n",
      "--- Testing Vector 38/192 ---\n",
      "File: location_sentence_99.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.4951\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_99.json\n",
      "\n",
      "--- Testing Vector 39/192 ---\n",
      "File: location_sentence_99.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: -8\n",
      "Vector Norm: 7.9855\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7780 (389/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7780\n",
      "  Accuracy drop: -0.0060 (-0.60 percentage points)\n",
      "  Removed hook for location_sentence_99.json\n",
      "\n",
      "--- Testing Vector 40/192 ---\n",
      "File: location_sentence_69.json\n",
      "Vector Type: count_increase\n",
      "Layer: 15 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0064\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_69.json\n",
      "\n",
      "--- Testing Vector 41/192 ---\n",
      "File: location_sentence_69.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 15 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0078\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_69.json\n",
      "\n",
      "--- Testing Vector 42/192 ---\n",
      "File: location_sentence_58.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0120\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.6920 (346/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6920\n",
      "  Accuracy drop: 0.0800 (+8.00 percentage points)\n",
      "  Removed hook for location_sentence_58.json\n",
      "\n",
      "--- Testing Vector 43/192 ---\n",
      "File: location_sentence_58.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.4992\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_58.json\n",
      "\n",
      "--- Testing Vector 44/192 ---\n",
      "File: location_sentence_6.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -4.5\n",
      "Vector Norm: 4.5078\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_6.json\n",
      "\n",
      "--- Testing Vector 45/192 ---\n",
      "File: location_sentence_6.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -6\n",
      "Vector Norm: 5.9877\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_6.json\n",
      "\n",
      "--- Testing Vector 46/192 ---\n",
      "File: location_sentence_16.json\n",
      "Vector Type: count_increase\n",
      "Layer: 11 res\n",
      "Scale: 17\n",
      "Vector Norm: 16.9872\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7420 (371/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7420\n",
      "  Accuracy drop: 0.0300 (+3.00 percentage points)\n",
      "  Removed hook for location_sentence_16.json\n",
      "\n",
      "--- Testing Vector 47/192 ---\n",
      "File: location_sentence_16.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9657\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7380 (369/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7380\n",
      "  Accuracy drop: 0.0340 (+3.40 percentage points)\n",
      "  Removed hook for location_sentence_16.json\n",
      "\n",
      "--- Testing Vector 48/192 ---\n",
      "File: location_sentence_84.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0254\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7340 (367/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7340\n",
      "  Accuracy drop: 0.0380 (+3.80 percentage points)\n",
      "  Removed hook for location_sentence_84.json\n",
      "\n",
      "--- Testing Vector 49/192 ---\n",
      "File: location_sentence_84.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0254\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7340 (367/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7340\n",
      "  Accuracy drop: 0.0380 (+3.80 percentage points)\n",
      "  Removed hook for location_sentence_84.json\n",
      "\n",
      "--- Testing Vector 50/192 ---\n",
      "File: location_sentence_1.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: 10\n",
      "Vector Norm: 10.0087\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_1.json\n",
      "\n",
      "--- Testing Vector 51/192 ---\n",
      "File: location_sentence_1.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9826\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.3400 (170/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.3400\n",
      "  Accuracy drop: 0.4320 (+43.20 percentage points)\n",
      "  Removed hook for location_sentence_1.json\n",
      "\n",
      "--- Testing Vector 52/192 ---\n",
      "File: location_sentence_44.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: 6.5\n",
      "Vector Norm: 6.4928\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_44.json\n",
      "\n",
      "--- Testing Vector 53/192 ---\n",
      "File: location_sentence_44.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 11 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9647\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7580 (379/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7580\n",
      "  Accuracy drop: 0.0140 (+1.40 percentage points)\n",
      "  Removed hook for location_sentence_44.json\n",
      "\n",
      "--- Testing Vector 54/192 ---\n",
      "File: location_sentence_71.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: 10\n",
      "Vector Norm: 9.9726\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_71.json\n",
      "\n",
      "--- Testing Vector 55/192 ---\n",
      "File: location_sentence_88.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: -2\n",
      "Vector Norm: 2.0019\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7820 (391/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7820\n",
      "  Accuracy drop: -0.0100 (-1.00 percentage points)\n",
      "  Removed hook for location_sentence_88.json\n",
      "\n",
      "--- Testing Vector 56/192 ---\n",
      "File: location_sentence_88.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: -5\n",
      "Vector Norm: 5.0115\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_88.json\n",
      "\n",
      "--- Testing Vector 57/192 ---\n",
      "File: location_sentence_43.json\n",
      "Vector Type: count_increase\n",
      "Layer: 10 res\n",
      "Scale: -17\n",
      "Vector Norm: 17.0385\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7460 (373/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7460\n",
      "  Accuracy drop: 0.0260 (+2.60 percentage points)\n",
      "  Removed hook for location_sentence_43.json\n",
      "\n",
      "--- Testing Vector 58/192 ---\n",
      "File: location_sentence_43.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: -4\n",
      "Vector Norm: 3.9975\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_43.json\n",
      "\n",
      "--- Testing Vector 59/192 ---\n",
      "File: location_sentence_46.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -2.5\n",
      "Vector Norm: 2.4974\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_46.json\n",
      "\n",
      "--- Testing Vector 60/192 ---\n",
      "File: location_sentence_46.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 1 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.4982\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_46.json\n",
      "\n",
      "--- Testing Vector 61/192 ---\n",
      "File: location_sentence_94.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.4985\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_94.json\n",
      "\n",
      "--- Testing Vector 62/192 ---\n",
      "File: location_sentence_94.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: 3\n",
      "Vector Norm: 2.9972\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_94.json\n",
      "\n",
      "--- Testing Vector 63/192 ---\n",
      "File: location_sentence_40.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: -8\n",
      "Vector Norm: 7.9975\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_40.json\n",
      "\n",
      "--- Testing Vector 64/192 ---\n",
      "File: location_sentence_40.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0046\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7820 (391/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7820\n",
      "  Accuracy drop: -0.0100 (-1.00 percentage points)\n",
      "  Removed hook for location_sentence_40.json\n",
      "\n",
      "--- Testing Vector 65/192 ---\n",
      "File: location_sentence_75.json\n",
      "Vector Type: count_increase\n",
      "Layer: 0 res\n",
      "Scale: -1\n",
      "Vector Norm: 1.0016\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_75.json\n",
      "\n",
      "--- Testing Vector 66/192 ---\n",
      "File: location_sentence_75.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9963\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7280 (364/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7280\n",
      "  Accuracy drop: 0.0440 (+4.40 percentage points)\n",
      "  Removed hook for location_sentence_75.json\n",
      "\n",
      "--- Testing Vector 67/192 ---\n",
      "File: location_sentence_98.json\n",
      "Vector Type: count_increase\n",
      "Layer: 12 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0198\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_98.json\n",
      "\n",
      "--- Testing Vector 68/192 ---\n",
      "File: location_sentence_98.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: 10\n",
      "Vector Norm: 10.0034\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.6940 (347/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6940\n",
      "  Accuracy drop: 0.0780 (+7.80 percentage points)\n",
      "  Removed hook for location_sentence_98.json\n",
      "\n",
      "--- Testing Vector 69/192 ---\n",
      "File: location_sentence_48.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.4955\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_48.json\n",
      "\n",
      "--- Testing Vector 70/192 ---\n",
      "File: location_sentence_48.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 1 res\n",
      "Scale: 6\n",
      "Vector Norm: 5.9912\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.3900 (195/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.3900\n",
      "  Accuracy drop: 0.3820 (+38.20 percentage points)\n",
      "  Removed hook for location_sentence_48.json\n",
      "\n",
      "--- Testing Vector 71/192 ---\n",
      "File: location_sentence_97.json\n",
      "Vector Type: count_increase\n",
      "Layer: 5 res\n",
      "Scale: 7.5\n",
      "Vector Norm: 7.4902\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_97.json\n",
      "\n",
      "--- Testing Vector 72/192 ---\n",
      "File: location_sentence_97.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: 8\n",
      "Vector Norm: 8.0053\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_97.json\n",
      "\n",
      "--- Testing Vector 73/192 ---\n",
      "File: location_sentence_83.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0231\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7500 (375/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7500\n",
      "  Accuracy drop: 0.0220 (+2.20 percentage points)\n",
      "  Removed hook for location_sentence_83.json\n",
      "\n",
      "--- Testing Vector 74/192 ---\n",
      "File: location_sentence_83.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0271\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7580 (379/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7580\n",
      "  Accuracy drop: 0.0140 (+1.40 percentage points)\n",
      "  Removed hook for location_sentence_83.json\n",
      "\n",
      "--- Testing Vector 75/192 ---\n",
      "File: location_sentence_57.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: 4.5\n",
      "Vector Norm: 4.5071\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_57.json\n",
      "\n",
      "--- Testing Vector 76/192 ---\n",
      "File: location_sentence_57.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 10 res\n",
      "Scale: -20\n",
      "Vector Norm: 20.0116\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7440 (372/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7440\n",
      "  Accuracy drop: 0.0280 (+2.80 percentage points)\n",
      "  Removed hook for location_sentence_57.json\n",
      "\n",
      "--- Testing Vector 77/192 ---\n",
      "File: location_sentence_4.json\n",
      "Vector Type: count_increase\n",
      "Layer: 11 res\n",
      "Scale: 10\n",
      "Vector Norm: 10.0266\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_4.json\n",
      "\n",
      "--- Testing Vector 78/192 ---\n",
      "File: location_sentence_4.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0189\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7240 (362/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7240\n",
      "  Accuracy drop: 0.0480 (+4.80 percentage points)\n",
      "  Removed hook for location_sentence_4.json\n",
      "\n",
      "--- Testing Vector 79/192 ---\n",
      "File: location_sentence_49.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: 3.5\n",
      "Vector Norm: 3.5111\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_49.json\n",
      "\n",
      "--- Testing Vector 80/192 ---\n",
      "File: location_sentence_49.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0207\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_49.json\n",
      "\n",
      "--- Testing Vector 81/192 ---\n",
      "File: location_sentence_92.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -4.5\n",
      "Vector Norm: 4.5073\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_92.json\n",
      "\n",
      "--- Testing Vector 82/192 ---\n",
      "File: location_sentence_92.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0181\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_92.json\n",
      "\n",
      "--- Testing Vector 83/192 ---\n",
      "File: location_sentence_10.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9469\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.6380 (319/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6380\n",
      "  Accuracy drop: 0.1340 (+13.40 percentage points)\n",
      "  Removed hook for location_sentence_10.json\n",
      "\n",
      "--- Testing Vector 84/192 ---\n",
      "File: location_sentence_10.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -20\n",
      "Vector Norm: 19.9375\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.5700 (285/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.5700\n",
      "  Accuracy drop: 0.2020 (+20.20 percentage points)\n",
      "  Removed hook for location_sentence_10.json\n",
      "\n",
      "--- Testing Vector 85/192 ---\n",
      "File: location_sentence_2.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: 3\n",
      "Vector Norm: 2.9985\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_2.json\n",
      "\n",
      "--- Testing Vector 86/192 ---\n",
      "File: location_sentence_2.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9992\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7500 (375/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7500\n",
      "  Accuracy drop: 0.0220 (+2.20 percentage points)\n",
      "  Removed hook for location_sentence_2.json\n",
      "\n",
      "--- Testing Vector 87/192 ---\n",
      "File: location_sentence_50.json\n",
      "Vector Type: count_increase\n",
      "Layer: 15 res\n",
      "Scale: -20\n",
      "Vector Norm: 19.9624\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_50.json\n",
      "\n",
      "--- Testing Vector 88/192 ---\n",
      "File: location_sentence_50.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 13 res\n",
      "Scale: 20\n",
      "Vector Norm: 19.9752\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_50.json\n",
      "\n",
      "--- Testing Vector 89/192 ---\n",
      "File: location_sentence_79.json\n",
      "Vector Type: count_increase\n",
      "Layer: 9 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0309\n",
      "  Registered hook at Layer 9 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_79.json\n",
      "\n",
      "--- Testing Vector 90/192 ---\n",
      "File: location_sentence_79.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: 7\n",
      "Vector Norm: 7.0197\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7800 (390/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7800\n",
      "  Accuracy drop: -0.0080 (-0.80 percentage points)\n",
      "  Removed hook for location_sentence_79.json\n",
      "\n",
      "--- Testing Vector 91/192 ---\n",
      "File: location_sentence_42.json\n",
      "Vector Type: count_increase\n",
      "Layer: 11 res\n",
      "Scale: 7.5\n",
      "Vector Norm: 7.5137\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_42.json\n",
      "\n",
      "--- Testing Vector 92/192 ---\n",
      "File: location_sentence_42.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -3.5\n",
      "Vector Norm: 3.4930\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_42.json\n",
      "\n",
      "--- Testing Vector 93/192 ---\n",
      "File: location_sentence_68.json\n",
      "Vector Type: count_increase\n",
      "Layer: 15 res\n",
      "Scale: 12\n",
      "Vector Norm: 11.9935\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_68.json\n",
      "\n",
      "--- Testing Vector 94/192 ---\n",
      "File: location_sentence_68.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 14 res\n",
      "Scale: 20\n",
      "Vector Norm: 20.0289\n",
      "  Registered hook at Layer 14 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7500 (375/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7500\n",
      "  Accuracy drop: 0.0220 (+2.20 percentage points)\n",
      "  Removed hook for location_sentence_68.json\n",
      "\n",
      "--- Testing Vector 95/192 ---\n",
      "File: location_sentence_38.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: 2\n",
      "Vector Norm: 2.0015\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_38.json\n",
      "\n",
      "--- Testing Vector 96/192 ---\n",
      "File: location_sentence_38.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 0 res\n",
      "Scale: -1.5\n",
      "Vector Norm: 1.5033\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_38.json\n",
      "\n",
      "--- Testing Vector 97/192 ---\n",
      "File: location_sentence_77.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: 5\n",
      "Vector Norm: 5.0022\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_77.json\n",
      "\n",
      "--- Testing Vector 98/192 ---\n",
      "File: location_sentence_77.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: 8\n",
      "Vector Norm: 8.0141\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_77.json\n",
      "\n",
      "--- Testing Vector 99/192 ---\n",
      "File: location_sentence_9.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: 5\n",
      "Vector Norm: 5.0027\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_9.json\n",
      "\n",
      "--- Testing Vector 100/192 ---\n",
      "File: location_sentence_9.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 5\n",
      "Vector Norm: 5.0027\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_9.json\n",
      "\n",
      "--- Testing Vector 101/192 ---\n",
      "File: location_sentence_63.json\n",
      "Vector Type: count_increase\n",
      "Layer: 0 res\n",
      "Scale: -1.5\n",
      "Vector Norm: 1.4991\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_63.json\n",
      "\n",
      "--- Testing Vector 102/192 ---\n",
      "File: location_sentence_63.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: -7.5\n",
      "Vector Norm: 7.4814\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_63.json\n",
      "\n",
      "--- Testing Vector 103/192 ---\n",
      "File: location_sentence_23.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: -2\n",
      "Vector Norm: 1.9993\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_23.json\n",
      "\n",
      "--- Testing Vector 104/192 ---\n",
      "File: location_sentence_23.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0115\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_23.json\n",
      "\n",
      "--- Testing Vector 105/192 ---\n",
      "File: location_sentence_80.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -3.5\n",
      "Vector Norm: 3.4965\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_80.json\n",
      "\n",
      "--- Testing Vector 106/192 ---\n",
      "File: location_sentence_80.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 3.5\n",
      "Vector Norm: 3.4966\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_80.json\n",
      "\n",
      "--- Testing Vector 107/192 ---\n",
      "File: location_sentence_93.json\n",
      "Vector Type: count_increase\n",
      "Layer: 11 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0153\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_93.json\n",
      "\n",
      "--- Testing Vector 108/192 ---\n",
      "File: location_sentence_93.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: 14\n",
      "Vector Norm: 14.0318\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_93.json\n",
      "\n",
      "--- Testing Vector 109/192 ---\n",
      "File: location_sentence_89.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: 12\n",
      "Vector Norm: 11.9828\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_89.json\n",
      "\n",
      "--- Testing Vector 110/192 ---\n",
      "File: location_sentence_89.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: 8\n",
      "Vector Norm: 8.0125\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_89.json\n",
      "\n",
      "--- Testing Vector 111/192 ---\n",
      "File: location_sentence_37.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9706\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.3700 (185/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.3700\n",
      "  Accuracy drop: 0.4020 (+40.20 percentage points)\n",
      "  Removed hook for location_sentence_37.json\n",
      "\n",
      "--- Testing Vector 112/192 ---\n",
      "File: location_sentence_37.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0132\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7220 (361/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7220\n",
      "  Accuracy drop: 0.0500 (+5.00 percentage points)\n",
      "  Removed hook for location_sentence_37.json\n",
      "\n",
      "--- Testing Vector 113/192 ---\n",
      "File: location_sentence_12.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: 3\n",
      "Vector Norm: 2.9972\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_12.json\n",
      "\n",
      "--- Testing Vector 114/192 ---\n",
      "File: location_sentence_12.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: -7.5\n",
      "Vector Norm: 7.5009\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_12.json\n",
      "\n",
      "--- Testing Vector 115/192 ---\n",
      "File: location_sentence_19.json\n",
      "Vector Type: count_increase\n",
      "Layer: 6 res\n",
      "Scale: 10\n",
      "Vector Norm: 9.9873\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_19.json\n",
      "\n",
      "--- Testing Vector 116/192 ---\n",
      "File: location_sentence_19.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: -8\n",
      "Vector Norm: 7.9921\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7580 (379/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7580\n",
      "  Accuracy drop: 0.0140 (+1.40 percentage points)\n",
      "  Removed hook for location_sentence_19.json\n",
      "\n",
      "--- Testing Vector 117/192 ---\n",
      "File: location_sentence_61.json\n",
      "Vector Type: count_increase\n",
      "Layer: 6 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0349\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7540 (377/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7540\n",
      "  Accuracy drop: 0.0180 (+1.80 percentage points)\n",
      "  Removed hook for location_sentence_61.json\n",
      "\n",
      "--- Testing Vector 118/192 ---\n",
      "File: location_sentence_61.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0112\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7560 (378/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7560\n",
      "  Accuracy drop: 0.0160 (+1.60 percentage points)\n",
      "  Removed hook for location_sentence_61.json\n",
      "\n",
      "--- Testing Vector 119/192 ---\n",
      "File: location_sentence_96.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: -3.5\n",
      "Vector Norm: 3.4911\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_96.json\n",
      "\n",
      "--- Testing Vector 120/192 ---\n",
      "File: location_sentence_96.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 1 res\n",
      "Scale: 3.5\n",
      "Vector Norm: 3.4921\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7460 (373/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7460\n",
      "  Accuracy drop: 0.0260 (+2.60 percentage points)\n",
      "  Removed hook for location_sentence_96.json\n",
      "\n",
      "--- Testing Vector 121/192 ---\n",
      "File: location_sentence_73.json\n",
      "Vector Type: count_increase\n",
      "Layer: 10 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9789\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_73.json\n",
      "\n",
      "--- Testing Vector 122/192 ---\n",
      "File: location_sentence_73.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0002\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7540 (377/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7540\n",
      "  Accuracy drop: 0.0180 (+1.80 percentage points)\n",
      "  Removed hook for location_sentence_73.json\n",
      "\n",
      "--- Testing Vector 123/192 ---\n",
      "File: location_sentence_36.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9943\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_36.json\n",
      "\n",
      "--- Testing Vector 124/192 ---\n",
      "File: location_sentence_36.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 15 res\n",
      "Scale: -17\n",
      "Vector Norm: 17.0160\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_36.json\n",
      "\n",
      "--- Testing Vector 125/192 ---\n",
      "File: location_sentence_87.json\n",
      "Vector Type: count_increase\n",
      "Layer: 14 res\n",
      "Scale: -17\n",
      "Vector Norm: 17.0102\n",
      "  Registered hook at Layer 14 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7500 (375/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7500\n",
      "  Accuracy drop: 0.0220 (+2.20 percentage points)\n",
      "  Removed hook for location_sentence_87.json\n",
      "\n",
      "--- Testing Vector 126/192 ---\n",
      "File: location_sentence_87.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 5.5\n",
      "Vector Norm: 5.4836\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_87.json\n",
      "\n",
      "--- Testing Vector 127/192 ---\n",
      "File: location_sentence_56.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: 6.5\n",
      "Vector Norm: 6.5052\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_56.json\n",
      "\n",
      "--- Testing Vector 128/192 ---\n",
      "File: location_sentence_56.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0182\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7580 (379/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7580\n",
      "  Accuracy drop: 0.0140 (+1.40 percentage points)\n",
      "  Removed hook for location_sentence_56.json\n",
      "\n",
      "--- Testing Vector 129/192 ---\n",
      "File: location_sentence_90.json\n",
      "Vector Type: count_increase\n",
      "Layer: 12 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9695\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_90.json\n",
      "\n",
      "--- Testing Vector 130/192 ---\n",
      "File: location_sentence_90.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: 17\n",
      "Vector Norm: 16.9630\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_90.json\n",
      "\n",
      "--- Testing Vector 131/192 ---\n",
      "File: location_sentence_32.json\n",
      "Vector Type: count_increase\n",
      "Layer: 10 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0152\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_32.json\n",
      "\n",
      "--- Testing Vector 132/192 ---\n",
      "File: location_sentence_32.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 10 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0152\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_32.json\n",
      "\n",
      "--- Testing Vector 133/192 ---\n",
      "File: location_sentence_18.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9902\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.4720 (236/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.4720\n",
      "  Accuracy drop: 0.3000 (+30.00 percentage points)\n",
      "  Removed hook for location_sentence_18.json\n",
      "\n",
      "--- Testing Vector 134/192 ---\n",
      "File: location_sentence_18.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9902\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.4720 (236/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.4720\n",
      "  Accuracy drop: 0.3000 (+30.00 percentage points)\n",
      "  Removed hook for location_sentence_18.json\n",
      "\n",
      "--- Testing Vector 135/192 ---\n",
      "File: location_sentence_67.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9962\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_67.json\n",
      "\n",
      "--- Testing Vector 136/192 ---\n",
      "File: location_sentence_67.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 1 res\n",
      "Scale: -2.5\n",
      "Vector Norm: 2.4988\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_67.json\n",
      "\n",
      "--- Testing Vector 137/192 ---\n",
      "File: location_sentence_85.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: 2.5\n",
      "Vector Norm: 2.5013\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_85.json\n",
      "\n",
      "--- Testing Vector 138/192 ---\n",
      "File: location_sentence_85.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: 2.5\n",
      "Vector Norm: 2.5013\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_85.json\n",
      "\n",
      "--- Testing Vector 139/192 ---\n",
      "File: location_sentence_35.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.5003\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_35.json\n",
      "\n",
      "--- Testing Vector 140/192 ---\n",
      "File: location_sentence_35.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 5 res\n",
      "Scale: 7\n",
      "Vector Norm: 7.0103\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_35.json\n",
      "\n",
      "--- Testing Vector 141/192 ---\n",
      "File: location_sentence_76.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: -2\n",
      "Vector Norm: 1.9990\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_76.json\n",
      "\n",
      "--- Testing Vector 142/192 ---\n",
      "File: location_sentence_76.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0222\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_76.json\n",
      "\n",
      "--- Testing Vector 143/192 ---\n",
      "File: location_sentence_3.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9905\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7480 (374/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7480\n",
      "  Accuracy drop: 0.0240 (+2.40 percentage points)\n",
      "  Removed hook for location_sentence_3.json\n",
      "\n",
      "--- Testing Vector 144/192 ---\n",
      "File: location_sentence_3.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -6.5\n",
      "Vector Norm: 6.5261\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_3.json\n",
      "\n",
      "--- Testing Vector 145/192 ---\n",
      "File: location_sentence_82.json\n",
      "Vector Type: count_increase\n",
      "Layer: 9 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0223\n",
      "  Registered hook at Layer 9 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_82.json\n",
      "\n",
      "--- Testing Vector 146/192 ---\n",
      "File: location_sentence_82.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 14 res\n",
      "Scale: 20\n",
      "Vector Norm: 19.9934\n",
      "  Registered hook at Layer 14 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7540 (377/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7540\n",
      "  Accuracy drop: 0.0180 (+1.80 percentage points)\n",
      "  Removed hook for location_sentence_82.json\n",
      "\n",
      "--- Testing Vector 147/192 ---\n",
      "File: location_sentence_41.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 15 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9920\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_41.json\n",
      "\n",
      "--- Testing Vector 148/192 ---\n",
      "File: location_sentence_26.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9854\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_26.json\n",
      "\n",
      "--- Testing Vector 149/192 ---\n",
      "File: location_sentence_26.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -17\n",
      "Vector Norm: 16.9648\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7320 (366/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7320\n",
      "  Accuracy drop: 0.0400 (+4.00 percentage points)\n",
      "  Removed hook for location_sentence_26.json\n",
      "\n",
      "--- Testing Vector 150/192 ---\n",
      "File: location_sentence_54.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9815\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_54.json\n",
      "\n",
      "--- Testing Vector 151/192 ---\n",
      "File: location_sentence_54.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 0 res\n",
      "Scale: 2\n",
      "Vector Norm: 2.0012\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_54.json\n",
      "\n",
      "--- Testing Vector 152/192 ---\n",
      "File: location_sentence_11.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9760\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_11.json\n",
      "\n",
      "--- Testing Vector 153/192 ---\n",
      "File: location_sentence_11.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 5\n",
      "Vector Norm: 4.9983\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_11.json\n",
      "\n",
      "--- Testing Vector 154/192 ---\n",
      "File: location_sentence_21.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: 10\n",
      "Vector Norm: 9.9677\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7640 (382/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7640\n",
      "  Accuracy drop: 0.0080 (+0.80 percentage points)\n",
      "  Removed hook for location_sentence_21.json\n",
      "\n",
      "--- Testing Vector 155/192 ---\n",
      "File: location_sentence_21.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 11 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0142\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7480 (374/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7480\n",
      "  Accuracy drop: 0.0240 (+2.40 percentage points)\n",
      "  Removed hook for location_sentence_21.json\n",
      "\n",
      "--- Testing Vector 156/192 ---\n",
      "File: location_sentence_65.json\n",
      "Vector Type: count_increase\n",
      "Layer: 6 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0065\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7560 (378/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7560\n",
      "  Accuracy drop: 0.0160 (+1.60 percentage points)\n",
      "  Removed hook for location_sentence_65.json\n",
      "\n",
      "--- Testing Vector 157/192 ---\n",
      "File: location_sentence_65.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 1 res\n",
      "Scale: 1.5\n",
      "Vector Norm: 1.5000\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_65.json\n",
      "\n",
      "--- Testing Vector 158/192 ---\n",
      "File: location_sentence_86.json\n",
      "Vector Type: count_increase\n",
      "Layer: 10 res\n",
      "Scale: 10\n",
      "Vector Norm: 10.0008\n",
      "  Registered hook at Layer 10 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_86.json\n",
      "\n",
      "--- Testing Vector 159/192 ---\n",
      "File: location_sentence_86.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 11 res\n",
      "Scale: 10\n",
      "Vector Norm: 9.9925\n",
      "  Registered hook at Layer 11 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_86.json\n",
      "\n",
      "--- Testing Vector 160/192 ---\n",
      "File: location_sentence_13.json\n",
      "Vector Type: count_increase\n",
      "Layer: 15 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0127\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_13.json\n",
      "\n",
      "--- Testing Vector 161/192 ---\n",
      "File: location_sentence_13.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0099\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.4100 (205/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.4100\n",
      "  Accuracy drop: 0.3620 (+36.20 percentage points)\n",
      "  Removed hook for location_sentence_13.json\n",
      "\n",
      "--- Testing Vector 162/192 ---\n",
      "File: location_sentence_17.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: 4.5\n",
      "Vector Norm: 4.5106\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_17.json\n",
      "\n",
      "--- Testing Vector 163/192 ---\n",
      "File: location_sentence_17.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 2 res\n",
      "Scale: 3\n",
      "Vector Norm: 2.9956\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_17.json\n",
      "\n",
      "--- Testing Vector 164/192 ---\n",
      "File: location_sentence_20.json\n",
      "Vector Type: count_increase\n",
      "Layer: 4 res\n",
      "Scale: 8\n",
      "Vector Norm: 8.0023\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_20.json\n",
      "\n",
      "--- Testing Vector 165/192 ---\n",
      "File: location_sentence_20.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 0 res\n",
      "Scale: 3\n",
      "Vector Norm: 2.9926\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_20.json\n",
      "\n",
      "--- Testing Vector 166/192 ---\n",
      "File: location_sentence_55.json\n",
      "Vector Type: count_increase\n",
      "Layer: 6 res\n",
      "Scale: 6\n",
      "Vector Norm: 6.0145\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_55.json\n",
      "\n",
      "--- Testing Vector 167/192 ---\n",
      "File: location_sentence_55.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 9 res\n",
      "Scale: 12\n",
      "Vector Norm: 12.0113\n",
      "  Registered hook at Layer 9 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_55.json\n",
      "\n",
      "--- Testing Vector 168/192 ---\n",
      "File: location_sentence_29.json\n",
      "Vector Type: count_increase\n",
      "Layer: 3 res\n",
      "Scale: -5.5\n",
      "Vector Norm: 5.5001\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_29.json\n",
      "\n",
      "--- Testing Vector 169/192 ---\n",
      "File: location_sentence_29.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0070\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7220 (361/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7220\n",
      "  Accuracy drop: 0.0500 (+5.00 percentage points)\n",
      "  Removed hook for location_sentence_29.json\n",
      "\n",
      "--- Testing Vector 170/192 ---\n",
      "File: location_sentence_25.json\n",
      "Vector Type: count_increase\n",
      "Layer: 5 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0223\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7320 (366/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7320\n",
      "  Accuracy drop: 0.0400 (+4.00 percentage points)\n",
      "  Removed hook for location_sentence_25.json\n",
      "\n",
      "--- Testing Vector 171/192 ---\n",
      "File: location_sentence_25.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0036\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_25.json\n",
      "\n",
      "--- Testing Vector 172/192 ---\n",
      "File: location_sentence_78.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 8 res\n",
      "Scale: 17\n",
      "Vector Norm: 17.0361\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7480 (374/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7480\n",
      "  Accuracy drop: 0.0240 (+2.40 percentage points)\n",
      "  Removed hook for location_sentence_78.json\n",
      "\n",
      "--- Testing Vector 173/192 ---\n",
      "File: location_sentence_45.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -7\n",
      "Vector Norm: 6.9778\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7740 (387/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7740\n",
      "  Accuracy drop: -0.0020 (-0.20 percentage points)\n",
      "  Removed hook for location_sentence_45.json\n",
      "\n",
      "--- Testing Vector 174/192 ---\n",
      "File: location_sentence_45.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9723\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7480 (374/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7480\n",
      "  Accuracy drop: 0.0240 (+2.40 percentage points)\n",
      "  Removed hook for location_sentence_45.json\n",
      "\n",
      "--- Testing Vector 175/192 ---\n",
      "File: location_sentence_22.json\n",
      "Vector Type: count_increase\n",
      "Layer: 1 res\n",
      "Scale: 2.5\n",
      "Vector Norm: 2.4968\n",
      "  Registered hook at Layer 1 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7620 (381/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7620\n",
      "  Accuracy drop: 0.0100 (+1.00 percentage points)\n",
      "  Removed hook for location_sentence_22.json\n",
      "\n",
      "--- Testing Vector 176/192 ---\n",
      "File: location_sentence_22.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: 20\n",
      "Vector Norm: 19.9641\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7220 (361/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7220\n",
      "  Accuracy drop: 0.0500 (+5.00 percentage points)\n",
      "  Removed hook for location_sentence_22.json\n",
      "\n",
      "--- Testing Vector 177/192 ---\n",
      "File: location_sentence_39.json\n",
      "Vector Type: count_increase\n",
      "Layer: 9 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9953\n",
      "  Registered hook at Layer 9 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7480 (374/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7480\n",
      "  Accuracy drop: 0.0240 (+2.40 percentage points)\n",
      "  Removed hook for location_sentence_39.json\n",
      "\n",
      "--- Testing Vector 178/192 ---\n",
      "File: location_sentence_39.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: 7.5\n",
      "Vector Norm: 7.4928\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7540 (377/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7540\n",
      "  Accuracy drop: 0.0180 (+1.80 percentage points)\n",
      "  Removed hook for location_sentence_39.json\n",
      "\n",
      "--- Testing Vector 179/192 ---\n",
      "File: location_sentence_28.json\n",
      "Vector Type: count_increase\n",
      "Layer: 13 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9931\n",
      "  Registered hook at Layer 13 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7700 (385/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7700\n",
      "  Accuracy drop: 0.0020 (+0.20 percentage points)\n",
      "  Removed hook for location_sentence_28.json\n",
      "\n",
      "--- Testing Vector 180/192 ---\n",
      "File: location_sentence_28.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 4 res\n",
      "Scale: -20\n",
      "Vector Norm: 20.0309\n",
      "  Registered hook at Layer 4 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.4720 (236/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.4720\n",
      "  Accuracy drop: 0.3000 (+30.00 percentage points)\n",
      "  Removed hook for location_sentence_28.json\n",
      "\n",
      "--- Testing Vector 181/192 ---\n",
      "File: location_sentence_14.json\n",
      "Vector Type: count_increase\n",
      "Layer: 5 res\n",
      "Scale: -17\n",
      "Vector Norm: 17.0336\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.6500 (325/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.6500\n",
      "  Accuracy drop: 0.1220 (+12.20 percentage points)\n",
      "  Removed hook for location_sentence_14.json\n",
      "\n",
      "--- Testing Vector 182/192 ---\n",
      "File: location_sentence_14.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 7 res\n",
      "Scale: -14\n",
      "Vector Norm: 14.0422\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7440 (372/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7440\n",
      "  Accuracy drop: 0.0280 (+2.80 percentage points)\n",
      "  Removed hook for location_sentence_14.json\n",
      "\n",
      "--- Testing Vector 183/192 ---\n",
      "File: location_sentence_74.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9832\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7420 (371/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7420\n",
      "  Accuracy drop: 0.0300 (+3.00 percentage points)\n",
      "  Removed hook for location_sentence_74.json\n",
      "\n",
      "--- Testing Vector 184/192 ---\n",
      "File: location_sentence_74.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 0 res\n",
      "Scale: -1.5\n",
      "Vector Norm: 1.5003\n",
      "  Registered hook at Layer 0 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_74.json\n",
      "\n",
      "--- Testing Vector 185/192 ---\n",
      "File: location_sentence_51.json\n",
      "Vector Type: count_increase\n",
      "Layer: 8 res\n",
      "Scale: -10\n",
      "Vector Norm: 9.9996\n",
      "  Registered hook at Layer 8 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7600 (380/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7600\n",
      "  Accuracy drop: 0.0120 (+1.20 percentage points)\n",
      "  Removed hook for location_sentence_51.json\n",
      "\n",
      "--- Testing Vector 186/192 ---\n",
      "File: location_sentence_51.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 6 res\n",
      "Scale: -12\n",
      "Vector Norm: 12.0378\n",
      "  Registered hook at Layer 6 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7520 (376/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7520\n",
      "  Accuracy drop: 0.0200 (+2.00 percentage points)\n",
      "  Removed hook for location_sentence_51.json\n",
      "\n",
      "--- Testing Vector 187/192 ---\n",
      "File: location_sentence_64.json\n",
      "Vector Type: count_increase\n",
      "Layer: 7 res\n",
      "Scale: -12\n",
      "Vector Norm: 11.9706\n",
      "  Registered hook at Layer 7 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_64.json\n",
      "\n",
      "--- Testing Vector 188/192 ---\n",
      "File: location_sentence_64.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 15 res\n",
      "Scale: -14\n",
      "Vector Norm: 13.9916\n",
      "  Registered hook at Layer 15 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7720 (386/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7720\n",
      "  Accuracy drop: 0.0000 (+0.00 percentage points)\n",
      "  Removed hook for location_sentence_64.json\n",
      "\n",
      "--- Testing Vector 189/192 ---\n",
      "File: location_sentence_66.json\n",
      "Vector Type: count_increase\n",
      "Layer: 2 res\n",
      "Scale: -3\n",
      "Vector Norm: 3.0014\n",
      "  Registered hook at Layer 2 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7660 (383/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7660\n",
      "  Accuracy drop: 0.0060 (+0.60 percentage points)\n",
      "  Removed hook for location_sentence_66.json\n",
      "\n",
      "--- Testing Vector 190/192 ---\n",
      "File: location_sentence_66.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 3 res\n",
      "Scale: 4.5\n",
      "Vector Norm: 4.4919\n",
      "  Registered hook at Layer 3 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7760 (388/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7760\n",
      "  Accuracy drop: -0.0040 (-0.40 percentage points)\n",
      "  Removed hook for location_sentence_66.json\n",
      "\n",
      "--- Testing Vector 191/192 ---\n",
      "File: location_sentence_24.json\n",
      "Vector Type: count_increase\n",
      "Layer: 5 res\n",
      "Scale: -10\n",
      "Vector Norm: 10.0137\n",
      "  Registered hook at Layer 5 res\n",
      "Interference Test (count_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (count_increase) accuracy: 0.7460 (373/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7460\n",
      "  Accuracy drop: 0.0260 (+2.60 percentage points)\n",
      "  Removed hook for location_sentence_24.json\n",
      "\n",
      "--- Testing Vector 192/192 ---\n",
      "File: location_sentence_24.json\n",
      "Vector Type: prob_increase\n",
      "Layer: 12 res\n",
      "Scale: 14\n",
      "Vector Norm: 13.9662\n",
      "  Registered hook at Layer 12 res\n",
      "Interference Test (prob_increase)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Interference Test (prob_increase) accuracy: 0.7680 (384/500)\n",
      "  Results: Baseline 0.7720 -> Interference 0.7680\n",
      "  Accuracy drop: 0.0040 (+0.40 percentage points)\n",
      "  Removed hook for location_sentence_24.json\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF ALL INTERFERENCE TESTS\n",
      "================================================================================\n",
      "Baseline Accuracy: 0.7720 (386/500)\n",
      "Tested 192 interference vectors\n",
      "\n",
      "File: location_sentence_52.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 14.0270\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_52.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: -1.5\n",
      "  Vector Norm: 1.5010\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_33.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 3.5\n",
      "  Vector Norm: 3.4977\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_33.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 14.0109\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6640\n",
      "  Accuracy Drop: 0.1080\n",
      "----------------------------------------\n",
      "File: location_sentence_31.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0379\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_31.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 9.9865\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6640\n",
      "  Accuracy Drop: 0.1080\n",
      "----------------------------------------\n",
      "File: location_sentence_100.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -2\n",
      "  Vector Norm: 1.9998\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_100.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -4\n",
      "  Vector Norm: 4.0079\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_59.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9807\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_59.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 12\n",
      "  Vector Norm: 12.0063\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_91.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 9 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9835\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_91.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 4.5\n",
      "  Vector Norm: 4.4929\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7780\n",
      "  Accuracy Drop: -0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_53.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -8\n",
      "  Vector Norm: 8.0149\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_53.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -8\n",
      "  Vector Norm: 8.0149\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_70.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9796\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_70.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 16.9514\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_62.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -4.5\n",
      "  Vector Norm: 4.4930\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_62.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -4\n",
      "  Vector Norm: 3.9938\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_15.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -3.5\n",
      "  Vector Norm: 3.5057\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_15.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0019\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7540\n",
      "  Accuracy Drop: 0.0180\n",
      "----------------------------------------\n",
      "File: location_sentence_7.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9593\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_7.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9926\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7340\n",
      "  Accuracy Drop: 0.0380\n",
      "----------------------------------------\n",
      "File: location_sentence_72.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -2\n",
      "  Vector Norm: 1.9961\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_72.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 14 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 20.0369\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_27.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -5\n",
      "  Vector Norm: 5.0115\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7820\n",
      "  Accuracy Drop: -0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_34.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 9.9921\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_34.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0071\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_30.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 9.9982\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_30.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 14 res\n",
      "  Scale: 12\n",
      "  Vector Norm: 12.0175\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7560\n",
      "  Accuracy Drop: 0.0160\n",
      "----------------------------------------\n",
      "File: location_sentence_95.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.5017\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_95.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 20.0486\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.5340\n",
      "  Accuracy Drop: 0.2380\n",
      "----------------------------------------\n",
      "File: location_sentence_60.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -6.5\n",
      "  Vector Norm: 6.4935\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7580\n",
      "  Accuracy Drop: 0.0140\n",
      "----------------------------------------\n",
      "File: location_sentence_60.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -5.5\n",
      "  Vector Norm: 5.4945\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_81.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 14.0407\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_81.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 19.9398\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7000\n",
      "  Accuracy Drop: 0.0720\n",
      "----------------------------------------\n",
      "File: location_sentence_47.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 1\n",
      "  Vector Norm: 0.9995\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_47.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9634\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7060\n",
      "  Accuracy Drop: 0.0660\n",
      "----------------------------------------\n",
      "File: location_sentence_99.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.4951\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_99.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -8\n",
      "  Vector Norm: 7.9855\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7780\n",
      "  Accuracy Drop: -0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_69.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0064\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_69.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0078\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_58.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0120\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6920\n",
      "  Accuracy Drop: 0.0800\n",
      "----------------------------------------\n",
      "File: location_sentence_58.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.4992\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_6.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -4.5\n",
      "  Vector Norm: 4.5078\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_6.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -6\n",
      "  Vector Norm: 5.9877\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_16.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 16.9872\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7420\n",
      "  Accuracy Drop: 0.0300\n",
      "----------------------------------------\n",
      "File: location_sentence_16.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9657\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7380\n",
      "  Accuracy Drop: 0.0340\n",
      "----------------------------------------\n",
      "File: location_sentence_84.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0254\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7340\n",
      "  Accuracy Drop: 0.0380\n",
      "----------------------------------------\n",
      "File: location_sentence_84.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0254\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7340\n",
      "  Accuracy Drop: 0.0380\n",
      "----------------------------------------\n",
      "File: location_sentence_1.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 10.0087\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_1.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9826\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.3400\n",
      "  Accuracy Drop: 0.4320\n",
      "----------------------------------------\n",
      "File: location_sentence_44.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: 6.5\n",
      "  Vector Norm: 6.4928\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_44.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9647\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7580\n",
      "  Accuracy Drop: 0.0140\n",
      "----------------------------------------\n",
      "File: location_sentence_71.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 9.9726\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_88.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: -2\n",
      "  Vector Norm: 2.0019\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7820\n",
      "  Accuracy Drop: -0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_88.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -5\n",
      "  Vector Norm: 5.0115\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_43.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 17.0385\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7460\n",
      "  Accuracy Drop: 0.0260\n",
      "----------------------------------------\n",
      "File: location_sentence_43.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -4\n",
      "  Vector Norm: 3.9975\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_46.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -2.5\n",
      "  Vector Norm: 2.4974\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_46.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.4982\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_94.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.4985\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_94.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 3\n",
      "  Vector Norm: 2.9972\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_40.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -8\n",
      "  Vector Norm: 7.9975\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_40.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0046\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7820\n",
      "  Accuracy Drop: -0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_75.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: -1\n",
      "  Vector Norm: 1.0016\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_75.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9963\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7280\n",
      "  Accuracy Drop: 0.0440\n",
      "----------------------------------------\n",
      "File: location_sentence_98.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0198\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_98.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 10.0034\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6940\n",
      "  Accuracy Drop: 0.0780\n",
      "----------------------------------------\n",
      "File: location_sentence_48.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.4955\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_48.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 6\n",
      "  Vector Norm: 5.9912\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.3900\n",
      "  Accuracy Drop: 0.3820\n",
      "----------------------------------------\n",
      "File: location_sentence_97.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: 7.5\n",
      "  Vector Norm: 7.4902\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_97.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: 8\n",
      "  Vector Norm: 8.0053\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_83.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0231\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7500\n",
      "  Accuracy Drop: 0.0220\n",
      "----------------------------------------\n",
      "File: location_sentence_83.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0271\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7580\n",
      "  Accuracy Drop: 0.0140\n",
      "----------------------------------------\n",
      "File: location_sentence_57.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 4.5\n",
      "  Vector Norm: 4.5071\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_57.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 20.0116\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7440\n",
      "  Accuracy Drop: 0.0280\n",
      "----------------------------------------\n",
      "File: location_sentence_4.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 10.0266\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_4.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0189\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7240\n",
      "  Accuracy Drop: 0.0480\n",
      "----------------------------------------\n",
      "File: location_sentence_49.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 3.5\n",
      "  Vector Norm: 3.5111\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_49.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0207\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_92.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -4.5\n",
      "  Vector Norm: 4.5073\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_92.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0181\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_10.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9469\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6380\n",
      "  Accuracy Drop: 0.1340\n",
      "----------------------------------------\n",
      "File: location_sentence_10.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 19.9375\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.5700\n",
      "  Accuracy Drop: 0.2020\n",
      "----------------------------------------\n",
      "File: location_sentence_2.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 3\n",
      "  Vector Norm: 2.9985\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_2.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9992\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7500\n",
      "  Accuracy Drop: 0.0220\n",
      "----------------------------------------\n",
      "File: location_sentence_50.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 19.9624\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_50.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: 20\n",
      "  Vector Norm: 19.9752\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_79.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 9 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0309\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_79.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: 7\n",
      "  Vector Norm: 7.0197\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7800\n",
      "  Accuracy Drop: -0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_42.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 7.5\n",
      "  Vector Norm: 7.5137\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_42.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -3.5\n",
      "  Vector Norm: 3.4930\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_68.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: 12\n",
      "  Vector Norm: 11.9935\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_68.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 14 res\n",
      "  Scale: 20\n",
      "  Vector Norm: 20.0289\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7500\n",
      "  Accuracy Drop: 0.0220\n",
      "----------------------------------------\n",
      "File: location_sentence_38.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 2\n",
      "  Vector Norm: 2.0015\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_38.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: -1.5\n",
      "  Vector Norm: 1.5033\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_77.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 5\n",
      "  Vector Norm: 5.0022\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_77.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: 8\n",
      "  Vector Norm: 8.0141\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_9.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 5\n",
      "  Vector Norm: 5.0027\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_9.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 5\n",
      "  Vector Norm: 5.0027\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_63.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: -1.5\n",
      "  Vector Norm: 1.4991\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_63.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -7.5\n",
      "  Vector Norm: 7.4814\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_23.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -2\n",
      "  Vector Norm: 1.9993\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_23.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0115\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_80.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -3.5\n",
      "  Vector Norm: 3.4965\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_80.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 3.5\n",
      "  Vector Norm: 3.4966\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_93.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0153\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_93.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 14.0318\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_89.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: 12\n",
      "  Vector Norm: 11.9828\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_89.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: 8\n",
      "  Vector Norm: 8.0125\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_37.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9706\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.3700\n",
      "  Accuracy Drop: 0.4020\n",
      "----------------------------------------\n",
      "File: location_sentence_37.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0132\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7220\n",
      "  Accuracy Drop: 0.0500\n",
      "----------------------------------------\n",
      "File: location_sentence_12.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 3\n",
      "  Vector Norm: 2.9972\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_12.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -7.5\n",
      "  Vector Norm: 7.5009\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_19.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 9.9873\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_19.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -8\n",
      "  Vector Norm: 7.9921\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7580\n",
      "  Accuracy Drop: 0.0140\n",
      "----------------------------------------\n",
      "File: location_sentence_61.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0349\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7540\n",
      "  Accuracy Drop: 0.0180\n",
      "----------------------------------------\n",
      "File: location_sentence_61.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0112\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7560\n",
      "  Accuracy Drop: 0.0160\n",
      "----------------------------------------\n",
      "File: location_sentence_96.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -3.5\n",
      "  Vector Norm: 3.4911\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_96.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 3.5\n",
      "  Vector Norm: 3.4921\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7460\n",
      "  Accuracy Drop: 0.0260\n",
      "----------------------------------------\n",
      "File: location_sentence_73.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9789\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_73.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0002\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7540\n",
      "  Accuracy Drop: 0.0180\n",
      "----------------------------------------\n",
      "File: location_sentence_36.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9943\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_36.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 17.0160\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_87.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 14 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 17.0102\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7500\n",
      "  Accuracy Drop: 0.0220\n",
      "----------------------------------------\n",
      "File: location_sentence_87.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 5.5\n",
      "  Vector Norm: 5.4836\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_56.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: 6.5\n",
      "  Vector Norm: 6.5052\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_56.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0182\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7580\n",
      "  Accuracy Drop: 0.0140\n",
      "----------------------------------------\n",
      "File: location_sentence_90.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9695\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_90.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 16.9630\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_32.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0152\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_32.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0152\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_18.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9902\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.4720\n",
      "  Accuracy Drop: 0.3000\n",
      "----------------------------------------\n",
      "File: location_sentence_18.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9902\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.4720\n",
      "  Accuracy Drop: 0.3000\n",
      "----------------------------------------\n",
      "File: location_sentence_67.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9962\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_67.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: -2.5\n",
      "  Vector Norm: 2.4988\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_85.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 2.5\n",
      "  Vector Norm: 2.5013\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_85.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 2.5\n",
      "  Vector Norm: 2.5013\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_35.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.5003\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_35.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: 7\n",
      "  Vector Norm: 7.0103\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_76.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: -2\n",
      "  Vector Norm: 1.9990\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_76.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0222\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_3.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9905\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7480\n",
      "  Accuracy Drop: 0.0240\n",
      "----------------------------------------\n",
      "File: location_sentence_3.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -6.5\n",
      "  Vector Norm: 6.5261\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_82.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 9 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0223\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_82.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 14 res\n",
      "  Scale: 20\n",
      "  Vector Norm: 19.9934\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7540\n",
      "  Accuracy Drop: 0.0180\n",
      "----------------------------------------\n",
      "File: location_sentence_41.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9920\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_26.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9854\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_26.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 16.9648\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7320\n",
      "  Accuracy Drop: 0.0400\n",
      "----------------------------------------\n",
      "File: location_sentence_54.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9815\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_54.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: 2\n",
      "  Vector Norm: 2.0012\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_11.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9760\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_11.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 5\n",
      "  Vector Norm: 4.9983\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_21.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 9.9677\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7640\n",
      "  Accuracy Drop: 0.0080\n",
      "----------------------------------------\n",
      "File: location_sentence_21.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0142\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7480\n",
      "  Accuracy Drop: 0.0240\n",
      "----------------------------------------\n",
      "File: location_sentence_65.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0065\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7560\n",
      "  Accuracy Drop: 0.0160\n",
      "----------------------------------------\n",
      "File: location_sentence_65.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 1.5\n",
      "  Vector Norm: 1.5000\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_86.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 10 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 10.0008\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_86.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 11 res\n",
      "  Scale: 10\n",
      "  Vector Norm: 9.9925\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_13.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0127\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_13.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0099\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.4100\n",
      "  Accuracy Drop: 0.3620\n",
      "----------------------------------------\n",
      "File: location_sentence_17.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 4.5\n",
      "  Vector Norm: 4.5106\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_17.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: 3\n",
      "  Vector Norm: 2.9956\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_20.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 8\n",
      "  Vector Norm: 8.0023\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_20.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: 3\n",
      "  Vector Norm: 2.9926\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_55.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: 6\n",
      "  Vector Norm: 6.0145\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_55.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 9 res\n",
      "  Scale: 12\n",
      "  Vector Norm: 12.0113\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_29.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: -5.5\n",
      "  Vector Norm: 5.5001\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_29.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0070\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7220\n",
      "  Accuracy Drop: 0.0500\n",
      "----------------------------------------\n",
      "File: location_sentence_25.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0223\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7320\n",
      "  Accuracy Drop: 0.0400\n",
      "----------------------------------------\n",
      "File: location_sentence_25.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0036\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_78.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: 17\n",
      "  Vector Norm: 17.0361\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7480\n",
      "  Accuracy Drop: 0.0240\n",
      "----------------------------------------\n",
      "File: location_sentence_45.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -7\n",
      "  Vector Norm: 6.9778\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7740\n",
      "  Accuracy Drop: -0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_45.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9723\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7480\n",
      "  Accuracy Drop: 0.0240\n",
      "----------------------------------------\n",
      "File: location_sentence_22.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 1 res\n",
      "  Scale: 2.5\n",
      "  Vector Norm: 2.4968\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7620\n",
      "  Accuracy Drop: 0.0100\n",
      "----------------------------------------\n",
      "File: location_sentence_22.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: 20\n",
      "  Vector Norm: 19.9641\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7220\n",
      "  Accuracy Drop: 0.0500\n",
      "----------------------------------------\n",
      "File: location_sentence_39.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 9 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9953\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7480\n",
      "  Accuracy Drop: 0.0240\n",
      "----------------------------------------\n",
      "File: location_sentence_39.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: 7.5\n",
      "  Vector Norm: 7.4928\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7540\n",
      "  Accuracy Drop: 0.0180\n",
      "----------------------------------------\n",
      "File: location_sentence_28.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 13 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9931\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7700\n",
      "  Accuracy Drop: 0.0020\n",
      "----------------------------------------\n",
      "File: location_sentence_28.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 4 res\n",
      "  Scale: -20\n",
      "  Vector Norm: 20.0309\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.4720\n",
      "  Accuracy Drop: 0.3000\n",
      "----------------------------------------\n",
      "File: location_sentence_14.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -17\n",
      "  Vector Norm: 17.0336\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.6500\n",
      "  Accuracy Drop: 0.1220\n",
      "----------------------------------------\n",
      "File: location_sentence_14.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 14.0422\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7440\n",
      "  Accuracy Drop: 0.0280\n",
      "----------------------------------------\n",
      "File: location_sentence_74.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9832\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7420\n",
      "  Accuracy Drop: 0.0300\n",
      "----------------------------------------\n",
      "File: location_sentence_74.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 0 res\n",
      "  Scale: -1.5\n",
      "  Vector Norm: 1.5003\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_51.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 8 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 9.9996\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7600\n",
      "  Accuracy Drop: 0.0120\n",
      "----------------------------------------\n",
      "File: location_sentence_51.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 6 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 12.0378\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7520\n",
      "  Accuracy Drop: 0.0200\n",
      "----------------------------------------\n",
      "File: location_sentence_64.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 7 res\n",
      "  Scale: -12\n",
      "  Vector Norm: 11.9706\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_64.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 15 res\n",
      "  Scale: -14\n",
      "  Vector Norm: 13.9916\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7720\n",
      "  Accuracy Drop: 0.0000\n",
      "----------------------------------------\n",
      "File: location_sentence_66.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 2 res\n",
      "  Scale: -3\n",
      "  Vector Norm: 3.0014\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7660\n",
      "  Accuracy Drop: 0.0060\n",
      "----------------------------------------\n",
      "File: location_sentence_66.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 3 res\n",
      "  Scale: 4.5\n",
      "  Vector Norm: 4.4919\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7760\n",
      "  Accuracy Drop: -0.0040\n",
      "----------------------------------------\n",
      "File: location_sentence_24.json\n",
      "  Vector Type: count_increase\n",
      "  Location: Layer 5 res\n",
      "  Scale: -10\n",
      "  Vector Norm: 10.0137\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7460\n",
      "  Accuracy Drop: 0.0260\n",
      "----------------------------------------\n",
      "File: location_sentence_24.json\n",
      "  Vector Type: prob_increase\n",
      "  Location: Layer 12 res\n",
      "  Scale: 14\n",
      "  Vector Norm: 13.9662\n",
      "  Baseline: 0.7720\n",
      "  With Interference: 0.7680\n",
      "  Accuracy Drop: 0.0040\n",
      "----------------------------------------\n",
      "\n",
      "Overall Statistics:\n",
      "  Average accuracy drop: 0.0277\n",
      "  Std accuracy drop: 0.0709\n",
      "  Max accuracy drop: 0.4320\n",
      "  Min accuracy drop: -0.0100\n",
      "  Number of harmful vectors (positive drop): 149\n",
      "  Number of beneficial vectors (negative drop): 25\n",
      "\n",
      "Results saved to ./interference_hellaswag_test_results.json\n"
     ]
    }
   ],
   "source": [
    "# Load interference vectors\n",
    "results_dir = \"./results/results_location\"\n",
    "n_files = 100  # Number of interference files to test\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"LOADING INTERFERENCE VECTORS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load interference files\n",
    "interference_info = load_interference_files(results_dir, n_files=n_files)\n",
    "\n",
    "if not interference_info:\n",
    "    print(\"No interference files loaded. Exiting.\")\n",
    "else:\n",
    "    # Parse all interference vectors\n",
    "    vectors = parse_interference_vectors(interference_info)\n",
    "    print(f\"Parsed {len(vectors)} interference vectors\")\n",
    "    \n",
    "    if vectors:\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"INTERFERENCE TESTING\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for i, vector_info in enumerate(vectors):\n",
    "            print(f\"\\n--- Testing Vector {i+1}/{len(vectors)} ---\")\n",
    "            print(f\"File: {vector_info['file_name']}\")\n",
    "            print(f\"Vector Type: {vector_info['vector_type']}\")\n",
    "            print(f\"Layer: {vector_info['layer_id']} {vector_info['layer_type']}\")\n",
    "            print(f\"Scale: {vector_info['scale']}\")\n",
    "            print(f\"Vector Norm: {vector_info['vector_norm']:.4f}\")\n",
    "            \n",
    "            # Register interference hook ONCE for this vector\n",
    "            hook_handle = register_interference_hook(\n",
    "                llama, vector_info, scale=1.0, interference_scale=0.25\n",
    "            )\n",
    "            \n",
    "            if hook_handle is None:\n",
    "                print(f\"  Failed to register hook for {vector_info['file_name']}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Test with interference (hook is already active)\n",
    "                interference_accuracy, interference_correct, interference_total = test_hellaswag_with_hook(\n",
    "                    llama, tokenizer, test_samples, hook_handle=hook_handle, \n",
    "                    description=f\"Interference Test ({vector_info['vector_type']})\"\n",
    "                )\n",
    "                \n",
    "                # Calculate accuracy drop\n",
    "                accuracy_drop = baseline_accuracy - interference_accuracy\n",
    "                \n",
    "                result = {\n",
    "                    'file_name': vector_info['file_name'],\n",
    "                    'vector_type': vector_info['vector_type'],\n",
    "                    'layer_id': vector_info['layer_id'],\n",
    "                    'layer_type': vector_info['layer_type'],\n",
    "                    'scale': vector_info['scale'],\n",
    "                    'vector_norm': vector_info['vector_norm'],\n",
    "                    'baseline_accuracy': baseline_accuracy,\n",
    "                    'baseline_correct': baseline_correct,\n",
    "                    'baseline_total': baseline_total,\n",
    "                    'interference_accuracy': interference_accuracy,\n",
    "                    'interference_correct': interference_correct,\n",
    "                    'interference_total': interference_total,\n",
    "                    'accuracy_drop': accuracy_drop\n",
    "                }\n",
    "                \n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"  Results: Baseline {baseline_accuracy:.4f} -> Interference {interference_accuracy:.4f}\")\n",
    "                print(f\"  Accuracy drop: {accuracy_drop:.4f} ({accuracy_drop*100:+.2f} percentage points)\")\n",
    "                \n",
    "            finally:\n",
    "                # Remove hook ONCE after testing all samples\n",
    "                if hook_handle:\n",
    "                    hook_handle.remove()\n",
    "                    print(f\"  Removed hook for {vector_info['file_name']}\")\n",
    "                \n",
    "                # Clean up memory after each vector test\n",
    "                clean_up_memory()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SUMMARY OF ALL INTERFERENCE TESTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"Baseline Accuracy: {baseline_accuracy:.4f} ({baseline_correct}/{baseline_total})\")\n",
    "        print(f\"Tested {len(all_results)} interference vectors\\n\")\n",
    "        \n",
    "        all_drops = [r['accuracy_drop'] for r in all_results]\n",
    "        \n",
    "        for result in all_results:\n",
    "            print(f\"File: {result['file_name']}\")\n",
    "            print(f\"  Vector Type: {result['vector_type']}\")\n",
    "            print(f\"  Location: Layer {result['layer_id']} {result['layer_type']}\")\n",
    "            print(f\"  Scale: {result['scale']}\")\n",
    "            print(f\"  Vector Norm: {result['vector_norm']:.4f}\")\n",
    "            print(f\"  Baseline: {result['baseline_accuracy']:.4f}\")\n",
    "            print(f\"  With Interference: {result['interference_accuracy']:.4f}\")\n",
    "            print(f\"  Accuracy Drop: {result['accuracy_drop']:.4f}\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        if all_drops:\n",
    "            print(f\"\\nOverall Statistics:\")\n",
    "            print(f\"  Average accuracy drop: {np.mean(all_drops):.4f}\")\n",
    "            print(f\"  Std accuracy drop: {np.std(all_drops):.4f}\")\n",
    "            print(f\"  Max accuracy drop: {np.max(all_drops):.4f}\")\n",
    "            print(f\"  Min accuracy drop: {np.min(all_drops):.4f}\")\n",
    "            print(f\"  Number of harmful vectors (positive drop): {sum(1 for x in all_drops if x > 0)}\")\n",
    "            print(f\"  Number of beneficial vectors (negative drop): {sum(1 for x in all_drops if x < 0)}\")\n",
    "        \n",
    "        # Save results\n",
    "        output_file = \"./interference_hellaswag_test_results.json\"\n",
    "        results_data = {\n",
    "            'test_config': {\n",
    "                'num_test_samples': len(test_samples),\n",
    "                'num_interference_vectors': len(all_results),\n",
    "                'results_directory': results_dir,\n",
    "                'interference_scale': 0.25,\n",
    "                'random_seed': 42\n",
    "            },\n",
    "            'baseline_results': {\n",
    "                'accuracy': baseline_accuracy,\n",
    "                'correct': baseline_correct,\n",
    "                'total': baseline_total\n",
    "            },\n",
    "            'interference_results': all_results,\n",
    "            'summary_statistics': {\n",
    "                'average_accuracy_drop': np.mean(all_drops) if all_drops else 0,\n",
    "                'std_accuracy_drop': np.std(all_drops) if all_drops else 0,\n",
    "                'max_accuracy_drop': np.max(all_drops) if all_drops else 0,\n",
    "                'min_accuracy_drop': np.min(all_drops) if all_drops else 0,\n",
    "                'num_harmful_vectors': sum(1 for x in all_drops if x > 0),\n",
    "                'num_beneficial_vectors': sum(1 for x in all_drops if x < 0)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results_data, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No valid interference vectors found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecb84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for location result files in: ./results/results_location\n",
      "Found 98 location result files\n",
      "\n",
      "====================================================================================================\n",
      "ANALYZING TOP TOKEN CHANGES FOR EACH LOCATION SENTENCE\n",
      "====================================================================================================\n",
      "\n",
      "==================== Processing File 1/98 ====================\n",
      "File: location_sentence_1.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'After months of planning, our road trip finally reached'\n",
      "File: location_sentence_1.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 10.0087\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' its'                    0.660156     ' its'                    0.679688     ↑ +0.019531\n",
      "2    ' the'                    0.243164     ' the'                    0.220703     ↓ -0.022461\n",
      "3    ' a'                      0.022583     ' a'                      0.023193     ↑ +0.000610\n",
      "4    ' it'                     0.012878     ' it'                     0.018066     ↑ +0.005188\n",
      "5    ' an'                     0.008850     ' an'                     0.009705     ↑ +0.000854\n",
      "6    ' our'                    0.005371     ' our'                    0.003799     ↓ -0.001572\n",
      "7    ' this'                   0.002380     ' one'                    0.002167     ↓ -0.000214\n",
      "8    ' one'                    0.002106     ' this'                   0.002029     ↓ -0.000076\n",
      "9    ' New'                    0.001198     ' fruition'               0.001160     ↓ -0.000038\n",
      "10   ' day'                    0.000992     ' New'                    0.001083     ↑ +0.000092\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' its'\n",
      "   Probability change: +0.019531\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' fruition' (prob: 0.001160)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' day' (prob: 0.000992)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.050636\n",
      "   Average absolute change per token: 0.005064\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 2/98 ====================\n",
      "File: location_sentence_10.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'All flights were canceled due to volcanic activity near'\n",
      "File: location_sentence_10.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 16.9469\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.458984     ' the'                    0.310547     ↓ -0.148438\n",
      "2    ' a'                      0.035400     ' Mount'                  0.114746     ↑ +0.079346\n",
      "3    ' Mount'                  0.029297     ' Iceland'                0.054199     ↑ +0.024902\n",
      "4    ' K'                      0.020142     ' Ey'                     0.044922     ↑ +0.024780\n",
      "5    ' an'                     0.018921     ' Mt'                     0.025513     ↑ +0.006592\n",
      "6    ' Tokyo'                  0.016724     ' a'                      0.021240     ↑ +0.004517\n",
      "7    ' airport'                0.011475     ' Yellowstone'            0.013672     ↑ +0.002197\n",
      "8    ' Bali'                   0.010132     ' Bali'                   0.012878     ↑ +0.002747\n",
      "9    ' airports'               0.008911     ' Krak'                   0.012085     ↑ +0.003174\n",
      "10   ' Rey'                    0.007416     ' airports'               0.010681     ↑ +0.003265\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.148438\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 5: ' Mt' (prob: 0.025513)\n",
      "   Rank 9: ' Krak' (prob: 0.012085)\n",
      "   Rank 3: ' Iceland' (prob: 0.054199)\n",
      "   Rank 7: ' Yellowstone' (prob: 0.013672)\n",
      "   Rank 4: ' Ey' (prob: 0.044922)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Rey' (prob: 0.007416)\n",
      "   Was rank 5: ' an' (prob: 0.018921)\n",
      "   Was rank 6: ' Tokyo' (prob: 0.016724)\n",
      "   Was rank 7: ' airport' (prob: 0.011475)\n",
      "   Was rank 4: ' K' (prob: 0.020142)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.299957\n",
      "   Average absolute change per token: 0.029996\n",
      "   New tokens in top-10: 5\n",
      "   Lost tokens from top-10: 5\n",
      "\n",
      "==================== Processing File 3/98 ====================\n",
      "File: location_sentence_100.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This fashion trend started among teenagers in underground clubs throughout'\n",
      "File: location_sentence_100.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 1.9998\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.478516     ' the'                    0.453125     ↓ -0.025391\n",
      "2    ' Europe'                 0.106934     ' Europe'                 0.114746     ↑ +0.007812\n",
      "3    ' New'                    0.050537     ' New'                    0.047852     ↓ -0.002686\n",
      "4    ' Japan'                  0.034668     ' Tokyo'                  0.039551     ↑ +0.004883\n",
      "5    ' Tokyo'                  0.032471     ' Japan'                  0.034912     ↑ +0.002441\n",
      "6    ' London'                 0.030640     ' London'                 0.028931     ↓ -0.001709\n",
      "7    ' Asia'                   0.018555     ' Paris'                  0.021240     ↑ +0.002686\n",
      "8    ' Los'                    0.017456     ' Asia'                   0.017578     ↑ +0.000122\n",
      "9    ' Paris'                  0.016357     ' Los'                    0.016479     ↑ +0.000122\n",
      "10   ' Berlin'                 0.014465     ' Berlin'                 0.016479     ↑ +0.002014\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.025391\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.049866\n",
      "   Average absolute change per token: 0.004987\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 4/98 ====================\n",
      "File: location_sentence_11.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'I left my heart in that little coastal town of'\n",
      "File: location_sentence_11.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 13.9760\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' San'                    0.039307     ' San'                    0.042725     ↑ +0.003418\n",
      "2    ' Santa'                  0.027100     ' Maine'                  0.024414     ↓ -0.002686\n",
      "3    ' Port'                   0.016479     ' Santa'                  0.022949     ↑ +0.006470\n",
      "4    ' Monterey'               0.016479     ' Port'                   0.013916     ↓ -0.002563\n",
      "5    ' Maine'                  0.012817     ' Monterey'               0.013062     ↑ +0.000244\n",
      "6    ' yours'                  0.011292     ' T'                      0.010803     ↓ -0.000488\n",
      "7    ' St'                     0.010620     ' K'                      0.010193     ↓ -0.000427\n",
      "8    ' S'                      0.010620     ' B'                      0.009521     ↓ -0.001099\n",
      "9    ' T'                      0.009949     ' Carm'                   0.009521     ↓ -0.000427\n",
      "10   ' P'                      0.009949     ' P'                      0.008972     ↓ -0.000977\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' San'\n",
      "   Probability change: +0.003418\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Carm' (prob: 0.009521)\n",
      "   Rank 8: ' B' (prob: 0.009521)\n",
      "   Rank 7: ' K' (prob: 0.010193)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' St' (prob: 0.010620)\n",
      "   Was rank 8: ' S' (prob: 0.010620)\n",
      "   Was rank 6: ' yours' (prob: 0.011292)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.018799\n",
      "   Average absolute change per token: 0.001880\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 5/98 ====================\n",
      "File: location_sentence_12.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This wine comes from a family-owned vineyard just outside'\n",
      "File: location_sentence_12.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 2.9972\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' of'                     0.605469     ' of'                     0.585938     ↓ -0.019531\n",
      "2    ' the'                    0.223633     ' the'                    0.215820     ↓ -0.007812\n",
      "3    ' San'                    0.005249     ' San'                    0.005737     ↑ +0.000488\n",
      "4    ' N'                      0.004944     ' N'                      0.005066     ↑ +0.000122\n",
      "5    ' T'                      0.004364     ' Florence'               0.004486     ↑ +0.000122\n",
      "6    ' St'                     0.004089     ' St'                     0.004211     ↑ +0.000122\n",
      "7    ' Ch'                     0.003845     ' T'                      0.004211     ↑ +0.000366\n",
      "8    ' Florence'               0.003845     ' M'                      0.003708     ↓ -0.000137\n",
      "9    ' P'                      0.003616     ' Ch'                     0.003708     ↑ +0.000092\n",
      "10   ' M'                      0.003387     ' P'                      0.003494     ↑ +0.000107\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' of'\n",
      "   Probability change: -0.019531\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.028900\n",
      "   Average absolute change per token: 0.002890\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "💾 Memory cleanup completed after 5 files\n",
      "\n",
      "==================== Processing File 6/98 ====================\n",
      "File: location_sentence_13.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They found the missing artifact buried beneath ruins in'\n",
      "File: location_sentence_13.json\n",
      "Vector: count_increase at Layer 15 res\n",
      "Vector norm: 17.0127\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.261719     ' the'                    0.244141     ↓ -0.017578\n",
      "2    ' a'                      0.191406     ' a'                      0.178711     ↓ -0.012695\n",
      "3    ' an'                     0.040039     ' an'                     0.039795     ↓ -0.000244\n",
      "4    ' Egypt'                  0.033203     ' Egypt'                  0.031006     ↓ -0.002197\n",
      "5    ' Mexico'                 0.018921     ' '                       0.027466     ↑ +0.008545\n",
      "6    ' Cambodia'               0.015747     ' Mexico'                 0.016602     ↑ +0.000854\n",
      "7    ' Peru'                   0.015747     ' ancient'                0.013794     ↓ -0.001953\n",
      "8    ' '                       0.015747     ' Cambodia'               0.012146     ↓ -0.003601\n",
      "9    ' Guatemala'              0.011475     ' Peru'                   0.011414     ↓ -0.000061\n",
      "10   ' Turkey'                 0.008972     ' Turkey'                 0.008911     ↓ -0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.017578\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' ancient' (prob: 0.013794)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Guatemala' (prob: 0.011475)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.047791\n",
      "   Average absolute change per token: 0.004779\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 7/98 ====================\n",
      "File: location_sentence_14.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Her research focuses on climate change effects observed around'\n",
      "File: location_sentence_14.json\n",
      "Vector: count_increase at Layer 5 res\n",
      "Vector norm: 17.0336\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 5 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.875000     ' the'                    0.789062     ↓ -0.085938\n",
      "2    ' Lake'                   0.012512     ' Antarctica'             0.019653     ↑ +0.007141\n",
      "3    ' tropical'               0.006287     ' '                       0.019653     ↑ +0.013367\n",
      "4    ' glaciers'               0.004883     ' Lake'                   0.005310     ↑ +0.000427\n",
      "5    ' Antarctica'             0.004608     ' volcanic'               0.004669     ↑ +0.000061\n",
      "6    ' natural'                0.002457     ' a'                      0.003876     ↑ +0.001419\n",
      "7    ' volcanic'               0.002304     ' Antarctic'              0.003220     ↑ +0.000916\n",
      "8    ' coral'                  0.002167     ' Greenland'              0.003021     ↑ +0.000854\n",
      "9    ' Antarctic'              0.001915     ' high'                   0.002838     ↑ +0.000923\n",
      "10   ' lakes'                  0.001801     ' tropical'               0.002670     ↑ +0.000870\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.085938\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' a' (prob: 0.003876)\n",
      "   Rank 8: ' Greenland' (prob: 0.003021)\n",
      "   Rank 9: ' high' (prob: 0.002838)\n",
      "   Rank 3: ' ' (prob: 0.019653)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' lakes' (prob: 0.001801)\n",
      "   Was rank 6: ' natural' (prob: 0.002457)\n",
      "   Was rank 4: ' glaciers' (prob: 0.004883)\n",
      "   Was rank 8: ' coral' (prob: 0.002167)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.111916\n",
      "   Average absolute change per token: 0.011192\n",
      "   New tokens in top-10: 4\n",
      "   Lost tokens from top-10: 4\n",
      "\n",
      "==================== Processing File 8/98 ====================\n",
      "File: location_sentence_15.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We're running low on supplies since leaving'\n",
      "File: location_sentence_15.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 3.5057\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.240234     ' the'                    0.225586     ↓ -0.014648\n",
      "2    ' home'                   0.047363     ' home'                   0.047363     = +0.000000\n",
      "3    ' our'                    0.022339     ' our'                    0.022339     = +0.000000\n",
      "4    ' Mexico'                 0.016357     ' Mexico'                 0.019775     ↑ +0.003418\n",
      "5    ' San'                    0.012756     ' San'                    0.014465     ↑ +0.001709\n",
      "6    ' on'                     0.012756     ' Australia'              0.013550     ↑ +0.000793\n",
      "7    ' New'                    0.011230     ' on'                     0.012756     ↑ +0.001526\n",
      "8    ' Australia'              0.010559     ' New'                    0.011963     ↑ +0.001404\n",
      "9    ' for'                    0.009949     ' civilization'           0.009338     ↓ -0.000610\n",
      "10   ' civilization'           0.009949     ' for'                    0.008789     ↓ -0.001160\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.014648\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.025269\n",
      "   Average absolute change per token: 0.002527\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 9/98 ====================\n",
      "File: location_sentence_16.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Legend says the fountain of youth lies somewhere in'\n",
      "File: location_sentence_16.json\n",
      "Vector: count_increase at Layer 11 res\n",
      "Vector norm: 16.9872\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 11 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.750000     ' the'                    0.570312     ↓ -0.179688\n",
      "2    ' Florida'                0.035156     ' Florida'                0.077148     ↑ +0.041992\n",
      "3    ' this'                   0.024170     ' South'                  0.038818     ↑ +0.014648\n",
      "4    ' South'                  0.022705     ' this'                   0.038818     ↑ +0.016113\n",
      "5    ' these'                  0.022705     ' these'                  0.025024     ↑ +0.002319\n",
      "6    ' a'                      0.012939     ' Cuba'                   0.020752     ↑ +0.007812\n",
      "7    ' B'                      0.010071     ' Central'                0.020752     ↑ +0.010681\n",
      "8    ' Central'                0.010071     ' America'                0.009827     ↓ -0.000244\n",
      "9    ' Cuba'                   0.006927     ' B'                      0.008667     ↑ +0.001740\n",
      "10   ' our'                    0.005066     ' our'                    0.008667     ↑ +0.003601\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.179688\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' America' (prob: 0.009827)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' a' (prob: 0.012939)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.278839\n",
      "   Average absolute change per token: 0.027884\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 10/98 ====================\n",
      "File: location_sentence_17.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'You'll find the best street food stalls around'\n",
      "File: location_sentence_17.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 4.5106\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.451172     ' the'                    0.519531     ↑ +0.068359\n",
      "2    ' Bangkok'                0.028809     ' Bangkok'                0.037598     ↑ +0.008789\n",
      "3    ' every'                  0.025391     ' every'                  0.033203     ↑ +0.007812\n",
      "4    ' H'                      0.023926     ' town'                   0.031250     ↑ +0.007324\n",
      "5    ' town'                   0.022461     ' this'                   0.020142     ↓ -0.002319\n",
      "6    ' this'                   0.022461     ' H'                      0.016724     ↓ -0.005737\n",
      "7    ' Ph'                     0.017456     ' Ph'                     0.010803     ↓ -0.006653\n",
      "8    ' Ch'                     0.010620     ' Singapore'              0.010803     ↑ +0.000183\n",
      "9    ' these'                  0.009338     ' Thailand'               0.008972     ↓ -0.000366\n",
      "10   ' here'                   0.009338     ' Asia'                   0.008423     ↓ -0.000916\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.068359\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Asia' (prob: 0.008423)\n",
      "   Rank 8: ' Singapore' (prob: 0.010803)\n",
      "   Rank 9: ' Thailand' (prob: 0.008972)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' these' (prob: 0.009338)\n",
      "   Was rank 10: ' here' (prob: 0.009338)\n",
      "   Was rank 8: ' Ch' (prob: 0.010620)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.108459\n",
      "   Average absolute change per token: 0.010846\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "💾 Memory cleanup completed after 10 files\n",
      "\n",
      "==================== Processing File 11/98 ====================\n",
      "File: location_sentence_18.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Our connecting flight got delayed while passing through'\n",
      "File: location_sentence_18.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 16.9902\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' security'               0.203125     ' Dubai'                  0.089355     ↓ -0.113770\n",
      "2    ' customs'                0.179688     ' the'                    0.065430     ↓ -0.114258\n",
      "3    ' the'                    0.123535     ' Singapore'              0.021240     ↓ -0.102295\n",
      "4    ' immigration'            0.048340     ' Hong'                   0.021240     ↓ -0.027100\n",
      "5    ' a'                      0.025879     ' customs'                0.019897     ↓ -0.005981\n",
      "6    ' US'                     0.022827     ' Istanbul'               0.019897     ↓ -0.002930\n",
      "7    ' Chicago'                0.018921     ' Paris'                  0.018677     ↓ -0.000244\n",
      "8    ' airport'                0.017822     ' Tokyo'                  0.018677     ↑ +0.000854\n",
      "9    ' Dubai'                  0.012207     ' Sydney'                 0.016479     ↑ +0.004272\n",
      "10   ' passport'               0.010803     ' Heath'                  0.016479     ↑ +0.005676\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' security' (prob: 0.203125)\n",
      "   After Hook:  ' Dubai' (prob: 0.089355)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' Istanbul' (prob: 0.019897)\n",
      "   Rank 7: ' Paris' (prob: 0.018677)\n",
      "   Rank 10: ' Heath' (prob: 0.016479)\n",
      "   Rank 4: ' Hong' (prob: 0.021240)\n",
      "   Rank 9: ' Sydney' (prob: 0.016479)\n",
      "   Rank 8: ' Tokyo' (prob: 0.018677)\n",
      "   Rank 3: ' Singapore' (prob: 0.021240)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 1: ' security' (prob: 0.203125)\n",
      "   Was rank 5: ' a' (prob: 0.025879)\n",
      "   Was rank 10: ' passport' (prob: 0.010803)\n",
      "   Was rank 4: ' immigration' (prob: 0.048340)\n",
      "   Was rank 6: ' US' (prob: 0.022827)\n",
      "   Was rank 7: ' Chicago' (prob: 0.018921)\n",
      "   Was rank 8: ' airport' (prob: 0.017822)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.377380\n",
      "   Average absolute change per token: 0.037738\n",
      "   New tokens in top-10: 7\n",
      "   Lost tokens from top-10: 7\n",
      "\n",
      "==================== Processing File 12/98 ====================\n",
      "File: location_sentence_19.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This painting depicts a famous historical battle fought near'\n",
      "File: location_sentence_19.json\n",
      "Vector: count_increase at Layer 6 res\n",
      "Vector norm: 9.9873\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 6 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.443359     ' the'                    0.447266     ↑ +0.003906\n",
      "2    ' this'                   0.038818     ' this'                   0.050293     ↑ +0.011475\n",
      "3    ' a'                      0.032227     ' a'                      0.026855     ↓ -0.005371\n",
      "4    ' present'                0.022095     ' present'                0.019653     ↓ -0.002441\n",
      "5    ' modern'                 0.012573     ' modern'                 0.012695     ↑ +0.000122\n",
      "6    ' Ch'                     0.009827     ' Lake'                   0.010498     ↑ +0.000671\n",
      "7    ' Lake'                   0.009827     ' Ch'                     0.009277     ↓ -0.000549\n",
      "8    ' Moscow'                 0.006348     ' Moscow'                 0.008179     ↑ +0.001831\n",
      "9    ' St'                     0.006348     ' St'                     0.006012     ↓ -0.000336\n",
      "10   ' what'                   0.005951     ' what'                   0.006012     ↑ +0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.003906\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.026764\n",
      "   Average absolute change per token: 0.002676\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 13/98 ====================\n",
      "File: location_sentence_2.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Nobody expected the storm to hit so hard in'\n",
      "File: location_sentence_2.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 2.9985\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.240234     ' the'                    0.229492     ↓ -0.010742\n",
      "2    ' '                       0.136719     ' such'                   0.115234     ↓ -0.021484\n",
      "3    ' such'                   0.068848     ' '                       0.054443     ↓ -0.014404\n",
      "4    ' this'                   0.019653     ' this'                   0.031006     ↑ +0.011353\n",
      "5    ' a'                      0.018555     ' a'                      0.025757     ↑ +0.007202\n",
      "6    ' late'                   0.017334     ' late'                   0.014648     ↓ -0.002686\n",
      "7    ' New'                    0.012756     ' just'                   0.014648     ↑ +0.001892\n",
      "8    ' Puerto'                 0.010559     ' our'                    0.012939     ↑ +0.002380\n",
      "9    ' April'                  0.009338     ' New'                    0.012146     ↑ +0.002808\n",
      "10   ' North'                  0.007721     ' that'                   0.010071     ↑ +0.002350\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.010742\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' just' (prob: 0.014648)\n",
      "   Rank 8: ' our' (prob: 0.012939)\n",
      "   Rank 10: ' that' (prob: 0.010071)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' April' (prob: 0.009338)\n",
      "   Was rank 10: ' North' (prob: 0.007721)\n",
      "   Was rank 8: ' Puerto' (prob: 0.010559)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.077301\n",
      "   Average absolute change per token: 0.007730\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 14/98 ====================\n",
      "File: location_sentence_20.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'His last known coordinates placed him somewhere near'\n",
      "File: location_sentence_20.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 8.0023\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.404297     ' the'                    0.349609     ↓ -0.054688\n",
      "2    ' a'                      0.027466     ' a'                      0.017456     ↓ -0.010010\n",
      "3    ' '                       0.015625     ' '                       0.017456     ↑ +0.001831\n",
      "4    ' Lake'                   0.005768     '\\n'                      0.011963     ↑ +0.006195\n",
      "5    '\\n'                      0.004761     ' Lake'                   0.006836     ↑ +0.002075\n",
      "6    ' downtown'               0.004486     ' K'                      0.005310     ↑ +0.000824\n",
      "7    ' an'                     0.004211     ' B'                      0.004700     ↑ +0.000488\n",
      "8    ' New'                    0.003967     ' P'                      0.004150     ↑ +0.000183\n",
      "9    ' B'                      0.003494     ' S'                      0.003891     ↑ +0.000397\n",
      "10   ' K'                      0.003494     ' T'                      0.003662     ↑ +0.000168\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.054688\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' S' (prob: 0.003891)\n",
      "   Rank 8: ' P' (prob: 0.004150)\n",
      "   Rank 10: ' T' (prob: 0.003662)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' downtown' (prob: 0.004486)\n",
      "   Was rank 7: ' an' (prob: 0.004211)\n",
      "   Was rank 8: ' New' (prob: 0.003967)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.076859\n",
      "   Average absolute change per token: 0.007686\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 15/98 ====================\n",
      "File: location_sentence_21.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Archaeologists discovered mysterious underground tunnels beneath'\n",
      "File: location_sentence_21.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 9.9677\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.488281     ' the'                    0.527344     ↑ +0.039062\n",
      "2    ' a'                      0.158203     ' a'                      0.110352     ↓ -0.047852\n",
      "3    ' an'                     0.115723     ' an'                     0.075684     ↓ -0.040039\n",
      "4    ' ancient'                0.040039     ' ancient'                0.052002     ↑ +0.011963\n",
      "5    ' Pompe'                  0.016724     ' Pompe'                  0.016968     ↑ +0.000244\n",
      "6    ' Jerusalem'              0.007416     ' Rome'                   0.009644     ↑ +0.002228\n",
      "7    ' Rome'                   0.005432     ' Paris'                  0.009033     ↑ +0.003601\n",
      "8    ' Egypt'                  0.005432     ' Jerusalem'              0.008484     ↑ +0.003052\n",
      "9    ' Mexico'                 0.005096     ' Stone'                  0.005493     ↑ +0.000397\n",
      "10   ' Stone'                  0.004486     ' Egypt'                  0.004852     ↑ +0.000366\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.039062\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' Paris' (prob: 0.009033)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Mexico' (prob: 0.005096)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.148804\n",
      "   Average absolute change per token: 0.014880\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 15 files\n",
      "\n",
      "==================== Processing File 16/98 ====================\n",
      "File: location_sentence_22.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We're currently tracking the hurricane as it approaches'\n",
      "File: location_sentence_22.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 2.4968\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.722656     ' the'                    0.726562     ↑ +0.003906\n",
      "2    ' Florida'                0.031738     ' Florida'                0.036133     ↑ +0.004395\n",
      "3    ' our'                    0.029785     ' our'                    0.026367     ↓ -0.003418\n",
      "4    ' land'                   0.021851     ' land'                   0.021851     = +0.000000\n",
      "5    '.'                       0.015991     '.'                       0.014099     ↓ -0.001892\n",
      "6    ','                       0.010986     ','                       0.012451     ↑ +0.001465\n",
      "7    ' and'                    0.010315     ' and'                    0.010315     = +0.000000\n",
      "8    ' Puerto'                 0.010315     ' Puerto'                 0.008545     ↓ -0.001770\n",
      "9    ' South'                  0.007080     ' Louisiana'              0.007111     ↑ +0.000031\n",
      "10   ' Louisiana'              0.006653     ' Cuba'                   0.007111     ↑ +0.000458\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.003906\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Cuba' (prob: 0.007111)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' South' (prob: 0.007080)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.017334\n",
      "   Average absolute change per token: 0.001733\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 17/98 ====================\n",
      "File: location_sentence_23.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'She sent a telegram saying she'd meet us in'\n",
      "File: location_sentence_23.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 1.9993\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Paris'                  0.101074     ' Paris'                  0.093262     ↓ -0.007812\n",
      "2    ' the'                    0.094727     ' the'                    0.082520     ↓ -0.012207\n",
      "3    ' New'                    0.044678     ' New'                    0.046875     ↑ +0.002197\n",
      "4    ' a'                      0.025513     ' a'                      0.023682     ↓ -0.001831\n",
      "5    ' London'                 0.021118     ' Chicago'                0.022217     ↑ +0.001099\n",
      "6    ' Chicago'                0.021118     ' London'                 0.019531     ↓ -0.001587\n",
      "7    ' town'                   0.018677     ' town'                   0.018433     ↓ -0.000244\n",
      "8    ' San'                    0.014526     ' San'                    0.015259     ↑ +0.000732\n",
      "9    ' '                       0.013672     ' Rome'                   0.014343     ↑ +0.000671\n",
      "10   ' Rome'                   0.012024     ' '                       0.009277     ↓ -0.002747\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Paris'\n",
      "   Probability change: -0.007812\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.031128\n",
      "   Average absolute change per token: 0.003113\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 18/98 ====================\n",
      "File: location_sentence_24.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This rare mineral is only found in mines near'\n",
      "File: location_sentence_24.json\n",
      "Vector: count_increase at Layer 5 res\n",
      "Vector norm: 10.0137\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 5 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.248047     ' the'                    0.255859     ↑ +0.007812\n",
      "2    ' a'                      0.020386     ' a'                      0.030518     ↑ +0.010132\n",
      "3    ' this'                   0.016846     ' this'                   0.019653     ↑ +0.002808\n",
      "4    ' its'                    0.014893     ' Lake'                   0.012695     ↓ -0.002197\n",
      "5    ' Mount'                  0.013977     ' its'                    0.011963     ↓ -0.002014\n",
      "6    ' Lake'                   0.011597     ' Mount'                  0.011963     ↑ +0.000366\n",
      "7    ' volcanic'               0.007477     ' volcanic'               0.006012     ↓ -0.001465\n",
      "8    ' San'                    0.005493     ' Yellowstone'            0.005310     ↓ -0.000183\n",
      "9    ' P'                      0.005157     ' P'                      0.004669     ↓ -0.000488\n",
      "10   ' where'                  0.005157     ' San'                    0.004669     ↓ -0.000488\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.007812\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Yellowstone' (prob: 0.005310)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' where' (prob: 0.005157)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.027954\n",
      "   Average absolute change per token: 0.002795\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 19/98 ====================\n",
      "File: location_sentence_25.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'After crossing three borders, we finally arrived at'\n",
      "File: location_sentence_25.json\n",
      "Vector: count_increase at Layer 5 res\n",
      "Vector norm: 14.0223\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 5 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.578125     ' the'                    0.648438     ↑ +0.070312\n",
      "2    ' our'                    0.187500     ' our'                    0.144531     ↓ -0.042969\n",
      "3    ' Lake'                   0.017456     ' a'                      0.014282     ↓ -0.003174\n",
      "4    ' a'                      0.013611     ' Lake'                   0.012634     ↓ -0.000977\n",
      "5    ' K'                      0.004150     ' Nam'                    0.003845     ↓ -0.000305\n",
      "6    ' Nam'                    0.003433     ' K'                      0.003403     ↓ -0.000031\n",
      "7    ' N'                      0.003036     ' my'                     0.002823     ↓ -0.000214\n",
      "8    ' Ch'                     0.003036     ' T'                      0.002823     ↓ -0.000214\n",
      "9    ' T'                      0.002686     ' Ch'                     0.002823     ↑ +0.000137\n",
      "10   ' L'                      0.002686     ' L'                      0.002335     ↓ -0.000351\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.070312\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' my' (prob: 0.002823)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' N' (prob: 0.003036)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.118683\n",
      "   Average absolute change per token: 0.011868\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 20/98 ====================\n",
      "File: location_sentence_26.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The documentary crew disappeared while filming in remote areas of'\n",
      "File: location_sentence_26.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 11.9854\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.345703     ' the'                    0.243164     ↓ -0.102539\n",
      "2    ' Papua'                  0.038818     ' Papua'                  0.039795     ↑ +0.000977\n",
      "3    ' Nepal'                  0.025024     ' Africa'                 0.035156     ↑ +0.010132\n",
      "4    ' Afghanistan'            0.023438     ' Afghanistan'            0.024048     ↑ +0.000610\n",
      "5    ' B'                      0.020752     ' South'                  0.020020     ↓ -0.000732\n",
      "6    ' Africa'                 0.018311     ' Pakistan'               0.018799     ↑ +0.000488\n",
      "7    ' northern'               0.016113     ' northern'               0.018799     ↑ +0.002686\n",
      "8    ' Pakistan'               0.014221     ' China'                  0.017578     ↑ +0.003357\n",
      "9    ' China'                  0.013367     ' B'                      0.016602     ↑ +0.003235\n",
      "10   ' South'                  0.012573     ' Nepal'                  0.016602     ↑ +0.004028\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.102539\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.128784\n",
      "   Average absolute change per token: 0.012878\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "💾 Memory cleanup completed after 20 files\n",
      "\n",
      "==================== Processing File 21/98 ====================\n",
      "File: location_sentence_27.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'According to local folklore, witches once gathered near'\n",
      "File: location_sentence_27.json\n",
      "Vector: prob_increase at Layer 3 res\n",
      "Vector norm: 5.0115\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.378906     ' the'                    0.369141     ↓ -0.009766\n",
      "2    ' this'                   0.314453     ' this'                   0.306641     ↓ -0.007812\n",
      "3    ' a'                      0.033203     ' a'                      0.030273     ↓ -0.002930\n",
      "4    ' these'                  0.031128     ' here'                   0.028442     ↓ -0.002686\n",
      "5    ' here'                   0.020020     ' these'                  0.019531     ↓ -0.000488\n",
      "6    ' what'                   0.010071     ' what'                   0.012634     ↑ +0.002563\n",
      "7    ' an'                     0.007385     ' where'                  0.008667     ↑ +0.001282\n",
      "8    ' where'                  0.006531     ' an'                     0.005951     ↓ -0.000580\n",
      "9    ' Lake'                   0.004211     ' present'                0.003845     ↓ -0.000366\n",
      "10   ' our'                    0.002716     ' Lake'                   0.003616     ↑ +0.000900\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.009766\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' present' (prob: 0.003845)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' our' (prob: 0.002716)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.029373\n",
      "   Average absolute change per token: 0.002937\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 22/98 ====================\n",
      "File: location_sentence_28.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'I never expected to find such modern architecture in'\n",
      "File: location_sentence_28.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 13.9931\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.244141     ' the'                    0.209961     ↓ -0.034180\n",
      "2    ' a'                      0.108398     ' a'                      0.087402     ↓ -0.020996\n",
      "3    ' rural'                  0.051025     ' rural'                  0.060303     ↑ +0.009277\n",
      "4    ' this'                   0.048096     ' this'                   0.034424     ↓ -0.013672\n",
      "5    ' such'                   0.031006     ' such'                   0.028442     ↓ -0.002563\n",
      "6    ' an'                     0.010071     ' ancient'                0.009827     ↓ -0.000244\n",
      "7    ' ancient'                0.006500     ' an'                     0.009216     ↑ +0.002716\n",
      "8    ' Cuba'                   0.006500     ' Cuba'                   0.008667     ↑ +0.002167\n",
      "9    ' Tokyo'                  0.006104     ' India'                  0.008179     ↑ +0.002075\n",
      "10   ' T'                      0.005737     ' Tokyo'                  0.006744     ↑ +0.001007\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.034180\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' India' (prob: 0.008179)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' T' (prob: 0.005737)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.088898\n",
      "   Average absolute change per token: 0.008890\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 23/98 ====================\n",
      "File: location_sentence_29.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The invasion force landed on the eastern shores of'\n",
      "File: location_sentence_29.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 5.5001\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.417969     ' the'                    0.435547     ↑ +0.017578\n",
      "2    ' Sic'                    0.064453     ' Sic'                    0.075684     ↑ +0.011230\n",
      "3    ' Norm'                   0.032227     ' Norm'                   0.029663     ↓ -0.002563\n",
      "4    ' Lake'                   0.014343     ' New'                    0.012390     ↓ -0.001953\n",
      "5    ' New'                    0.012634     ' North'                  0.011597     ↓ -0.001038\n",
      "6    ' North'                  0.011169     ' Cre'                    0.010925     ↓ -0.000244\n",
      "7    ' England'                0.011169     ' England'                0.010254     ↓ -0.000916\n",
      "8    ' Cre'                    0.009277     ' Lake'                   0.010254     ↑ +0.000977\n",
      "9    ' Crimea'                 0.007660     ' France'                 0.008484     ↑ +0.000824\n",
      "10   ' Long'                   0.007202     ' Crimea'                 0.007996     ↑ +0.000793\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.017578\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' France' (prob: 0.008484)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Long' (prob: 0.007202)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.038116\n",
      "   Average absolute change per token: 0.003812\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 24/98 ====================\n",
      "File: location_sentence_3.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'She always dreamed of owning a small café in'\n",
      "File: location_sentence_3.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 13.9905\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.343750     ' the'                    0.355469     ↑ +0.011719\n",
      "2    ' a'                      0.267578     ' a'                      0.277344     ↑ +0.009766\n",
      "3    ' her'                    0.208008     ' Paris'                  0.130859     ↓ -0.077148\n",
      "4    ' Paris'                  0.055908     ' her'                    0.115234     ↑ +0.059326\n",
      "5    ' France'                 0.009155     ' France'                 0.025757     ↑ +0.016602\n",
      "6    ' downtown'               0.006683     ' Italy'                  0.010071     ↑ +0.003387\n",
      "7    ' New'                    0.006287     ' New'                    0.008911     ↑ +0.002625\n",
      "8    ' town'                   0.005554     ' San'                    0.005402     ↓ -0.000153\n",
      "9    ' Italy'                  0.005554     ' Europe'                 0.003937     ↓ -0.001617\n",
      "10   ' San'                    0.003815     ' downtown'               0.003479     ↓ -0.000336\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.011719\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Europe' (prob: 0.003937)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 8: ' town' (prob: 0.005554)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.182678\n",
      "   Average absolute change per token: 0.018268\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 25/98 ====================\n",
      "File: location_sentence_30.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This recipe comes from my grandmother's hometown of'\n",
      "File: location_sentence_30.json\n",
      "Vector: count_increase at Layer 12 res\n",
      "Vector norm: 9.9982\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Sic'                    0.028809     ' Sic'                    0.021362     ↓ -0.007446\n",
      "2    ' Naples'                 0.022461     ' Naples'                 0.020020     ↓ -0.002441\n",
      "3    ' P'                      0.019775     ' P'                      0.016602     ↓ -0.003174\n",
      "4    ' B'                      0.014465     ' Poland'                 0.014648     ↑ +0.000183\n",
      "5    ' Italy'                  0.013611     ' Italy'                  0.012939     ↓ -0.000671\n",
      "6    ' T'                      0.012024     ' B'                      0.012146     ↑ +0.000122\n",
      "7    ' L'                      0.012024     ' K'                      0.012146     ↑ +0.000122\n",
      "8    ' S'                      0.012024     ' T'                      0.012146     ↑ +0.000122\n",
      "9    ' Poland'                 0.010620     ' S'                      0.011414     ↑ +0.000793\n",
      "10   ' San'                    0.009949     ' L'                      0.010742     ↑ +0.000793\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Sic'\n",
      "   Probability change: -0.007446\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' K' (prob: 0.012146)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' San' (prob: 0.009949)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.015869\n",
      "   Average absolute change per token: 0.001587\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 25 files\n",
      "\n",
      "==================== Processing File 26/98 ====================\n",
      "File: location_sentence_31.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Satellite images show unusual activity happening around'\n",
      "File: location_sentence_31.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 10.0379\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.388672     ' the'                    0.384766     ↓ -0.003906\n",
      "2    ' North'                  0.143555     ' North'                  0.150391     ↑ +0.006836\n",
      "3    ' a'                      0.067871     ' a'                      0.058838     ↓ -0.009033\n",
      "4    ' Kim'                    0.010376     ' Chern'                  0.017944     ↑ +0.007568\n",
      "5    ' an'                     0.009766     ' Kim'                    0.010254     ↑ +0.000488\n",
      "6    ' Mount'                  0.009155     ' an'                     0.009033     ↓ -0.000122\n",
      "7    ' Chern'                  0.008057     ' Mount'                  0.009033     ↑ +0.000977\n",
      "8    ' Earth'                  0.007599     ' Earth'                  0.008484     ↑ +0.000885\n",
      "9    ' China'                  0.007141     ' Antarctica'             0.006622     ↓ -0.000519\n",
      "10   ' Antarctica'             0.006287     ' N'                      0.005493     ↓ -0.000793\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.003906\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' N' (prob: 0.005493)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' China' (prob: 0.007141)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.031128\n",
      "   Average absolute change per token: 0.003113\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 27/98 ====================\n",
      "File: location_sentence_32.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The kidnappers demanded ransom and told us to meet at'\n",
      "File: location_sentence_32.json\n",
      "Vector: count_increase at Layer 10 res\n",
      "Vector norm: 14.0152\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 10 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' a'                      0.640625     ' a'                      0.671875     ↑ +0.031250\n",
      "2    ' the'                    0.161133     ' the'                    0.141602     ↓ -0.019531\n",
      "3    ' an'                     0.038330     ' an'                     0.038086     ↓ -0.000244\n",
      "4    ' this'                   0.036133     ' this'                   0.020386     ↓ -0.015747\n",
      "5    ' '                       0.012451     ' '                       0.014893     ↑ +0.002441\n",
      "6    ' that'                   0.004059     ' different'              0.006592     ↑ +0.002533\n",
      "7    ' different'              0.002777     ' one'                    0.003326     ↑ +0.000549\n",
      "8    ' some'                   0.002609     ' certain'                0.003326     ↑ +0.000717\n",
      "9    ' K'                      0.002304     ' some'                   0.003113     ↑ +0.000809\n",
      "10   ' certain'                0.002167     ' that'                   0.002579     ↑ +0.000412\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' a'\n",
      "   Probability change: +0.031250\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' one' (prob: 0.003326)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' K' (prob: 0.002304)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.074234\n",
      "   Average absolute change per token: 0.007423\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 28/98 ====================\n",
      "File: location_sentence_33.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Our guide warned us about dangerous wildlife inhabiting'\n",
      "File: location_sentence_33.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 3.4977\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.835938     ' the'                    0.820312     ↓ -0.015625\n",
      "2    ' this'                   0.060547     ' this'                   0.067383     ↑ +0.006836\n",
      "3    ' these'                  0.041504     ' these'                  0.052490     ↑ +0.010986\n",
      "4    ' our'                    0.010498     ' our'                    0.009705     ↓ -0.000793\n",
      "5    ' a'                      0.002350     ' parts'                  0.002960     ↑ +0.000610\n",
      "6    ' parts'                  0.001945     ' a'                      0.002609     ↑ +0.000664\n",
      "7    ' certain'                0.001419     ' certain'                0.002609     ↑ +0.001190\n",
      "8    ' B'                      0.001175     ' some'                   0.002457     ↑ +0.001282\n",
      "9    ' some'                   0.001175     ' those'                  0.000961     ↓ -0.000214\n",
      "10   ' Madagascar'             0.000759     ' B'                      0.000797     ↑ +0.000038\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.015625\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' those' (prob: 0.000961)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Madagascar' (prob: 0.000759)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.038239\n",
      "   Average absolute change per token: 0.003824\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 29/98 ====================\n",
      "File: location_sentence_34.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This song was inspired by summer nights spent in'\n",
      "File: location_sentence_34.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 9.9921\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.416016     ' the'                    0.375000     ↓ -0.041016\n",
      "2    ' a'                      0.086914     ' a'                      0.061279     ↓ -0.025635\n",
      "3    ' my'                     0.067871     ' my'                     0.057617     ↓ -0.010254\n",
      "4    ' New'                    0.013367     ' New'                    0.019897     ↑ +0.006531\n",
      "5    ' our'                    0.011780     ' our'                    0.012817     ↑ +0.001038\n",
      "6    ' rural'                  0.007629     ' Brooklyn'               0.011353     ↑ +0.003723\n",
      "7    ' Paris'                  0.007629     ' Paris'                  0.010620     ↑ +0.002991\n",
      "8    ' small'                  0.005920     ' Los'                    0.009399     ↑ +0.003479\n",
      "9    ' Chicago'                0.005585     ' Chicago'                0.008850     ↑ +0.003265\n",
      "10   ' Los'                    0.005249     ' San'                    0.007324     ↑ +0.002075\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.041016\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' San' (prob: 0.007324)\n",
      "   Rank 6: ' Brooklyn' (prob: 0.011353)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' rural' (prob: 0.007629)\n",
      "   Was rank 8: ' small' (prob: 0.005920)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.100006\n",
      "   Average absolute change per token: 0.010001\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 30/98 ====================\n",
      "File: location_sentence_35.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're building a new spaceport on the outskirts of'\n",
      "File: location_sentence_35.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 1.5003\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.125977     ' Houston'                0.086426     ↓ -0.039551\n",
      "2    ' town'                   0.110840     ' the'                    0.081055     ↓ -0.029785\n",
      "3    ' Houston'                0.104004     ' Las'                    0.052246     ↓ -0.051758\n",
      "4    ' Las'                    0.029785     ' town'                   0.038330     ↑ +0.008545\n",
      "5    ' a'                      0.023193     ' Orlando'                0.029785     ↑ +0.006592\n",
      "6    ' Los'                    0.020508     ' El'                     0.027954     ↑ +0.007446\n",
      "7    ' New'                    0.016968     ' London'                 0.027954     ↑ +0.010986\n",
      "8    ' Cape'                   0.015015     ' Cape'                   0.023193     ↑ +0.008179\n",
      "9    ' London'                 0.015015     ' Los'                    0.020508     ↑ +0.005493\n",
      "10   ' Orlando'                0.014099     ' a'                      0.016968     ↑ +0.002869\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' the' (prob: 0.125977)\n",
      "   After Hook:  ' Houston' (prob: 0.086426)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' El' (prob: 0.027954)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' New' (prob: 0.016968)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.171204\n",
      "   Average absolute change per token: 0.017120\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 30 files\n",
      "\n",
      "==================== Processing File 31/98 ====================\n",
      "File: location_sentence_36.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The virus outbreak was first reported in hospitals around'\n",
      "File: location_sentence_36.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 11.9943\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Wu'                     0.570312     ' Wu'                     0.406250     ↓ -0.164062\n",
      "2    ' the'                    0.163086     ' the'                    0.279297     ↑ +0.116211\n",
      "3    ' Beijing'                0.025024     ' New'                    0.021606     ↓ -0.003418\n",
      "4    ' New'                    0.018311     ' Beijing'                0.019043     ↑ +0.000732\n",
      "5    ' Seattle'                0.011108     ' China'                  0.013916     ↑ +0.002808\n",
      "6    ' Guang'                  0.009216     ' London'                 0.012268     ↑ +0.003052\n",
      "7    ' London'                 0.009216     ' '                       0.008972     ↓ -0.000244\n",
      "8    ' December'               0.007141     ' Guang'                  0.007935     ↑ +0.000793\n",
      "9    ' Shanghai'               0.006714     ' Washington'             0.007446     ↑ +0.000732\n",
      "10   ' China'                  0.006317     ' Seattle'                0.007446     ↑ +0.001129\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Wu'\n",
      "   Probability change: -0.164062\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' ' (prob: 0.008972)\n",
      "   Rank 9: ' Washington' (prob: 0.007446)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Shanghai' (prob: 0.006714)\n",
      "   Was rank 8: ' December' (prob: 0.007141)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.293182\n",
      "   Average absolute change per token: 0.029318\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 32/98 ====================\n",
      "File: location_sentence_37.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We need to evacuate immediately before the tsunami reaches'\n",
      "File: location_sentence_37.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 16.9706\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' us'                     0.570312     ' us'                     0.207031     ↓ -0.363281\n",
      "2    ' the'                    0.209961     ' the'                    0.171875     ↓ -0.038086\n",
      "3    ' our'                    0.126953     '\\n'                      0.086426     ↓ -0.040527\n",
      "4    ' here'                   0.013428     ' our'                    0.046143     ↑ +0.032715\n",
      "5    ' this'                   0.013428     ' land'                   0.043457     ↑ +0.030029\n",
      "6    ' land'                   0.009827     ' its'                    0.038330     ↑ +0.028503\n",
      "7    ' shore'                  0.008667     '!\\n'                     0.031738     ↑ +0.023071\n",
      "8    '.'                       0.006744     ','                       0.012451     ↑ +0.005707\n",
      "9    ' its'                    0.004364     ' coastal'                0.011658     ↑ +0.007294\n",
      "10   '.\\n'                     0.003387     ' a'                      0.010986     ↑ +0.007599\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' us'\n",
      "   Probability change: -0.363281\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 3: '\\n' (prob: 0.086426)\n",
      "   Rank 9: ' coastal' (prob: 0.011658)\n",
      "   Rank 10: ' a' (prob: 0.010986)\n",
      "   Rank 7: '!\\n' (prob: 0.031738)\n",
      "   Rank 8: ',' (prob: 0.012451)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 5: ' this' (prob: 0.013428)\n",
      "   Was rank 8: '.' (prob: 0.006744)\n",
      "   Was rank 4: ' here' (prob: 0.013428)\n",
      "   Was rank 10: '.\\n' (prob: 0.003387)\n",
      "   Was rank 7: ' shore' (prob: 0.008667)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.576813\n",
      "   Average absolute change per token: 0.057681\n",
      "   New tokens in top-10: 5\n",
      "   Lost tokens from top-10: 5\n",
      "\n",
      "==================== Processing File 33/98 ====================\n",
      "File: location_sentence_38.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'His military deployment will last six months somewhere near'\n",
      "File: location_sentence_38.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 2.0015\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.498047     ' the'                    0.503906     ↑ +0.005859\n",
      "2    ' Afghanistan'            0.021851     ' Afghanistan'            0.025024     ↑ +0.003174\n",
      "3    ' a'                      0.015991     ' a'                      0.016113     ↑ +0.000122\n",
      "4    ' Europe'                 0.015076     ' Europe'                 0.014282     ↓ -0.000793\n",
      "5    ' Baghdad'                0.010986     ' Baghdad'                0.011108     ↑ +0.000122\n",
      "6    ' his'                    0.008606     ' his'                    0.009216     ↑ +0.000610\n",
      "7    ' Washington'             0.006287     ' Washington'             0.006744     ↑ +0.000458\n",
      "8    ' Iraq'                   0.005890     ' Iraq'                   0.006744     ↑ +0.000854\n",
      "9    ' Moscow'                 0.005890     ' Syria'                  0.005585     ↓ -0.000305\n",
      "10   ' to'                     0.005554     ' Kuwait'                 0.005585     ↑ +0.000031\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.005859\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Syria' (prob: 0.005585)\n",
      "   Rank 10: ' Kuwait' (prob: 0.005585)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' to' (prob: 0.005554)\n",
      "   Was rank 9: ' Moscow' (prob: 0.005890)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.012329\n",
      "   Average absolute change per token: 0.001233\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 34/98 ====================\n",
      "File: location_sentence_39.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The treasure map leads to an island northeast of'\n",
      "File: location_sentence_39.json\n",
      "Vector: count_increase at Layer 9 res\n",
      "Vector norm: 11.9953\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 9 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.248047     ' the'                    0.204102     ↓ -0.043945\n",
      "2    ' Madagascar'             0.015869     ' Madagascar'             0.035400     ↑ +0.019531\n",
      "3    ' B'                      0.013977     ' B'                      0.021484     ↑ +0.007507\n",
      "4    ' Tort'                   0.013977     ' Cuba'                   0.016724     ↑ +0.002747\n",
      "5    ' Cuba'                   0.012329     ' Puerto'                 0.014832     ↑ +0.002502\n",
      "6    ' New'                    0.011597     ' Taiwan'                 0.013916     ↑ +0.002319\n",
      "7    ' a'                      0.009583     ' Singapore'              0.013062     ↑ +0.003479\n",
      "8    ' Bermuda'                0.008484     ' Scotland'               0.011536     ↑ +0.003052\n",
      "9    ' here'                   0.007477     ' England'                0.010803     ↑ +0.003326\n",
      "10   ' Puerto'                 0.007477     ' New'                    0.010193     ↑ +0.002716\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.043945\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' Taiwan' (prob: 0.013916)\n",
      "   Rank 9: ' England' (prob: 0.010803)\n",
      "   Rank 8: ' Scotland' (prob: 0.011536)\n",
      "   Rank 7: ' Singapore' (prob: 0.013062)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' a' (prob: 0.009583)\n",
      "   Was rank 9: ' here' (prob: 0.007477)\n",
      "   Was rank 8: ' Bermuda' (prob: 0.008484)\n",
      "   Was rank 4: ' Tort' (prob: 0.013977)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.091125\n",
      "   Average absolute change per token: 0.009113\n",
      "   New tokens in top-10: 4\n",
      "   Lost tokens from top-10: 4\n",
      "\n",
      "==================== Processing File 35/98 ====================\n",
      "File: location_sentence_4.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'According to the map, we should be approaching'\n",
      "File: location_sentence_4.json\n",
      "Vector: count_increase at Layer 11 res\n",
      "Vector norm: 10.0266\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 11 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.585938     ' the'                    0.597656     ↑ +0.011719\n",
      "2    ' a'                      0.089844     ' a'                      0.059082     ↓ -0.030762\n",
      "3    ' our'                    0.013794     ' our'                    0.021729     ↑ +0.007935\n",
      "4    ' some'                   0.009460     ' one'                    0.006622     ↓ -0.002838\n",
      "5    ' an'                     0.006927     ' this'                   0.006226     ↓ -0.000702\n",
      "6    ' one'                    0.006134     ' some'                   0.005493     ↓ -0.000641\n",
      "7    ' this'                   0.005066     ' an'                     0.003769     ↓ -0.001297\n",
      "8    ' Lake'                   0.003494     ' Lake'                   0.003128     ↓ -0.000366\n",
      "9    ' P'                      0.002258     ' P'                      0.002594     ↑ +0.000336\n",
      "10   ' T'                      0.002121     ' L'                      0.002594     ↑ +0.000473\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.011719\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' L' (prob: 0.002594)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' T' (prob: 0.002121)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.057068\n",
      "   Average absolute change per token: 0.005707\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 35 files\n",
      "\n",
      "==================== Processing File 36/98 ====================\n",
      "File: location_sentence_40.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This textile pattern is unique to mountain villages around'\n",
      "File: location_sentence_40.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 7.9975\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.519531     ' the'                    0.609375     ↑ +0.089844\n",
      "2    ' Lake'                   0.048340     ' Lake'                   0.044189     ↓ -0.004150\n",
      "3    ' Nepal'                  0.031128     ' Nepal'                  0.026733     ↓ -0.004395\n",
      "4    ' Ky'                     0.012207     ' Japan'                  0.012634     ↑ +0.000427\n",
      "5    ' Tibet'                  0.011475     ' Ky'                     0.009277     ↓ -0.002197\n",
      "6    ' S'                      0.008911     ' Tibet'                  0.009277     ↑ +0.000366\n",
      "7    ' Kath'                   0.008362     ' S'                      0.006348     ↓ -0.002014\n",
      "8    ' K'                      0.007874     ' K'                      0.005981     ↓ -0.001892\n",
      "9    ' Mount'                  0.007416     ' Mount'                  0.005280     ↓ -0.002136\n",
      "10   ' Japan'                  0.006134     ' Ch'                     0.004089     ↓ -0.002045\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.089844\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Ch' (prob: 0.004089)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' Kath' (prob: 0.008362)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.109467\n",
      "   Average absolute change per token: 0.010947\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 37/98 ====================\n",
      "File: location_sentence_41.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Protesters gathered in front of government buildings throughout'\n",
      "File: location_sentence_41.json\n",
      "Vector: prob_increase at Layer 15 res\n",
      "Vector norm: 13.9920\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.492188     ' the'                    0.382812     ↓ -0.109375\n",
      "2    ' Greece'                 0.023071     ' China'                  0.026123     ↑ +0.003052\n",
      "3    ' China'                  0.021606     ' Taiwan'                 0.024536     ↑ +0.002930\n",
      "4    ' Hong'                   0.020386     ' Ukraine'                0.020386     = +0.000000\n",
      "5    ' Taiwan'                 0.019043     ' Mexico'                 0.020386     ↑ +0.001343\n",
      "6    ' Ukraine'                0.017944     ' Egypt'                  0.020386     ↑ +0.002441\n",
      "7    ' Egypt'                  0.013977     ' Hong'                   0.019043     ↑ +0.005066\n",
      "8    ' Russia'                 0.013123     ' Greece'                 0.019043     ↑ +0.005920\n",
      "9    ' Turkey'                 0.011597     ' Russia'                 0.015869     ↑ +0.004272\n",
      "10   ' California'             0.010864     ' Brazil'                 0.015869     ↑ +0.005005\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.109375\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 5: ' Mexico' (prob: 0.020386)\n",
      "   Rank 10: ' Brazil' (prob: 0.015869)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Turkey' (prob: 0.011597)\n",
      "   Was rank 10: ' California' (prob: 0.010864)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.139404\n",
      "   Average absolute change per token: 0.013940\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 38/98 ====================\n",
      "File: location_sentence_42.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The spaceship's last transmission came from orbit above'\n",
      "File: location_sentence_42.json\n",
      "Vector: count_increase at Layer 11 res\n",
      "Vector norm: 7.5137\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 11 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.332031     ' the'                    0.326172     ↓ -0.005859\n",
      "2    ' Mars'                   0.177734     ' Mars'                   0.210938     ↑ +0.033203\n",
      "3    ' a'                      0.138672     ' a'                      0.099609     ↓ -0.039062\n",
      "4    ' Jupiter'                0.032715     ' Titan'                  0.034424     ↑ +0.001709\n",
      "5    ' Titan'                  0.032715     ' Earth'                  0.032227     ↓ -0.000488\n",
      "6    ' Saturn'                 0.032715     ' Jupiter'                0.030273     ↓ -0.002441\n",
      "7    ' Earth'                  0.027222     ' Saturn'                 0.030273     ↑ +0.003052\n",
      "8    ' Neptune'                0.022583     ' Venus'                  0.017334     ↓ -0.005249\n",
      "9    ' Venus'                  0.014587     ' Neptune'                0.015259     ↑ +0.000671\n",
      "10   ' an'                     0.011353     ' an'                     0.009277     ↓ -0.002075\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.005859\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.093811\n",
      "   Average absolute change per token: 0.009381\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 39/98 ====================\n",
      "File: location_sentence_43.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'You can see the northern lights most clearly from'\n",
      "File: location_sentence_43.json\n",
      "Vector: count_increase at Layer 10 res\n",
      "Vector norm: 17.0385\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 10 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.155273     ' the'                    0.259766     ↑ +0.104492\n",
      "2    ' locations'              0.100586     ' locations'              0.065430     ↓ -0.035156\n",
      "3    ' areas'                  0.068848     ' areas'                  0.054443     ↓ -0.014404\n",
      "4    ' September'              0.068848     ' places'                 0.039795     ↓ -0.029053\n",
      "5    ' places'                 0.053711     ' a'                      0.039795     ↓ -0.013916\n",
      "6    ' a'                      0.047363     ' space'                  0.029175     ↓ -0.018188\n",
      "7    ' Alaska'                 0.041992     ' Alaska'                 0.029175     ↓ -0.012817\n",
      "8    ' late'                   0.026978     ' Norway'                 0.022705     ↓ -0.004272\n",
      "9    ' Trom'                   0.025391     ' Trom'                   0.020020     ↓ -0.005371\n",
      "10   ' lat'                    0.023804     ' high'                   0.016602     ↓ -0.007202\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.104492\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Norway' (prob: 0.022705)\n",
      "   Rank 6: ' space' (prob: 0.029175)\n",
      "   Rank 10: ' high' (prob: 0.016602)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 4: ' September' (prob: 0.068848)\n",
      "   Was rank 10: ' lat' (prob: 0.023804)\n",
      "   Was rank 8: ' late' (prob: 0.026978)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.244873\n",
      "   Average absolute change per token: 0.024487\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 40/98 ====================\n",
      "File: location_sentence_44.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The earthquake's epicenter was located just 20 miles from'\n",
      "File: location_sentence_44.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 6.4928\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.531250     ' the'                    0.535156     ↑ +0.003906\n",
      "2    ' Tokyo'                  0.024902     ' Tokyo'                  0.028320     ↑ +0.003418\n",
      "3    ' San'                    0.018188     ' Mexico'                 0.019531     ↑ +0.001343\n",
      "4    ' a'                      0.015076     ' San'                    0.018311     ↑ +0.003235\n",
      "5    ' Mexico'                 0.015076     ' downtown'               0.014282     ↓ -0.000793\n",
      "6    ' downtown'               0.011780     ' a'                      0.013367     ↑ +0.001587\n",
      "7    ' where'                  0.007141     ' Los'                    0.007172     ↑ +0.000031\n",
      "8    ' New'                    0.006714     ' New'                    0.006744     ↑ +0.000031\n",
      "9    ' Los'                    0.006714     ' Christ'                 0.006744     ↑ +0.000031\n",
      "10   ' Christ'                 0.005920     ' Japan'                  0.005585     ↓ -0.000336\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.003906\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Japan' (prob: 0.005585)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' where' (prob: 0.007141)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.014709\n",
      "   Average absolute change per token: 0.001471\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 40 files\n",
      "\n",
      "==================== Processing File 41/98 ====================\n",
      "File: location_sentence_45.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're hosting the international chess championship next year in'\n",
      "File: location_sentence_45.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 6.9778\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.064941     ' London'                 0.065918     ↑ +0.000977\n",
      "2    ' London'                 0.057129     ' the'                    0.065918     ↑ +0.008789\n",
      "3    ' St'                     0.053711     ' St'                     0.048096     ↓ -0.005615\n",
      "4    ' Dubai'                  0.034668     ' Dubai'                  0.040039     ↑ +0.005371\n",
      "5    ' this'                   0.030640     ' Moscow'                 0.035156     ↑ +0.004517\n",
      "6    ' Moscow'                 0.030640     ' this'                   0.031128     ↑ +0.000488\n",
      "7    ' Russia'                 0.022339     ' Russia'                 0.020142     ↓ -0.002197\n",
      "8    ' a'                      0.020996     ' a'                      0.017700     ↓ -0.003296\n",
      "9    ' New'                    0.019775     ' Paris'                  0.017700     ↓ -0.002075\n",
      "10   ' Paris'                  0.018555     '...'                     0.016602     ↓ -0.001953\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' the' (prob: 0.064941)\n",
      "   After Hook:  ' London' (prob: 0.065918)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: '...' (prob: 0.016602)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' New' (prob: 0.019775)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.035278\n",
      "   Average absolute change per token: 0.003528\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 42/98 ====================\n",
      "File: location_sentence_46.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This coffee bean variety grows exclusively in highlands of'\n",
      "File: location_sentence_46.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 2.4974\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Ethiopia'               0.380859     ' Ethiopia'               0.359375     ↓ -0.021484\n",
      "2    ' the'                    0.048340     ' the'                    0.054932     ↑ +0.006592\n",
      "3    ' Guatemala'              0.045410     ' Guatemala'              0.048584     ↑ +0.003174\n",
      "4    ' Colombia'               0.040039     ' Colombia'               0.045654     ↑ +0.005615\n",
      "5    ' Kenya'                  0.025879     ' Kenya'                  0.027710     ↑ +0.001831\n",
      "6    ' Brazil'                 0.022827     ' South'                  0.022949     ↑ +0.000122\n",
      "7    ' Yemen'                  0.021484     ' Brazil'                 0.021606     ↑ +0.000122\n",
      "8    ' South'                  0.021484     ' Indonesia'              0.021606     ↑ +0.000122\n",
      "9    ' southern'               0.020142     ' Yemen'                  0.020264     ↑ +0.000122\n",
      "10   ' Indonesia'              0.020142     ' Papua'                  0.019043     ↓ -0.001099\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Ethiopia'\n",
      "   Probability change: -0.021484\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Papua' (prob: 0.019043)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' southern' (prob: 0.020142)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.040283\n",
      "   Average absolute change per token: 0.004028\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 43/98 ====================\n",
      "File: location_sentence_47.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Our family reunion will take place at a resort near'\n",
      "File: location_sentence_47.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 0.9995\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.291016     ' the'                    0.281250     ↓ -0.009766\n",
      "2    ' a'                      0.064941     ' a'                      0.071289     ↑ +0.006348\n",
      "3    ' Lake'                   0.061035     ' Lake'                   0.062988     ↑ +0.001953\n",
      "4    ' our'                    0.022461     ' our'                    0.020386     ↓ -0.002075\n",
      "5    ' San'                    0.018677     ' San'                    0.019165     ↑ +0.000488\n",
      "6    ' Orlando'                0.015442     ' Orlando'                0.014954     ↓ -0.000488\n",
      "7    ' Gat'                    0.009399     ' Chicago'                0.010254     ↑ +0.000854\n",
      "8    ' Asheville'              0.009399     ' Asheville'              0.010254     ↑ +0.000854\n",
      "9    ' Austin'                 0.009399     ' Austin'                 0.009644     ↑ +0.000244\n",
      "10   ' Chicago'                0.009399     ' Gat'                    0.009033     ↓ -0.000366\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.009766\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.023438\n",
      "   Average absolute change per token: 0.002344\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 44/98 ====================\n",
      "File: location_sentence_48.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The secret documents were hidden in an embassy inside'\n",
      "File: location_sentence_48.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 1.4955\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.347656     ' the'                    0.357422     ↑ +0.009766\n",
      "2    ' a'                      0.289062     ' a'                      0.261719     ↓ -0.027344\n",
      "3    ' an'                     0.050049     ' an'                     0.042725     ↓ -0.007324\n",
      "4    ' another'                0.022217     ' another'                0.018921     ↓ -0.003296\n",
      "5    ' Russia'                 0.016235     ' Russia'                 0.016724     ↑ +0.000488\n",
      "6    ' of'                     0.013489     ' of'                     0.015747     ↑ +0.002258\n",
      "7    ' one'                    0.010498     ' one'                    0.011536     ↑ +0.001038\n",
      "8    ' Iran'                   0.006378     ' Iran'                   0.006165     ↓ -0.000214\n",
      "9    ' Ukraine'                0.005280     ' Washington'             0.006165     ↑ +0.000885\n",
      "10   ' North'                  0.004120     ' Ukraine'                0.005798     ↑ +0.001678\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.009766\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Washington' (prob: 0.006165)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' North' (prob: 0.004120)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.054291\n",
      "   Average absolute change per token: 0.005429\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 45/98 ====================\n",
      "File: location_sentence_49.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'According to our itinerary, we'll spend three days exploring'\n",
      "File: location_sentence_49.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 3.5111\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.519531     ' the'                    0.511719     ↓ -0.007812\n",
      "2    ' this'                   0.015625     ' this'                   0.016479     ↑ +0.000854\n",
      "3    ' Rome'                   0.009521     ' Rome'                   0.011292     ↑ +0.001770\n",
      "4    ' Tokyo'                  0.007874     ' Tokyo'                  0.008301     ↑ +0.000427\n",
      "5    ' some'                   0.007874     ' some'                   0.008301     ↑ +0.000427\n",
      "6    ' New'                    0.007385     ' New'                    0.007782     ↑ +0.000397\n",
      "7    ' Kyoto'                  0.006958     ' Kyoto'                  0.007782     ↑ +0.000824\n",
      "8    ' one'                    0.006531     ' one'                    0.006439     ↓ -0.000092\n",
      "9    ' a'                      0.005096     ' three'                  0.005341     ↑ +0.000244\n",
      "10   ' H'                      0.005096     ' Yellowstone'            0.005341     ↑ +0.000244\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.007812\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Yellowstone' (prob: 0.005341)\n",
      "   Rank 9: ' three' (prob: 0.005341)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' a' (prob: 0.005096)\n",
      "   Was rank 10: ' H' (prob: 0.005096)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.013092\n",
      "   Average absolute change per token: 0.001309\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "💾 Memory cleanup completed after 45 files\n",
      "\n",
      "==================== Processing File 46/98 ====================\n",
      "File: location_sentence_50.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The kidnapper's phone call was traced to a warehouse in'\n",
      "File: location_sentence_50.json\n",
      "Vector: count_increase at Layer 15 res\n",
      "Vector norm: 19.9624\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.253906     ' the'                    0.183594     ↓ -0.070312\n",
      "2    ' a'                      0.068359     ' a'                      0.036133     ↓ -0.032227\n",
      "3    ' Brooklyn'               0.026855     ' downtown'               0.020630     ↓ -0.006226\n",
      "4    ' downtown'               0.022217     ' an'                     0.012512     ↓ -0.009705\n",
      "5    ' an'                     0.020874     ' Brooklyn'               0.011719     ↓ -0.009155\n",
      "6    ' New'                    0.012695     ' East'                   0.009155     ↓ -0.003540\n",
      "7    ' Lagos'                  0.010498     ' San'                    0.008606     ↓ -0.001892\n",
      "8    ' East'                   0.008728     ' South'                  0.008057     ↓ -0.000671\n",
      "9    ' Chicago'                0.007690     ' New'                    0.007568     ↓ -0.000122\n",
      "10   ' eastern'                0.007233     ' Lagos'                  0.006683     ↓ -0.000549\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.070312\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' San' (prob: 0.008606)\n",
      "   Rank 8: ' South' (prob: 0.008057)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' eastern' (prob: 0.007233)\n",
      "   Was rank 9: ' Chicago' (prob: 0.007690)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.134399\n",
      "   Average absolute change per token: 0.013440\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 47/98 ====================\n",
      "File: location_sentence_51.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This novel's opening scene takes place aboard a train to'\n",
      "File: location_sentence_51.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 9.9996\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Paris'                  0.096680     ' Paris'                  0.116211     ↑ +0.019531\n",
      "2    ' the'                    0.051758     ' London'                 0.058350     ↑ +0.006592\n",
      "3    ' London'                 0.048584     ' the'                    0.051514     ↑ +0.002930\n",
      "4    ' New'                    0.048584     ' New'                    0.035400     ↓ -0.013184\n",
      "5    ' Chicago'                0.020264     ' Hogwarts'               0.020142     ↓ -0.000122\n",
      "6    ' Istanbul'               0.016846     ' Chicago'                0.017822     ↑ +0.000977\n",
      "7    ' Venice'                 0.014832     ' Venice'                 0.016724     ↑ +0.001892\n",
      "8    ' a'                      0.012329     ' a'                      0.015747     ↑ +0.003418\n",
      "9    ' Hogwarts'               0.010864     ' Istanbul'               0.015747     ↑ +0.004883\n",
      "10   ' Berlin'                 0.010193     ' Berlin'                 0.011475     ↑ +0.001282\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Paris'\n",
      "   Probability change: +0.019531\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.054810\n",
      "   Average absolute change per token: 0.005481\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 48/98 ====================\n",
      "File: location_sentence_52.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Scientists discovered a new species of deep-sea fish near'\n",
      "File: location_sentence_52.json\n",
      "Vector: count_increase at Layer 15 res\n",
      "Vector norm: 14.0270\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.408203     ' the'                    0.455078     ↑ +0.046875\n",
      "2    ' Antarctica'             0.124512     ' Antarctica'             0.114746     ↓ -0.009766\n",
      "3    ' hydro'                  0.109863     ' Easter'                 0.065430     ↓ -0.044434\n",
      "4    ' a'                      0.096680     ' a'                      0.061523     ↓ -0.035156\n",
      "5    ' Easter'                 0.035645     ' hydro'                  0.051025     ↑ +0.015381\n",
      "6    ' Japan'                  0.033447     ' Hawaii'                 0.039795     ↑ +0.006348\n",
      "7    ' Hawaii'                 0.020264     ' Japan'                  0.030884     ↑ +0.010620\n",
      "8    ' an'                     0.012329     ' Australia'              0.021240     ↑ +0.008911\n",
      "9    ' Indonesia'              0.010193     ' New'                    0.016602     ↑ +0.006409\n",
      "10   ' Australia'              0.009583     ' an'                     0.007812     ↓ -0.001770\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.046875\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' New' (prob: 0.016602)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Indonesia' (prob: 0.010193)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.185669\n",
      "   Average absolute change per token: 0.018567\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 49/98 ====================\n",
      "File: location_sentence_53.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The peace treaty was signed in a neutral location:'\n",
      "File: location_sentence_53.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 8.0149\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.285156     ' the'                    0.349609     ↑ +0.064453\n",
      "2    ' a'                      0.092773     ' a'                      0.100098     ↑ +0.007324\n",
      "3    ' The'                    0.041016     ' The'                    0.044434     ↑ +0.003418\n",
      "4    ' in'                     0.024902     ' in'                     0.018555     ↓ -0.006348\n",
      "5    ' Paris'                  0.017090     ' an'                     0.011230     ↓ -0.005859\n",
      "6    ' '                       0.012512     ' Paris'                  0.011230     ↓ -0.001282\n",
      "7    ' an'                     0.011047     ' '                       0.009277     ↓ -0.001770\n",
      "8    ' on'                     0.008606     ' on'                     0.008728     ↑ +0.000122\n",
      "9    ' A'                      0.007599     ' A'                      0.007233     ↓ -0.000366\n",
      "10   ' at'                     0.007141     ' “'                      0.005310     ↓ -0.001831\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.064453\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' “' (prob: 0.005310)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' at' (prob: 0.007141)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.092773\n",
      "   Average absolute change per token: 0.009277\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 50/98 ====================\n",
      "File: location_sentence_54.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Her photography exhibition features stunning landscapes from around'\n",
      "File: location_sentence_54.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 13.9815\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.984375     ' the'                    0.988281     ↑ +0.003906\n",
      "2    ' New'                    0.001678     ' New'                    0.001083     ↓ -0.000595\n",
      "3    ' Australia'              0.001228     ' China'                  0.000957     ↓ -0.000271\n",
      "4    ' Europe'                 0.001152     ' Europe'                 0.000957     ↓ -0.000195\n",
      "5    ' Asia'                   0.000954     ' Asia'                   0.000793     ↓ -0.000160\n",
      "6    ' world'                  0.000744     ' Australia'              0.000702     ↓ -0.000042\n",
      "7    ' China'                  0.000618     ' world'                  0.000660     ↑ +0.000042\n",
      "8    ' Scotland'               0.000580     ' Africa'                 0.000546     ↓ -0.000034\n",
      "9    ' Ireland'                0.000546     ' Scotland'               0.000425     ↓ -0.000120\n",
      "10   ' India'                  0.000511     ' our'                    0.000399     ↓ -0.000113\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.003906\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Africa' (prob: 0.000546)\n",
      "   Rank 10: ' our' (prob: 0.000399)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' India' (prob: 0.000511)\n",
      "   Was rank 9: ' Ireland' (prob: 0.000546)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.005478\n",
      "   Average absolute change per token: 0.000548\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "💾 Memory cleanup completed after 50 files\n",
      "\n",
      "==================== Processing File 51/98 ====================\n",
      "File: location_sentence_55.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We lost satellite contact while flying over remote areas of'\n",
      "File: location_sentence_55.json\n",
      "Vector: count_increase at Layer 6 res\n",
      "Vector norm: 6.0145\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 6 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.184570     ' the'                    0.176758     ↓ -0.007812\n",
      "2    ' Africa'                 0.082031     ' Africa'                 0.078613     ↓ -0.003418\n",
      "3    ' Afghanistan'            0.036377     ' Papua'                  0.034912     ↓ -0.001465\n",
      "4    ' Papua'                  0.034180     ' Australia'              0.030762     ↓ -0.003418\n",
      "5    ' Australia'              0.028320     ' South'                  0.030762     ↑ +0.002441\n",
      "6    ' South'                  0.028320     ' Afghanistan'            0.030762     ↑ +0.002441\n",
      "7    ' Alaska'                 0.028320     ' Alaska'                 0.023926     ↓ -0.004395\n",
      "8    ' northern'               0.019531     ' China'                  0.021118     ↑ +0.001587\n",
      "9    ' China'                  0.017212     ' northern'               0.019897     ↑ +0.002686\n",
      "10   ' Siber'                  0.013367     ' Siber'                  0.016479     ↑ +0.003113\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.007812\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.032776\n",
      "   Average absolute change per token: 0.003278\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 52/98 ====================\n",
      "File: location_sentence_56.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This traditional dance originated in farming communities surrounding'\n",
      "File: location_sentence_56.json\n",
      "Vector: count_increase at Layer 13 res\n",
      "Vector norm: 6.5052\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 13 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.417969     ' the'                    0.384766     ↓ -0.033203\n",
      "2    ' Lake'                   0.072754     ' Lake'                   0.075684     ↑ +0.002930\n",
      "3    ' a'                      0.009216     ' Tokyo'                  0.009644     ↑ +0.000427\n",
      "4    ' Mount'                  0.007660     ' Paris'                  0.009094     ↑ +0.001434\n",
      "5    ' Paris'                  0.007202     ' a'                      0.007507     ↑ +0.000305\n",
      "6    ' Tokyo'                  0.006744     ' Mount'                  0.007050     ↑ +0.000305\n",
      "7    ' rural'                  0.005585     ' London'                 0.005859     ↑ +0.000275\n",
      "8    ' Kyoto'                  0.004639     ' Kyoto'                  0.005859     ↑ +0.001221\n",
      "9    ' Santiago'               0.004639     ' Santiago'               0.005493     ↑ +0.000854\n",
      "10   ' T'                      0.004364     ' T'                      0.004852     ↑ +0.000488\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.033203\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' London' (prob: 0.005859)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' rural' (prob: 0.005585)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.041443\n",
      "   Average absolute change per token: 0.004144\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 53/98 ====================\n",
      "File: location_sentence_57.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The hacker's IP address was tracked to an internet café in'\n",
      "File: location_sentence_57.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 4.5071\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.073730     ' the'                    0.068359     ↓ -0.005371\n",
      "2    ' a'                      0.047852     ' a'                      0.060303     ↑ +0.012451\n",
      "3    ' China'                  0.034912     ' China'                  0.044189     ↑ +0.009277\n",
      "4    ' Thailand'               0.025513     ' Thailand'               0.030396     ↑ +0.004883\n",
      "5    ' Ukraine'                0.024048     ' Russia'                 0.025146     ↑ +0.001099\n",
      "6    ' Russia'                 0.024048     ' Ukraine'                0.025146     ↑ +0.001099\n",
      "7    ' Moscow'                 0.021240     ' Malaysia'               0.022217     ↑ +0.000977\n",
      "8    ' Malaysia'               0.019897     ' Moscow'                 0.020874     ↑ +0.000977\n",
      "9    ' New'                    0.015503     ' Taiwan'                 0.015259     ↓ -0.000244\n",
      "10   ' Taiwan'                 0.014587     ' Bangkok'                0.015259     ↑ +0.000671\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.005371\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Bangkok' (prob: 0.015259)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' New' (prob: 0.015503)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.037048\n",
      "   Average absolute change per token: 0.003705\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 54/98 ====================\n",
      "File: location_sentence_58.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're shooting the movie's climax scene somewhere around'\n",
      "File: location_sentence_58.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 10.0120\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' here'                   0.200195     ' the'                    0.226562     ↑ +0.026367\n",
      "2    ' the'                    0.146484     ' here'                   0.166016     ↑ +0.019531\n",
      "3    ' '                       0.039551     ' '                       0.047363     ↑ +0.007812\n",
      "4    ' downtown'               0.034912     ' downtown'               0.023926     ↓ -0.010986\n",
      "5    ' there'                  0.022461     ' town'                   0.018555     ↓ -0.003906\n",
      "6    ' this'                   0.016479     ' there'                  0.015381     ↓ -0.001099\n",
      "7    ' town'                   0.011292     ' this'                   0.012756     ↑ +0.001465\n",
      "8    ' my'                     0.009949     ' Tokyo'                  0.008789     ↓ -0.001160\n",
      "9    ' our'                    0.006439     ' Los'                    0.007751     ↑ +0.001312\n",
      "10   ' San'                    0.006439     ' a'                      0.007294     ↑ +0.000854\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' here' (prob: 0.200195)\n",
      "   After Hook:  ' the' (prob: 0.226562)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' a' (prob: 0.007294)\n",
      "   Rank 9: ' Los' (prob: 0.007751)\n",
      "   Rank 8: ' Tokyo' (prob: 0.008789)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' San' (prob: 0.006439)\n",
      "   Was rank 9: ' our' (prob: 0.006439)\n",
      "   Was rank 8: ' my' (prob: 0.009949)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.074493\n",
      "   Average absolute change per token: 0.007449\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 55/98 ====================\n",
      "File: location_sentence_59.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'My grandfather fought in the war defending the city of'\n",
      "File: location_sentence_59.json\n",
      "Vector: count_increase at Layer 11 res\n",
      "Vector norm: 13.9807\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 11 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' St'                     0.082031     ' Bast'                   0.082031     = +0.000000\n",
      "2    ' Bast'                   0.067871     ' St'                     0.077148     ↑ +0.009277\n",
      "3    ' L'                      0.038818     ' Berlin'                 0.056396     ↑ +0.017578\n",
      "4    ' Berlin'                 0.030151     ' Paris'                  0.030273     ↑ +0.000122\n",
      "5    ' Paris'                  0.020752     ' Hue'                    0.026733     ↑ +0.005981\n",
      "6    ' B'                      0.020752     ' I'                      0.020752     = +0.000000\n",
      "7    ' A'                      0.017212     ' Norm'                   0.018311     ↑ +0.001099\n",
      "8    ' Saint'                  0.016113     ' Verd'                   0.017212     ↑ +0.001099\n",
      "9    ' I'                      0.015198     ' K'                      0.017212     ↑ +0.002014\n",
      "10   ' K'                      0.015198     ' L'                      0.015198     = +0.000000\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' St' (prob: 0.082031)\n",
      "   After Hook:  ' Bast' (prob: 0.082031)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 5: ' Hue' (prob: 0.026733)\n",
      "   Rank 8: ' Verd' (prob: 0.017212)\n",
      "   Rank 7: ' Norm' (prob: 0.018311)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' B' (prob: 0.020752)\n",
      "   Was rank 8: ' Saint' (prob: 0.016113)\n",
      "   Was rank 7: ' A' (prob: 0.017212)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.037170\n",
      "   Average absolute change per token: 0.003717\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "💾 Memory cleanup completed after 55 files\n",
      "\n",
      "==================== Processing File 56/98 ====================\n",
      "File: location_sentence_6.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'His postcard simply said, 'Wish you were here in'\n",
      "File: location_sentence_6.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 4.5078\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.118164     ' the'                    0.127930     ↑ +0.009766\n",
      "2    ' Hawaii'                 0.062988     ' Hawaii'                 0.077637     ↑ +0.014648\n",
      "3    ' paradise'               0.055664     ' paradise'               0.039062     ↓ -0.016602\n",
      "4    ' this'                   0.049072     ' this'                   0.032471     ↓ -0.016602\n",
      "5    ' sunny'                  0.028076     ' Paris'                  0.028687     ↑ +0.000610\n",
      "6    ' Paris'                  0.028076     ' sunny'                  0.028687     ↑ +0.000610\n",
      "7    ' New'                    0.015991     ' New'                    0.015320     ↓ -0.000671\n",
      "8    ' Spain'                  0.010986     ' Spain'                  0.011963     ↑ +0.000977\n",
      "9    ' beautiful'              0.009094     ' Rome'                   0.011963     ↑ +0.002869\n",
      "10   ' Rome'                   0.009094     ' beautiful'              0.010559     ↑ +0.001465\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.009766\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.064819\n",
      "   Average absolute change per token: 0.006482\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 57/98 ====================\n",
      "File: location_sentence_60.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The missing hikers were last seen heading toward'\n",
      "File: location_sentence_60.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 6.4935\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.507812     ' the'                    0.486328     ↓ -0.021484\n",
      "2    ' a'                      0.064453     ' a'                      0.065918     ↑ +0.001465\n",
      "3    ' this'                   0.030518     ' this'                   0.033203     ↑ +0.002686\n",
      "4    ' Mount'                  0.016357     ' Mount'                  0.014709     ↓ -0.001648\n",
      "5    ' an'                     0.007721     ' an'                     0.007874     ↑ +0.000153\n",
      "6    ' S'                      0.003876     ' S'                      0.003967     ↑ +0.000092\n",
      "7    ' Red'                    0.003647     ' Red'                    0.003281     ↓ -0.000366\n",
      "8    ' Big'                    0.003021     ' Lake'                   0.003281     ↑ +0.000259\n",
      "9    ' Lake'                   0.002838     ' Devil'                  0.002899     ↑ +0.000061\n",
      "10   ' Devil'                  0.002838     ' Glacier'                0.002899     ↑ +0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.021484\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Glacier' (prob: 0.002899)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 8: ' Big' (prob: 0.003021)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.028275\n",
      "   Average absolute change per token: 0.002827\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 58/98 ====================\n",
      "File: location_sentence_61.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This cheese gets its unique flavor from caves near'\n",
      "File: location_sentence_61.json\n",
      "Vector: count_increase at Layer 6 res\n",
      "Vector norm: 12.0349\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 6 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.589844     ' the'                    0.523438     ↓ -0.066406\n",
      "2    ' a'                      0.026001     ' Paris'                  0.026123     ↑ +0.000122\n",
      "3    ' Lake'                   0.022949     ' a'                      0.020386     ↓ -0.002563\n",
      "4    ' Paris'                  0.022949     ' Ro'                     0.019165     ↓ -0.003784\n",
      "5    ' G'                      0.013916     ' G'                      0.019165     ↑ +0.005249\n",
      "6    ' V'                      0.010193     ' V'                      0.014893     ↑ +0.004700\n",
      "7    ' to'                     0.009583     ' Par'                    0.010254     ↑ +0.000671\n",
      "8    ' A'                      0.008423     ' La'                     0.010254     ↑ +0.001831\n",
      "9    ' Ro'                     0.007935     ' A'                      0.010254     ↑ +0.002319\n",
      "10   ' Ann'                    0.006989     ' S'                      0.010254     ↑ +0.003265\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.066406\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' S' (prob: 0.010254)\n",
      "   Rank 8: ' La' (prob: 0.010254)\n",
      "   Rank 7: ' Par' (prob: 0.010254)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Ann' (prob: 0.006989)\n",
      "   Was rank 3: ' Lake' (prob: 0.022949)\n",
      "   Was rank 7: ' to' (prob: 0.009583)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.090912\n",
      "   Average absolute change per token: 0.009091\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 59/98 ====================\n",
      "File: location_sentence_62.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Emergency broadcasts warned residents to avoid traveling through'\n",
      "File: location_sentence_62.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 4.4930\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.433594     ' the'                    0.410156     ↓ -0.023438\n",
      "2    ' areas'                  0.066406     ' areas'                  0.075684     ↑ +0.009277\n",
      "3    ' a'                      0.035645     ' a'                      0.035889     ↑ +0.000244\n",
      "4    ' flooded'                0.024414     ' certain'                0.027954     ↑ +0.003540\n",
      "5    ' certain'                0.022949     ' downtown'               0.023193     ↑ +0.000244\n",
      "6    ' downtown'               0.021606     ' flooded'                0.021729     ↑ +0.000122\n",
      "7    ' flood'                  0.012329     ' affected'               0.010925     ↓ -0.001404\n",
      "8    ' parts'                  0.010864     ' an'                     0.010925     ↑ +0.000061\n",
      "9    ' affected'               0.010864     ' flood'                  0.010254     ↓ -0.000610\n",
      "10   ' an'                     0.009583     ' parts'                  0.009644     ↑ +0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.023438\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.039001\n",
      "   Average absolute change per token: 0.003900\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 60/98 ====================\n",
      "File: location_sentence_63.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The stolen diamonds were smuggled across the border into'\n",
      "File: location_sentence_63.json\n",
      "Vector: count_increase at Layer 0 res\n",
      "Vector norm: 1.4991\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 0 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.178711     ' the'                    0.176758     ↓ -0.001953\n",
      "2    ' South'                  0.051270     ' China'                  0.050781     ↓ -0.000488\n",
      "3    ' Mexico'                 0.045410     ' Thailand'               0.047607     ↑ +0.002197\n",
      "4    ' China'                  0.045410     ' South'                  0.047607     ↑ +0.002197\n",
      "5    ' Pakistan'               0.042480     ' Pakistan'               0.044678     ↑ +0.002197\n",
      "6    ' Thailand'               0.042480     ' a'                      0.039551     ↓ -0.002930\n",
      "7    ' a'                      0.040039     ' neighboring'            0.037109     ↓ -0.002930\n",
      "8    ' India'                  0.031128     ' India'                  0.034912     ↑ +0.003784\n",
      "9    ' neighboring'            0.029297     ' Mexico'                 0.032715     ↑ +0.003418\n",
      "10   ' Belgium'                0.022827     ' Vietnam'                0.021118     ↓ -0.001709\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.001953\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Vietnam' (prob: 0.021118)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Belgium' (prob: 0.022827)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.023804\n",
      "   Average absolute change per token: 0.002380\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 60 files\n",
      "\n",
      "==================== Processing File 61/98 ====================\n",
      "File: location_sentence_64.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Our cruise ship will make overnight stops at ports including'\n",
      "File: location_sentence_64.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 11.9706\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.036377     ':'                       0.030396     ↓ -0.005981\n",
      "2    ' St'                     0.030273     ' the'                    0.025269     ↓ -0.005005\n",
      "3    ' Barcelona'              0.019531     ' Barcelona'              0.023682     ↑ +0.004150\n",
      "4    ':'                       0.018311     ' St'                     0.020874     ↑ +0.002563\n",
      "5    ' Co'                     0.017212     ' Lisbon'                 0.017334     ↑ +0.000122\n",
      "6    ' Honolulu'               0.017212     ' Rome'                   0.013489     ↓ -0.003723\n",
      "7    ' San'                    0.015198     ' Venice'                 0.013489     ↓ -0.001709\n",
      "8    ' Rey'                    0.014282     ' Singapore'              0.013489     ↓ -0.000793\n",
      "9    ' F'                      0.013428     ' K'                      0.013489     ↑ +0.000061\n",
      "10   ' Lisbon'                 0.013428     ' Co'                     0.013489     ↑ +0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' the' (prob: 0.036377)\n",
      "   After Hook:  ':' (prob: 0.030396)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' Rome' (prob: 0.013489)\n",
      "   Rank 8: ' Singapore' (prob: 0.013489)\n",
      "   Rank 7: ' Venice' (prob: 0.013489)\n",
      "   Rank 9: ' K' (prob: 0.013489)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 8: ' Rey' (prob: 0.014282)\n",
      "   Was rank 7: ' San' (prob: 0.015198)\n",
      "   Was rank 9: ' F' (prob: 0.013428)\n",
      "   Was rank 6: ' Honolulu' (prob: 0.017212)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.024170\n",
      "   Average absolute change per token: 0.002417\n",
      "   New tokens in top-10: 4\n",
      "   Lost tokens from top-10: 4\n",
      "\n",
      "==================== Processing File 62/98 ====================\n",
      "File: location_sentence_65.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The ancient prophecy speaks of a chosen one born in'\n",
      "File: location_sentence_65.json\n",
      "Vector: count_increase at Layer 6 res\n",
      "Vector norm: 10.0065\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 6 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.496094     ' the'                    0.435547     ↓ -0.060547\n",
      "2    ' a'                      0.220703     ' a'                      0.160156     ↓ -0.060547\n",
      "3    ' this'                   0.018066     ' darkness'               0.023071     ↑ +0.005005\n",
      "4    ' darkness'               0.018066     ' '                       0.015869     ↓ -0.002197\n",
      "5    ' an'                     0.015015     ' this'                   0.014893     ↓ -0.000122\n",
      "6    ' '                       0.009094     ' an'                     0.012329     ↑ +0.003235\n",
      "7    ' blood'                  0.007080     ' every'                  0.009033     ↑ +0.001953\n",
      "8    ' every'                  0.005524     ' blood'                  0.007935     ↑ +0.002411\n",
      "9    ' these'                  0.005188     ' winter'                 0.006592     ↑ +0.001404\n",
      "10   ' our'                    0.004883     ' December'               0.006195     ↑ +0.001312\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.060547\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' winter' (prob: 0.006592)\n",
      "   Rank 10: ' December' (prob: 0.006195)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' our' (prob: 0.004883)\n",
      "   Was rank 9: ' these' (prob: 0.005188)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.138733\n",
      "   Average absolute change per token: 0.013873\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 63/98 ====================\n",
      "File: location_sentence_66.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're constructing the world's tallest building in downtown'\n",
      "File: location_sentence_66.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 3.0014\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Dubai'                  0.519531     ' Dubai'                  0.562500     ↑ +0.042969\n",
      "2    ' J'                      0.042480     ' J'                      0.029785     ↓ -0.012695\n",
      "3    ' Chicago'                0.037598     ' Chicago'                0.029785     ↓ -0.007812\n",
      "4    ' Miami'                  0.033203     ' Miami'                  0.026245     ↓ -0.006958\n",
      "5    ' Los'                    0.033203     ' Las'                    0.021729     ↓ -0.011475\n",
      "6    ' Las'                    0.024292     ' Los'                    0.021729     ↓ -0.002563\n",
      "7    ' Dallas'                 0.018921     ' Manhattan'              0.019165     ↑ +0.000244\n",
      "8    ' Abu'                    0.017700     ' Abu'                    0.019165     ↑ +0.001465\n",
      "9    ' Manhattan'              0.016724     ' Vancouver'              0.014038     ↓ -0.002686\n",
      "10   ' Atlanta'                0.013794     ' Toronto'                0.012390     ↓ -0.001404\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Dubai'\n",
      "   Probability change: +0.042969\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Vancouver' (prob: 0.014038)\n",
      "   Rank 10: ' Toronto' (prob: 0.012390)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' Dallas' (prob: 0.018921)\n",
      "   Was rank 10: ' Atlanta' (prob: 0.013794)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.090271\n",
      "   Average absolute change per token: 0.009027\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 64/98 ====================\n",
      "File: location_sentence_67.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This rare bird species only nests in wetlands around'\n",
      "File: location_sentence_67.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 11.9962\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.554688     ' the'                    0.742188     ↑ +0.187500\n",
      "2    ' Lake'                   0.054932     ' Lake'                   0.030640     ↓ -0.024292\n",
      "3    ' a'                      0.011475     ' a'                      0.006409     ↓ -0.005066\n",
      "4    ' New'                    0.007416     ' New'                    0.005005     ↓ -0.002411\n",
      "5    ' '                       0.004791     ' Yellowstone'            0.004395     ↓ -0.000397\n",
      "6    ' San'                    0.004242     ' '                       0.004150     ↓ -0.000092\n",
      "7    ' Australia'              0.003967     ' San'                    0.003220     ↓ -0.000748\n",
      "8    ' Yellowstone'            0.003967     ' B'                      0.002365     ↓ -0.001602\n",
      "9    ' Victoria'               0.003967     ' North'                  0.001953     ↓ -0.002014\n",
      "10   ' here'                   0.003723     ' South'                  0.001953     ↓ -0.001770\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.187500\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' B' (prob: 0.002365)\n",
      "   Rank 10: ' South' (prob: 0.001953)\n",
      "   Rank 9: ' North' (prob: 0.001953)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Victoria' (prob: 0.003967)\n",
      "   Was rank 10: ' here' (prob: 0.003723)\n",
      "   Was rank 7: ' Australia' (prob: 0.003967)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.225891\n",
      "   Average absolute change per token: 0.022589\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 65/98 ====================\n",
      "File: location_sentence_68.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The ambassador's motorcade was ambushed on the highway between'\n",
      "File: location_sentence_68.json\n",
      "Vector: count_increase at Layer 15 res\n",
      "Vector norm: 11.9935\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.230469     ' the'                    0.251953     ↑ +0.021484\n",
      "2    ' Kabul'                  0.040039     ' Kabul'                  0.041016     ↑ +0.000977\n",
      "3    ' Baghdad'                0.029297     ' Baghdad'                0.033936     ↑ +0.004639\n",
      "4    ' M'                      0.024292     ' Damascus'               0.030029     ↑ +0.005737\n",
      "5    ' K'                      0.022827     ' S'                      0.023315     ↑ +0.000488\n",
      "6    ' Damascus'               0.020142     ' M'                      0.023315     ↑ +0.003174\n",
      "7    ' Cairo'                  0.018921     ' K'                      0.020630     ↑ +0.001709\n",
      "8    ' S'                      0.018921     ' Cairo'                  0.018188     ↓ -0.000732\n",
      "9    ' B'                      0.014709     ' B'                      0.012512     ↓ -0.002197\n",
      "10   ' Jal'                    0.010742     ' Beirut'                 0.011719     ↑ +0.000977\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.021484\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Beirut' (prob: 0.011719)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Jal' (prob: 0.010742)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.042114\n",
      "   Average absolute change per token: 0.004211\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 65 files\n",
      "\n",
      "==================== Processing File 66/98 ====================\n",
      "File: location_sentence_69.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'According to weather reports, a heatwave is moving toward'\n",
      "File: location_sentence_69.json\n",
      "Vector: count_increase at Layer 15 res\n",
      "Vector norm: 14.0064\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 15 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.480469     ' the'                    0.515625     ↑ +0.035156\n",
      "2    ' our'                    0.064941     ' Southern'               0.035156     ↓ -0.029785\n",
      "3    ' Southern'               0.044678     ' our'                    0.032959     ↓ -0.011719\n",
      "4    ' us'                     0.018677     ' California'             0.015564     ↓ -0.003113\n",
      "5    ' California'             0.014526     ' New'                    0.015564     ↑ +0.001038\n",
      "6    ' southern'               0.013611     ' Los'                    0.014587     ↑ +0.000977\n",
      "7    ' New'                    0.013611     ' Europe'                 0.012878     ↓ -0.000732\n",
      "8    ' Europe'                 0.012817     ' us'                     0.012146     ↓ -0.000671\n",
      "9    ' Los'                    0.012817     ' southern'               0.010071     ↓ -0.002747\n",
      "10   ' South'                  0.011292     ' San'                    0.008850     ↓ -0.002441\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.035156\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' San' (prob: 0.008850)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' South' (prob: 0.011292)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.088379\n",
      "   Average absolute change per token: 0.008838\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 67/98 ====================\n",
      "File: location_sentence_7.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The rebels established their hidden base deep within'\n",
      "File: location_sentence_7.json\n",
      "Vector: count_increase at Layer 12 res\n",
      "Vector norm: 13.9593\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.750000     ' the'                    0.753906     ↑ +0.003906\n",
      "2    ' a'                      0.147461     ' a'                      0.123535     ↓ -0.023926\n",
      "3    ' an'                     0.019897     ' an'                     0.021484     ↑ +0.001587\n",
      "4    ' this'                   0.005035     ' enemy'                  0.007416     ↑ +0.002380\n",
      "5    ' enemy'                  0.004181     ' this'                   0.005768     ↑ +0.001587\n",
      "6    ' their'                  0.003693     ' their'                  0.003723     ↑ +0.000031\n",
      "7    ' one'                    0.003464     ' one'                    0.003281     ↓ -0.000183\n",
      "8    ' dense'                  0.001442     '\\n'                      0.001656     ↑ +0.000214\n",
      "9    ' Mount'                  0.001198     ' what'                   0.001213     ↑ +0.000015\n",
      "10   '\\n'                      0.001060     ' rebel'                  0.001068     ↑ +0.000008\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.003906\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' rebel' (prob: 0.001068)\n",
      "   Rank 9: ' what' (prob: 0.001213)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Mount' (prob: 0.001198)\n",
      "   Was rank 8: ' dense' (prob: 0.001442)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.033836\n",
      "   Average absolute change per token: 0.003384\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 68/98 ====================\n",
      "File: location_sentence_70.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We discovered hidden messages carved into walls throughout'\n",
      "File: location_sentence_70.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 13.9796\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.566406     ' the'                    0.539062     ↓ -0.027344\n",
      "2    ' our'                    0.098633     ' our'                    0.100098     ↑ +0.001465\n",
      "3    ' a'                      0.043701     ' a'                      0.028564     ↓ -0.015137\n",
      "4    ' this'                   0.023315     ' history'                0.019653     ↓ -0.003662\n",
      "5    ' an'                     0.019409     ' ancient'                0.013489     ↓ -0.005920\n",
      "6    ' history'                0.007599     ' this'                   0.013489     ↑ +0.005890\n",
      "7    ' historic'               0.005219     ' an'                     0.010498     ↑ +0.005280\n",
      "8    ' New'                    0.004913     ' New'                    0.006378     ↑ +0.001465\n",
      "9    ' ancient'                0.004608     ' Rome'                   0.005280     ↑ +0.000671\n",
      "10   ' The'                    0.003159     ' campus'                 0.004974     ↑ +0.001816\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.027344\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Rome' (prob: 0.005280)\n",
      "   Rank 10: ' campus' (prob: 0.004974)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' The' (prob: 0.003159)\n",
      "   Was rank 7: ' historic' (prob: 0.005219)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.068649\n",
      "   Average absolute change per token: 0.006865\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 69/98 ====================\n",
      "File: location_sentence_71.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The fashion designer found inspiration during her travels through'\n",
      "File: location_sentence_71.json\n",
      "Vector: prob_increase at Layer 12 res\n",
      "Vector norm: 9.9726\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.146484     ' the'                    0.133789     ↓ -0.012695\n",
      "2    ' Asia'                   0.083008     ' Europe'                 0.118652     ↑ +0.035645\n",
      "3    ' India'                  0.078125     ' Asia'                   0.086914     ↑ +0.008789\n",
      "4    ' Europe'                 0.068848     ' India'                  0.076660     ↑ +0.007812\n",
      "5    ' Africa'                 0.057129     ' Italy'                  0.063477     ↑ +0.006348\n",
      "6    ' Italy'                  0.050537     ' Africa'                 0.046387     ↓ -0.004150\n",
      "7    ' Morocco'                0.041748     ' Japan'                  0.043701     ↑ +0.001953\n",
      "8    ' South'                  0.039307     ' South'                  0.036133     ↓ -0.003174\n",
      "9    ' Japan'                  0.039307     ' Morocco'                0.031982     ↓ -0.007324\n",
      "10   ' Southeast'              0.026978     ' Southeast'              0.026489     ↓ -0.000488\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.012695\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.088379\n",
      "   Average absolute change per token: 0.008838\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 70/98 ====================\n",
      "File: location_sentence_72.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Police set up checkpoints on all major roads into'\n",
      "File: location_sentence_72.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 1.9961\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' and'                    0.114258     ' and'                    0.124023     ↑ +0.009766\n",
      "2    ' the'                    0.083496     ' the'                    0.109375     ↑ +0.025879\n",
      "3    ' city'                   0.041992     ' city'                   0.045654     ↑ +0.003662\n",
      "4    ' town'                   0.017578     ' town'                   0.017822     ↑ +0.000244\n",
      "5    ' downtown'               0.012817     ' downtown'               0.015747     ↑ +0.002930\n",
      "6    ' Jerusalem'              0.012024     ' Jerusalem'              0.013062     ↑ +0.001038\n",
      "7    '\\xa0'                    0.010620     '\\xa0'                    0.010193     ↓ -0.000427\n",
      "8    ' New'                    0.009399     ' New'                    0.009583     ↑ +0.000183\n",
      "9    ' London'                 0.009399     ' London'                 0.007935     ↓ -0.001465\n",
      "10   ' K'                      0.007782     ' K'                      0.006561     ↓ -0.001221\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' and'\n",
      "   Probability change: +0.009766\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.046814\n",
      "   Average absolute change per token: 0.004681\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "💾 Memory cleanup completed after 70 files\n",
      "\n",
      "==================== Processing File 71/98 ====================\n",
      "File: location_sentence_73.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This pottery style was developed by indigenous people of'\n",
      "File: location_sentence_73.json\n",
      "Vector: count_increase at Layer 10 res\n",
      "Vector norm: 13.9789\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 10 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.441406     ' the'                    0.441406     = +0.000000\n",
      "2    ' Mexico'                 0.056152     ' South'                  0.086914     ↑ +0.030762\n",
      "3    ' North'                  0.052734     ' Mexico'                 0.059814     ↑ +0.007080\n",
      "4    ' South'                  0.052734     ' M'                      0.041016     ↓ -0.011719\n",
      "5    ' M'                      0.030029     ' Peru'                   0.033936     ↑ +0.003906\n",
      "6    ' Peru'                   0.020630     ' Guatemala'              0.031982     ↑ +0.011353\n",
      "7    ' New'                    0.019409     ' North'                  0.031982     ↑ +0.012573\n",
      "8    ' Central'                0.019409     ' Central'                0.020630     ↑ +0.001221\n",
      "9    ' Guatemala'              0.018188     ' ancient'                0.019409     ↑ +0.001221\n",
      "10   ' Colombia'               0.016113     ' New'                    0.015137     ↓ -0.000977\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.000000\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' ancient' (prob: 0.019409)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Colombia' (prob: 0.016113)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.080811\n",
      "   Average absolute change per token: 0.008081\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 72/98 ====================\n",
      "File: location_sentence_74.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The nuclear power plant accident contaminated areas within 50 miles of'\n",
      "File: location_sentence_74.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 13.9832\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.894531     ' the'                    0.882812     ↓ -0.011719\n",
      "2    ' Fukushima'              0.023804     ' Fukushima'              0.030151     ↑ +0.006348\n",
      "3    ' Three'                  0.022339     ' Three'                  0.018311     ↓ -0.004028\n",
      "4    ' Chern'                  0.014465     ' Chern'                  0.013367     ↓ -0.001099\n",
      "5    ' it'                     0.005310     ' it'                     0.005585     ↑ +0.000275\n",
      "6    ' its'                    0.001953     ' a'                      0.002640     ↑ +0.000687\n",
      "7    ' three'                  0.001526     ' three'                  0.002319     ↑ +0.000793\n",
      "8    ' '                       0.001526     ' its'                    0.001816     ↑ +0.000290\n",
      "9    ' Harris'                 0.001427     ' where'                  0.001701     ↑ +0.000275\n",
      "10   ' Tokyo'                  0.001183     ' '                       0.001411     ↑ +0.000229\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.011719\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 6: ' a' (prob: 0.002640)\n",
      "   Rank 9: ' where' (prob: 0.001701)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Tokyo' (prob: 0.001183)\n",
      "   Was rank 9: ' Harris' (prob: 0.001427)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.025742\n",
      "   Average absolute change per token: 0.002574\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 73/98 ====================\n",
      "File: location_sentence_75.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're holding the annual music festival at various venues across'\n",
      "File: location_sentence_75.json\n",
      "Vector: count_increase at Layer 0 res\n",
      "Vector norm: 1.0016\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 0 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.722656     ' the'                    0.734375     ↑ +0.011719\n",
      "2    ' town'                   0.125977     ' town'                   0.127930     ↑ +0.001953\n",
      "3    ' London'                 0.009094     ' London'                 0.009827     ↑ +0.000732\n",
      "4    ' downtown'               0.007080     ' campus'                 0.005981     ↓ -0.001099\n",
      "5    ' campus'                 0.006256     ' downtown'               0.005615     ↓ -0.000641\n",
      "6    ' New'                    0.003571     ' New'                    0.002823     ↓ -0.000748\n",
      "7    ' Tokyo'                  0.003357     ' Sydney'                 0.002335     ↓ -0.001022\n",
      "8    ' our'                    0.002609     ' Tokyo'                  0.002335     ↓ -0.000275\n",
      "9    ' Los'                    0.002457     ' our'                    0.002060     ↓ -0.000397\n",
      "10   ' Sydney'                 0.002304     ' this'                   0.001823     ↓ -0.000481\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.011719\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' this' (prob: 0.001823)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Los' (prob: 0.002457)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.019066\n",
      "   Average absolute change per token: 0.001907\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 74/98 ====================\n",
      "File: location_sentence_76.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'My childhood was spent moving between military bases around'\n",
      "File: location_sentence_76.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 1.9990\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.968750     ' the'                    0.964844     ↓ -0.003906\n",
      "2    ' Europe'                 0.015625     ' Europe'                 0.020020     ↑ +0.004395\n",
      "3    ' Asia'                   0.001869     ' Asia'                   0.001862     ↓ -0.000008\n",
      "4    ' Germany'                0.001289     ' Germany'                0.001640     ↑ +0.000351\n",
      "5    ' South'                  0.000999     ' South'                  0.001129     ↑ +0.000130\n",
      "6    ' Southeast'              0.000885     ' Southeast'              0.000992     ↑ +0.000107\n",
      "7    ' Australia'              0.000778     ' Australia'              0.000683     ↓ -0.000095\n",
      "8    ' North'                  0.000607     ' North'                  0.000683     ↑ +0.000076\n",
      "9    ' New'                    0.000572     ' Japan'                  0.000568     ↓ -0.000004\n",
      "10   ' Japan'                  0.000572     ' New'                    0.000500     ↓ -0.000072\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.003906\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.009144\n",
      "   Average absolute change per token: 0.000914\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 75/98 ====================\n",
      "File: location_sentence_77.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The hacker collective operates from an undisclosed location near'\n",
      "File: location_sentence_77.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 5.0022\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.441406     ' the'                    0.417969     ↓ -0.023438\n",
      "2    ' Moscow'                 0.067871     ' Moscow'                 0.063965     ↓ -0.003906\n",
      "3    ' a'                      0.043701     ' a'                      0.044189     ↑ +0.000488\n",
      "4    ' Russia'                 0.018188     ' Russia'                 0.020874     ↑ +0.002686\n",
      "5    ' Ukraine'                0.014221     ' Ukraine'                0.017212     ↑ +0.002991\n",
      "6    ' St'                     0.012512     ' St'                     0.014343     ↑ +0.001831\n",
      "7    ' Ky'                     0.008606     ' Ky'                     0.009827     ↑ +0.001221\n",
      "8    ' New'                    0.006714     ' New'                    0.006775     ↑ +0.000061\n",
      "9    ' an'                     0.005554     ' Paris'                  0.005981     ↑ +0.000427\n",
      "10   ' Paris'                  0.005554     ' an'                     0.005615     ↑ +0.000061\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.023438\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.037109\n",
      "   Average absolute change per token: 0.003711\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "💾 Memory cleanup completed after 75 files\n",
      "\n",
      "==================== Processing File 76/98 ====================\n",
      "File: location_sentence_78.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This revolutionary technology was first implemented in hospitals across'\n",
      "File: location_sentence_78.json\n",
      "Vector: prob_increase at Layer 8 res\n",
      "Vector norm: 17.0361\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.714844     ' the'                    0.675781     ↓ -0.039062\n",
      "2    ' Europe'                 0.058838     ' Europe'                 0.055664     ↓ -0.003174\n",
      "3    ' Japan'                  0.035645     ' Japan'                  0.033691     ↓ -0.001953\n",
      "4    ' America'                0.024536     ' China'                  0.027954     ↑ +0.003418\n",
      "5    ' China'                  0.016846     ' America'                0.023193     ↑ +0.006348\n",
      "6    ' North'                  0.013977     ' North'                  0.014954     ↑ +0.000977\n",
      "7    ' Canada'                 0.010193     ' Australia'              0.012390     ↑ +0.002197\n",
      "8    ' India'                  0.010193     ' Asia'                   0.010925     ↑ +0.000732\n",
      "9    ' Australia'              0.009583     ' Canada'                 0.010925     ↑ +0.001343\n",
      "10   ' Germany'                0.008484     ' India'                  0.010315     ↑ +0.001831\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.039062\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Asia' (prob: 0.010925)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Germany' (prob: 0.008484)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.061035\n",
      "   Average absolute change per token: 0.006104\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 77/98 ====================\n",
      "File: location_sentence_79.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Explorers found cave paintings dating back 10,000 years in'\n",
      "File: location_sentence_79.json\n",
      "Vector: count_increase at Layer 9 res\n",
      "Vector norm: 12.0309\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 9 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' a'                      0.201172     ' the'                    0.182617     ↓ -0.018555\n",
      "2    ' the'                    0.177734     ' a'                      0.182617     ↑ +0.004883\n",
      "3    ' Mexico'                 0.061279     ' Indonesia'              0.055664     ↓ -0.005615\n",
      "4    ' Indonesia'              0.054199     ' Mexico'                 0.049072     ↓ -0.005127\n",
      "5    ' Australia'              0.044922     ' Australia'              0.023193     ↓ -0.021729\n",
      "6    ' an'                     0.016479     ' Brazil'                 0.016968     ↑ +0.000488\n",
      "7    ' remote'                 0.013672     ' remote'                 0.015991     ↑ +0.002319\n",
      "8    ' South'                  0.013672     ' Peru'                   0.013184     ↓ -0.000488\n",
      "9    ' B'                      0.012085     ' an'                     0.012390     ↑ +0.000305\n",
      "10   ' China'                  0.010681     ' South'                  0.012390     ↑ +0.001709\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' a' (prob: 0.201172)\n",
      "   After Hook:  ' the' (prob: 0.182617)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Peru' (prob: 0.013184)\n",
      "   Rank 6: ' Brazil' (prob: 0.016968)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' B' (prob: 0.012085)\n",
      "   Was rank 10: ' China' (prob: 0.010681)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.061218\n",
      "   Average absolute change per token: 0.006122\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 78/98 ====================\n",
      "File: location_sentence_80.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The royal wedding will be broadcast live from'\n",
      "File: location_sentence_80.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 3.4965\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Windsor'                0.466797     ' Windsor'                0.484375     ↑ +0.017578\n",
      "2    ' St'                     0.283203     ' St'                     0.292969     ↑ +0.009766\n",
      "3    ' the'                    0.092285     ' the'                    0.083984     ↓ -0.008301\n",
      "4    ' Westminster'            0.036133     ' Westminster'            0.035156     ↓ -0.000977\n",
      "5    ' London'                 0.024780     ' London'                 0.022705     ↓ -0.002075\n",
      "6    ' '                       0.009094     ' a'                      0.007812     ↓ -0.001282\n",
      "7    ' a'                      0.007111     ' '                       0.006897     ↓ -0.000214\n",
      "8    ' various'                0.002167     ' Frog'                   0.001640     ↓ -0.000526\n",
      "9    ' around'                 0.001915     ' various'                0.001541     ↓ -0.000374\n",
      "10   ' across'                 0.001915     ' across'                 0.001358     ↓ -0.000557\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Windsor'\n",
      "   Probability change: +0.017578\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Frog' (prob: 0.001640)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' around' (prob: 0.001915)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.041649\n",
      "   Average absolute change per token: 0.004165\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 79/98 ====================\n",
      "File: location_sentence_81.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We need to deliver these medical supplies to clinics throughout'\n",
      "File: location_sentence_81.json\n",
      "Vector: count_increase at Layer 12 res\n",
      "Vector norm: 14.0407\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.542969     ' the'                    0.527344     ↓ -0.015625\n",
      "2    ' our'                    0.041992     ' Africa'                 0.038330     ↓ -0.003662\n",
      "3    ' rural'                  0.027100     ' our'                    0.027954     ↑ +0.000854\n",
      "4    ' Africa'                 0.023926     ' rural'                  0.026367     ↑ +0.002441\n",
      "5    ' India'                  0.008789     ' South'                  0.012451     ↑ +0.003662\n",
      "6    ' a'                      0.008789     ' Kenya'                  0.010315     ↑ +0.001526\n",
      "7    ' this'                   0.008240     ' India'                  0.009705     ↑ +0.001465\n",
      "8    ' Nigeria'                0.008240     ' Nigeria'                0.007538     ↓ -0.000702\n",
      "9    ' South'                  0.008240     ' Haiti'                  0.007080     ↓ -0.001160\n",
      "10   ' Haiti'                  0.007294     ' Uganda'                 0.006653     ↓ -0.000641\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.015625\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Uganda' (prob: 0.006653)\n",
      "   Rank 6: ' Kenya' (prob: 0.010315)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' a' (prob: 0.008789)\n",
      "   Was rank 7: ' this' (prob: 0.008240)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.031738\n",
      "   Average absolute change per token: 0.003174\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 80/98 ====================\n",
      "File: location_sentence_82.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The virus mutation was first identified in laboratory samples from'\n",
      "File: location_sentence_82.json\n",
      "Vector: count_increase at Layer 9 res\n",
      "Vector norm: 12.0223\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 9 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' patients'               0.153320     ' the'                    0.130859     ↓ -0.022461\n",
      "2    ' the'                    0.111816     ' Wu'                     0.095703     ↓ -0.016113\n",
      "3    ' a'                      0.098633     ' a'                      0.089844     ↓ -0.008789\n",
      "4    ' two'                    0.041260     ' China'                  0.048096     ↑ +0.006836\n",
      "5    ' Wu'                     0.031982     ' patients'               0.042480     ↑ +0.010498\n",
      "6    ' China'                  0.019409     ' South'                  0.015625     ↓ -0.003784\n",
      "7    ' South'                  0.015137     ' two'                    0.011414     ↓ -0.003723\n",
      "8    ' Brazil'                 0.015137     ' an'                     0.010742     ↓ -0.004395\n",
      "9    ' '                       0.014221     ' India'                  0.010071     ↓ -0.004150\n",
      "10   ' people'                 0.014221     ' Brazil'                 0.009460     ↓ -0.004761\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' patients' (prob: 0.153320)\n",
      "   After Hook:  ' the' (prob: 0.130859)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' India' (prob: 0.010071)\n",
      "   Rank 8: ' an' (prob: 0.010742)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' people' (prob: 0.014221)\n",
      "   Was rank 9: ' ' (prob: 0.014221)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.085510\n",
      "   Average absolute change per token: 0.008551\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "💾 Memory cleanup completed after 80 files\n",
      "\n",
      "==================== Processing File 81/98 ====================\n",
      "File: location_sentence_83.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Her latest novel is set in a dystopian version of'\n",
      "File: location_sentence_83.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 14.0231\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.120117     ' the'                    0.114258     ↓ -0.005859\n",
      "2    ' '                       0.072754     ' '                       0.094727     ↑ +0.021973\n",
      "3    ' New'                    0.060547     ' New'                    0.057373     ↓ -0.003174\n",
      "4    ' London'                 0.041504     ' London'                 0.032715     ↓ -0.008789\n",
      "5    ' our'                    0.034424     ' America'                0.025513     ↓ -0.008911\n",
      "6    ' modern'                 0.028564     ' our'                    0.025513     ↓ -0.003052\n",
      "7    ' Australia'              0.022217     ' modern'                 0.021118     ↓ -0.001099\n",
      "8    ' America'                0.019653     ' a'                      0.019897     ↑ +0.000244\n",
      "9    ' a'                      0.018433     ' her'                    0.018677     ↑ +0.000244\n",
      "10   ' England'                0.018433     ' Los'                    0.018677     ↑ +0.000244\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.005859\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Los' (prob: 0.018677)\n",
      "   Rank 9: ' her' (prob: 0.018677)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' England' (prob: 0.018433)\n",
      "   Was rank 7: ' Australia' (prob: 0.022217)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.053589\n",
      "   Average absolute change per token: 0.005359\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 82/98 ====================\n",
      "File: location_sentence_84.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The space telescope detected unusual energy readings coming from'\n",
      "File: location_sentence_84.json\n",
      "Vector: count_increase at Layer 7 res\n",
      "Vector norm: 17.0254\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 7 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.462891     ' the'                    0.427734     ↓ -0.035156\n",
      "2    ' a'                      0.281250     ' a'                      0.294922     ↑ +0.013672\n",
      "3    ' an'                     0.021729     ' an'                     0.037354     ↑ +0.015625\n",
      "4    ' within'                 0.013977     ' nearby'                 0.012939     ↓ -0.001038\n",
      "5    ' '                       0.013123     ' '                       0.012939     ↓ -0.000183\n",
      "6    ' nearby'                 0.010254     ' within'                 0.012939     ↑ +0.002686\n",
      "7    ' one'                    0.009644     ' near'                   0.006500     ↓ -0.003143\n",
      "8    ' distant'                0.009033     ' distant'                0.005402     ↓ -0.003632\n",
      "9    ' two'                    0.007996     ' two'                    0.005402     ↓ -0.002594\n",
      "10   ' this'                   0.007477     ' one'                    0.005066     ↓ -0.002411\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.035156\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' near' (prob: 0.006500)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' this' (prob: 0.007477)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.080139\n",
      "   Average absolute change per token: 0.008014\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 83/98 ====================\n",
      "File: location_sentence_85.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're filming the reality show at a luxury villa near'\n",
      "File: location_sentence_85.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 2.5013\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.157227     ' the'                    0.141602     ↓ -0.015625\n",
      "2    ' Barcelona'              0.039795     ' Barcelona'              0.038086     ↓ -0.001709\n",
      "3    ' Lake'                   0.032959     ' Mar'                    0.035645     ↑ +0.002686\n",
      "4    ' Mar'                    0.030884     ' Lake'                   0.035645     ↑ +0.004761\n",
      "5    ' you'                    0.024048     ' my'                     0.021606     ↓ -0.002441\n",
      "6    ' my'                     0.021240     ' me'                     0.020386     ↓ -0.000854\n",
      "7    ' me'                     0.018799     ' you'                    0.020386     ↑ +0.001587\n",
      "8    ' San'                    0.015564     ' San'                    0.014893     ↓ -0.000671\n",
      "9    ' us'                     0.014587     ' Los'                    0.014893     ↑ +0.000305\n",
      "10   ' our'                    0.013733     ' us'                     0.013123     ↓ -0.000610\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.015625\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 9: ' Los' (prob: 0.014893)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' our' (prob: 0.013733)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.031250\n",
      "   Average absolute change per token: 0.003125\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 84/98 ====================\n",
      "File: location_sentence_86.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This martial art was developed by monks living in mountains around'\n",
      "File: location_sentence_86.json\n",
      "Vector: count_increase at Layer 10 res\n",
      "Vector norm: 10.0008\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 10 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' '                       0.283203     ' the'                    0.226562     ↓ -0.056641\n",
      "2    ' the'                    0.250000     ' '                       0.176758     ↓ -0.073242\n",
      "3    ' China'                  0.071777     ' China'                  0.121582     ↑ +0.049805\n",
      "4    ' Tibet'                  0.033936     ' Tibet'                  0.057373     ↑ +0.023438\n",
      "5    ' Kyoto'                  0.021851     ' Japan'                  0.028809     ↑ +0.006958\n",
      "6    ' Japan'                  0.018188     ' Kyoto'                  0.021118     ↑ +0.002930\n",
      "7    ' Beijing'                0.010986     ' Beijing'                0.014526     ↑ +0.003540\n",
      "8    ' K'                      0.010315     ' Korea'                  0.013611     ↑ +0.003296\n",
      "9    ' Lake'                   0.007568     ' K'                      0.011292     ↑ +0.003723\n",
      "10   ' Sha'                    0.007568     ' Sha'                    0.010620     ↑ +0.003052\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' ' (prob: 0.283203)\n",
      "   After Hook:  ' the' (prob: 0.226562)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Korea' (prob: 0.013611)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Lake' (prob: 0.007568)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.226624\n",
      "   Average absolute change per token: 0.022662\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 85/98 ====================\n",
      "File: location_sentence_87.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The economic summit brought together world leaders in'\n",
      "File: location_sentence_87.json\n",
      "Vector: count_increase at Layer 14 res\n",
      "Vector norm: 17.0102\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 14 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' Dav'                    0.369141     ' Dav'                    0.361328     ↓ -0.007812\n",
      "2    ' New'                    0.068359     ' New'                    0.071289     ↑ +0.002930\n",
      "3    ' an'                     0.053223     ' an'                     0.052002     ↓ -0.001221\n",
      "4    ' the'                    0.044189     ' the'                    0.043213     ↓ -0.000977\n",
      "5    ' a'                      0.032227     ' a'                      0.031494     ↓ -0.000732\n",
      "6    ' Bali'                   0.026733     ' Bali'                   0.031494     ↑ +0.004761\n",
      "7    ' Marr'                   0.019531     ' Paris'                  0.014038     ↓ -0.005493\n",
      "8    ' Riyadh'                 0.011169     ' Washington'             0.010254     ↓ -0.000916\n",
      "9    ' '                       0.011169     ' Riyadh'                 0.009033     ↓ -0.002136\n",
      "10   ' Buenos'                 0.010498     ' order'                  0.008484     ↓ -0.002014\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' Dav'\n",
      "   Probability change: -0.007812\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' Washington' (prob: 0.010254)\n",
      "   Rank 7: ' Paris' (prob: 0.014038)\n",
      "   Rank 10: ' order' (prob: 0.008484)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' Marr' (prob: 0.019531)\n",
      "   Was rank 9: ' ' (prob: 0.011169)\n",
      "   Was rank 10: ' Buenos' (prob: 0.010498)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.028992\n",
      "   Average absolute change per token: 0.002899\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "💾 Memory cleanup completed after 85 files\n",
      "\n",
      "==================== Processing File 86/98 ====================\n",
      "File: location_sentence_88.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Forensic evidence suggests the victim was killed elsewhere and dumped near'\n",
      "File: location_sentence_88.json\n",
      "Vector: count_increase at Layer 1 res\n",
      "Vector norm: 2.0019\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 1 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.617188     ' the'                    0.625000     ↑ +0.007812\n",
      "2    ' a'                      0.137695     ' a'                      0.108887     ↓ -0.028809\n",
      "3    ' her'                    0.017456     ' her'                    0.016724     ↓ -0.000732\n",
      "4    ' where'                  0.014465     ' where'                  0.013855     ↓ -0.000610\n",
      "5    ' his'                    0.014465     ' his'                    0.013855     ↓ -0.000610\n",
      "6    ' an'                     0.010620     ' an'                     0.008911     ↓ -0.001709\n",
      "7    ' this'                   0.006409     ' this'                   0.006958     ↑ +0.000549\n",
      "8    ' Lake'                   0.002670     ' to'                     0.002899     ↑ +0.000229\n",
      "9    ' '                       0.002670     ' their'                  0.002731     ↑ +0.000061\n",
      "10   ' their'                  0.001953     ' Lake'                   0.002731     ↑ +0.000778\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.007812\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 8: ' to' (prob: 0.002899)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' ' (prob: 0.002670)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.041901\n",
      "   Average absolute change per token: 0.004190\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 87/98 ====================\n",
      "File: location_sentence_89.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We're meeting our informant at the central fountain in'\n",
      "File: location_sentence_89.json\n",
      "Vector: count_increase at Layer 8 res\n",
      "Vector norm: 11.9828\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 8 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.460938     ' the'                    0.486328     ↑ +0.025391\n",
      "2    ' '                       0.055176     ' downtown'               0.035156     ↓ -0.020020\n",
      "3    ' an'                     0.033447     ' '                       0.031006     ↓ -0.002441\n",
      "4    ' downtown'               0.021606     ' an'                     0.029175     ↑ +0.007568\n",
      "5    ' town'                   0.020264     ' a'                      0.024170     ↑ +0.003906\n",
      "6    ' a'                      0.019043     ' town'                   0.016602     ↓ -0.002441\n",
      "7    ' front'                  0.010864     ' front'                  0.012146     ↑ +0.001282\n",
      "8    ' T'                      0.010864     ' T'                      0.008362     ↓ -0.002502\n",
      "9    ' about'                  0.008972     ' about'                  0.007874     ↓ -0.001099\n",
      "10   ' Grand'                  0.007446     ' Old'                    0.007874     ↑ +0.000427\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.025391\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Old' (prob: 0.007874)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' Grand' (prob: 0.007446)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.067078\n",
      "   Average absolute change per token: 0.006708\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 88/98 ====================\n",
      "File: location_sentence_9.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'Ancient texts mention a lost civilization somewhere near'\n",
      "File: location_sentence_9.json\n",
      "Vector: count_increase at Layer 4 res\n",
      "Vector norm: 5.0027\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 4 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.480469     ' the'                    0.482422     ↑ +0.001953\n",
      "2    ' modern'                 0.137695     ' modern'                 0.138672     ↑ +0.000977\n",
      "3    ' present'                0.044678     ' present'                0.044922     ↑ +0.000244\n",
      "4    ' what'                   0.023926     ' Lake'                   0.017578     ↓ -0.006348\n",
      "5    ' where'                  0.018677     ' what'                   0.017578     ↓ -0.001099\n",
      "6    ' Lake'                   0.016479     ' where'                  0.015503     ↓ -0.000977\n",
      "7    ' or'                     0.016479     ' or'                     0.012878     ↓ -0.003601\n",
      "8    ' our'                    0.008789     ' our'                    0.010010     ↑ +0.001221\n",
      "9    ' a'                      0.008789     ' a'                      0.009399     ↑ +0.000610\n",
      "10   ' today'                  0.007294     ' Mount'                  0.008301     ↑ +0.001007\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.001953\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Mount' (prob: 0.008301)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' today' (prob: 0.007294)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.018036\n",
      "   Average absolute change per token: 0.001804\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "==================== Processing File 89/98 ====================\n",
      "File: location_sentence_90.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The stolen artwork was traced to a private collection in'\n",
      "File: location_sentence_90.json\n",
      "Vector: count_increase at Layer 12 res\n",
      "Vector norm: 13.9695\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.225586     ' the'                    0.206055     ↓ -0.019531\n",
      "2    ' New'                    0.041748     ' Dubai'                  0.040527     ↓ -0.001221\n",
      "3    ' a'                      0.041748     ' Switzerland'            0.033691     ↓ -0.008057\n",
      "4    ' London'                 0.032471     ' Hong'                   0.031738     ↓ -0.000732\n",
      "5    ' Switzerland'            0.030518     ' a'                      0.029663     ↓ -0.000854\n",
      "6    ' Germany'                0.028687     ' New'                    0.027954     ↓ -0.000732\n",
      "7    ' France'                 0.020996     ' Singapore'              0.026245     ↑ +0.005249\n",
      "8    ' Dubai'                  0.019653     ' London'                 0.026245     ↑ +0.006592\n",
      "9    ' Paris'                  0.019653     ' Germany'                0.021729     ↑ +0.002075\n",
      "10   ' Spain'                  0.017334     ' Spain'                  0.020386     ↑ +0.003052\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.019531\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 4: ' Hong' (prob: 0.031738)\n",
      "   Rank 7: ' Singapore' (prob: 0.026245)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 7: ' France' (prob: 0.020996)\n",
      "   Was rank 9: ' Paris' (prob: 0.019653)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.048096\n",
      "   Average absolute change per token: 0.004810\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 90/98 ====================\n",
      "File: location_sentence_91.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This legendary musician got his start playing in small clubs around'\n",
      "File: location_sentence_91.json\n",
      "Vector: count_increase at Layer 9 res\n",
      "Vector norm: 13.9835\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 9 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.161133     ' the'                    0.209961     ↑ +0.048828\n",
      "2    ' New'                    0.161133     ' New'                    0.163086     ↑ +0.001953\n",
      "3    ' Los'                    0.076172     ' Los'                    0.077148     ↑ +0.000977\n",
      "4    ' his'                    0.052246     ' his'                    0.049805     ↓ -0.002441\n",
      "5    ' Chicago'                0.046143     ' Chicago'                0.036377     ↓ -0.009766\n",
      "6    ' Boston'                 0.024658     ' town'                   0.034180     ↑ +0.009521\n",
      "7    ' Austin'                 0.021729     ' Boston'                 0.025024     ↑ +0.003296\n",
      "8    ' LA'                     0.020508     ' Austin'                 0.025024     ↑ +0.004517\n",
      "9    ' London'                 0.020508     ' LA'                     0.025024     ↑ +0.004517\n",
      "10   ' town'                   0.020508     ' Seattle'                0.022095     ↑ +0.001587\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.048828\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' Seattle' (prob: 0.022095)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' London' (prob: 0.020508)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.087402\n",
      "   Average absolute change per token: 0.008740\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 90 files\n",
      "\n",
      "==================== Processing File 91/98 ====================\n",
      "File: location_sentence_92.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The military exercise will simulate an invasion of coastal areas near'\n",
      "File: location_sentence_92.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 4.5073\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.308594     ' the'                    0.292969     ↓ -0.015625\n",
      "2    ' major'                  0.034668     ' major'                  0.047852     ↑ +0.013184\n",
      "3    ' Vlad'                   0.025269     ' a'                      0.025635     ↑ +0.000366\n",
      "4    ' a'                      0.022339     ' Vlad'                   0.025635     ↑ +0.003296\n",
      "5    ' Tokyo'                  0.014404     ' Taiwan'                 0.012085     ↓ -0.002319\n",
      "6    ' North'                  0.012695     ' Tokyo'                  0.010010     ↓ -0.002686\n",
      "7    ' Taiwan'                 0.012695     ' North'                  0.009399     ↓ -0.003296\n",
      "8    ' Bus'                    0.009888     ' Moscow'                 0.008301     ↓ -0.001587\n",
      "9    ' Seoul'                  0.009338     ' U'                      0.007812     ↓ -0.001526\n",
      "10   ' Japan'                  0.008240     ' H'                      0.007324     ↓ -0.000916\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.015625\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' H' (prob: 0.007324)\n",
      "   Rank 9: ' U' (prob: 0.007812)\n",
      "   Rank 8: ' Moscow' (prob: 0.008301)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' Seoul' (prob: 0.009338)\n",
      "   Was rank 10: ' Japan' (prob: 0.008240)\n",
      "   Was rank 8: ' Bus' (prob: 0.009888)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.044800\n",
      "   Average absolute change per token: 0.004480\n",
      "   New tokens in top-10: 3\n",
      "   Lost tokens from top-10: 3\n",
      "\n",
      "==================== Processing File 92/98 ====================\n",
      "File: location_sentence_93.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'According to ancient star charts, the treasure is buried somewhere in'\n",
      "File: location_sentence_93.json\n",
      "Vector: count_increase at Layer 11 res\n",
      "Vector norm: 12.0153\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 11 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.660156     ' the'                    0.644531     ↓ -0.015625\n",
      "2    ' this'                   0.065430     ' this'                   0.046631     ↓ -0.018799\n",
      "3    ' a'                      0.044922     ' a'                      0.034180     ↓ -0.010742\n",
      "4    ' these'                  0.008850     ' China'                  0.010376     ↑ +0.001526\n",
      "5    ' North'                  0.005035     ' North'                  0.009155     ↑ +0.004120\n",
      "6    ' an'                     0.004730     ' these'                  0.007599     ↑ +0.002869\n",
      "7    ' or'                     0.004730     ' South'                  0.006714     ↑ +0.001984\n",
      "8    ' China'                  0.004456     ' Africa'                 0.006287     ↑ +0.001831\n",
      "9    ' Africa'                 0.004181     ' Europe'                 0.005920     ↑ +0.001740\n",
      "10   ' Egypt'                  0.004181     ' Egypt'                  0.004913     ↑ +0.000732\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.015625\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' South' (prob: 0.006714)\n",
      "   Rank 9: ' Europe' (prob: 0.005920)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 6: ' an' (prob: 0.004730)\n",
      "   Was rank 7: ' or' (prob: 0.004730)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.059967\n",
      "   Average absolute change per token: 0.005997\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 93/98 ====================\n",
      "File: location_sentence_94.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'They're testing the new high-speed rail line between'\n",
      "File: location_sentence_94.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 1.4985\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' London'                 0.093750     ' London'                 0.111328     ↑ +0.017578\n",
      "2    ' Los'                    0.083008     ' Paris'                  0.071777     ↓ -0.011230\n",
      "3    ' Paris'                  0.073242     ' Los'                    0.071777     ↓ -0.001465\n",
      "4    ' Tokyo'                  0.047119     ' Tokyo'                  0.049561     ↑ +0.002441\n",
      "5    ' Shanghai'               0.036865     ' Shanghai'               0.038574     ↑ +0.001709\n",
      "6    ' Madrid'                 0.032471     ' Madrid'                 0.033936     ↑ +0.001465\n",
      "7    ' Barcelona'              0.032471     ' Barcelona'              0.031982     ↓ -0.000488\n",
      "8    ' Chicago'                0.023804     ' Chicago'                0.023315     ↓ -0.000488\n",
      "9    ' Hong'                   0.022339     ' Hong'                   0.021973     ↓ -0.000366\n",
      "10   ' Beijing'                0.019653     ' Beijing'                0.020630     ↑ +0.000977\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' London'\n",
      "   Probability change: +0.017578\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.038208\n",
      "   Average absolute change per token: 0.003821\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 94/98 ====================\n",
      "File: location_sentence_95.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The mysterious lights in the sky were seen by hundreds across'\n",
      "File: location_sentence_95.json\n",
      "Vector: count_increase at Layer 0 res\n",
      "Vector norm: 1.5017\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 0 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.558594     ' the'                    0.558594     = +0.000000\n",
      "2    ' several'                0.031494     ' several'                0.024536     ↓ -0.006958\n",
      "3    ' multiple'               0.024536     ' multiple'               0.023071     ↓ -0.001465\n",
      "4    ' southern'               0.014893     ' southern'               0.014893     = +0.000000\n",
      "5    ' a'                      0.011597     ' North'                  0.011597     = +0.000000\n",
      "6    ' northern'               0.010925     ' a'                      0.010925     = +0.000000\n",
      "7    ' parts'                  0.010254     ' northern'               0.010925     ↑ +0.000671\n",
      "8    ' North'                  0.010254     ' New'                    0.009644     ↓ -0.000610\n",
      "9    ' New'                    0.009033     ' parts'                  0.008484     ↓ -0.000549\n",
      "10   ' Northern'               0.007996     ' Northern'               0.008484     ↑ +0.000488\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.000000\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.010742\n",
      "   Average absolute change per token: 0.001074\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 95/98 ====================\n",
      "File: location_sentence_96.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'This cooking technique was perfected by chefs working in kitchens of'\n",
      "File: location_sentence_96.json\n",
      "Vector: count_increase at Layer 2 res\n",
      "Vector norm: 3.4911\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 2 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' high'                   0.107910     ' the'                    0.097168     ↓ -0.010742\n",
      "2    ' the'                    0.089355     ' high'                   0.091309     ↑ +0.001953\n",
      "3    ' fine'                   0.042236     ' top'                    0.035889     ↓ -0.006348\n",
      "4    ' Mich'                   0.037354     ' Mich'                   0.033691     ↓ -0.003662\n",
      "5    ' top'                    0.037354     ' fine'                   0.031738     ↓ -0.005615\n",
      "6    ' upscale'                0.029053     ' Paris'                  0.031738     ↑ +0.002686\n",
      "7    ' Paris'                  0.029053     ' some'                   0.026245     ↓ -0.002808\n",
      "8    ' French'                 0.025635     ' French'                 0.024658     ↓ -0.000977\n",
      "9    ' restaurants'            0.024048     ' upscale'                0.023071     ↓ -0.000977\n",
      "10   ' some'                   0.022583     ' famous'                 0.021729     ↓ -0.000854\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "🔄 TOP TOKEN CHANGED:\n",
      "   Before Hook: ' high' (prob: 0.107910)\n",
      "   After Hook:  ' the' (prob: 0.097168)\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' famous' (prob: 0.021729)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' restaurants' (prob: 0.024048)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.036621\n",
      "   Average absolute change per token: 0.003662\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "💾 Memory cleanup completed after 95 files\n",
      "\n",
      "==================== Processing File 96/98 ====================\n",
      "File: location_sentence_97.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The secret research facility is hidden beneath ordinary-looking buildings in'\n",
      "File: location_sentence_97.json\n",
      "Vector: count_increase at Layer 5 res\n",
      "Vector norm: 7.4902\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 5 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.273438     ' the'                    0.269531     ↓ -0.003906\n",
      "2    ' a'                      0.128906     ' a'                      0.144531     ↑ +0.015625\n",
      "3    ' downtown'               0.044678     ' downtown'               0.056641     ↑ +0.011963\n",
      "4    ' cities'                 0.023926     ' Washington'             0.020874     ↓ -0.003052\n",
      "5    ' various'                0.022461     ' an'                     0.019531     ↓ -0.002930\n",
      "6    ' major'                  0.019775     ' several'                0.018433     ↓ -0.001343\n",
      "7    ' Washington'             0.019775     ' various'                0.018433     ↓ -0.001343\n",
      "8    ' an'                     0.018677     ' cities'                 0.017212     ↓ -0.001465\n",
      "9    ' New'                    0.017456     ' major'                  0.015259     ↓ -0.002197\n",
      "10   ' several'                0.017456     ' New'                    0.014282     ↓ -0.003174\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.003906\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.046997\n",
      "   Average absolute change per token: 0.004700\n",
      "   New tokens in top-10: 0\n",
      "   Lost tokens from top-10: 0\n",
      "\n",
      "==================== Processing File 97/98 ====================\n",
      "File: location_sentence_98.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'We're routing the pipeline through the least populated areas of'\n",
      "File: location_sentence_98.json\n",
      "Vector: count_increase at Layer 12 res\n",
      "Vector norm: 12.0198\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 12 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.625000     ' the'                    0.644531     ↑ +0.019531\n",
      "2    ' our'                    0.042480     ' our'                    0.023560     ↓ -0.018921\n",
      "3    ' North'                  0.018799     ' North'                  0.010437     ↓ -0.008362\n",
      "4    ' Texas'                  0.010071     ' Alaska'                 0.009827     ↓ -0.000244\n",
      "5    ' New'                    0.009460     ' New'                    0.008667     ↓ -0.000793\n",
      "6    ' rural'                  0.007385     ' South'                  0.006744     ↓ -0.000641\n",
      "7    ' South'                  0.006531     ' Canada'                 0.005249     ↓ -0.001282\n",
      "8    ' Alaska'                 0.006134     ' Montana'                0.005249     ↓ -0.000885\n",
      "9    ' West'                   0.006134     ' rural'                  0.005249     ↓ -0.000885\n",
      "10   ' Pennsylvania'           0.005066     ' Texas'                  0.004639     ↓ -0.000427\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: +0.019531\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 7: ' Canada' (prob: 0.005249)\n",
      "   Rank 8: ' Montana' (prob: 0.005249)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 9: ' West' (prob: 0.006134)\n",
      "   Was rank 10: ' Pennsylvania' (prob: 0.005066)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.051971\n",
      "   Average absolute change per token: 0.005197\n",
      "   New tokens in top-10: 2\n",
      "   Lost tokens from top-10: 2\n",
      "\n",
      "==================== Processing File 98/98 ====================\n",
      "File: location_sentence_99.json\n",
      "\n",
      "================================================================================\n",
      "Analyzing sentence: 'The assassination plot targeted political figures gathering in'\n",
      "File: location_sentence_99.json\n",
      "Vector: count_increase at Layer 3 res\n",
      "Vector norm: 1.4951\n",
      "Applied scaling: 1.0 * 0.25 = 0.25\n",
      "================================================================================\n",
      "  Registered hook at Layer 3 res\n",
      "\n",
      "TOP-10 TOKEN COMPARISON:\n",
      "Rank Before Hook               Prob         After Hook                Prob         Change    \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    ' the'                    0.236328     ' the'                    0.217773     ↓ -0.018555\n",
      "2    ' a'                      0.081543     ' a'                      0.075195     ↓ -0.006348\n",
      "3    ' Paris'                  0.014221     ' Paris'                  0.013916     ↓ -0.000305\n",
      "4    ' Parliament'             0.009766     ' Washington'             0.013062     ↑ +0.003296\n",
      "5    ' Istanbul'               0.009155     ' downtown'               0.010193     ↑ +0.001038\n",
      "6    ' Washington'             0.009155     ' Oslo'                   0.009521     ↑ +0.000366\n",
      "7    ' an'                     0.008606     ' Parliament'             0.009521     ↑ +0.000916\n",
      "8    ' downtown'               0.008606     ' an'                     0.008423     ↓ -0.000183\n",
      "9    ' Oslo'                   0.008118     ' Istanbul'               0.008423     ↑ +0.000305\n",
      "10   ' front'                  0.007599     ' New'                    0.006989     ↓ -0.000610\n",
      "\n",
      "CHANGE ANALYSIS:\n",
      "----------------------------------------\n",
      "✅ TOP TOKEN UNCHANGED: ' the'\n",
      "   Probability change: -0.018555\n",
      "\n",
      "📈 NEW TOKENS IN TOP-10:\n",
      "   Rank 10: ' New' (prob: 0.006989)\n",
      "\n",
      "📉 TOKENS DROPPED FROM TOP-10:\n",
      "   Was rank 10: ' front' (prob: 0.007599)\n",
      "\n",
      "📊 OVERALL DISTRIBUTION METRICS:\n",
      "   Total absolute probability change in top-10: 0.031921\n",
      "   Average absolute change per token: 0.003192\n",
      "   New tokens in top-10: 1\n",
      "   Lost tokens from top-10: 1\n",
      "\n",
      "====================================================================================================\n",
      "FINAL PROCESSING SUMMARY\n",
      "====================================================================================================\n",
      "Total files found: 98\n",
      "Successfully processed: 98\n",
      "Errors encountered: 0\n",
      "Processing success rate: 100.0%\n",
      "\n",
      "OVERALL ANALYSIS STATISTICS:\n",
      "  Files with top token changes: 10 / 98 (10.2%)\n",
      "  Average total probability change: 0.080284\n",
      "  Average new tokens in top-10: 1.46\n",
      "  Average lost tokens from top-10: 1.46\n",
      "\n",
      "TOP 5 FILES WITH MOST SIGNIFICANT TOKEN CHANGES:\n",
      "1. location_sentence_37.json\n",
      "   Total prob change: 0.576813\n",
      "   Top token changed: No\n",
      "   New/Lost tokens: +5/-5\n",
      "2. location_sentence_18.json\n",
      "   Total prob change: 0.377380\n",
      "   Top token changed: Yes\n",
      "   New/Lost tokens: +7/-7\n",
      "3. location_sentence_10.json\n",
      "   Total prob change: 0.299957\n",
      "   Top token changed: No\n",
      "   New/Lost tokens: +5/-5\n",
      "4. location_sentence_36.json\n",
      "   Total prob change: 0.293182\n",
      "   Top token changed: No\n",
      "   New/Lost tokens: +2/-2\n",
      "5. location_sentence_16.json\n",
      "   Total prob change: 0.278839\n",
      "   Top token changed: No\n",
      "   New/Lost tokens: +1/-1\n",
      "\n",
      "✅ Analysis completed! Check the detailed output above for individual file results.\n"
     ]
    }
   ],
   "source": [
    "## Analyze individual file results - top token changes for each sentence\n",
    "import glob\n",
    "\n",
    "# Process all location result files\n",
    "results_dir = \"./results/results_location\"\n",
    "print(f\"Looking for location result files in: {results_dir}\")\n",
    "\n",
    "# Find all location sentence JSON files\n",
    "pattern = os.path.join(results_dir, \"location_sentence_*.json\")\n",
    "all_files = glob.glob(pattern)\n",
    "\n",
    "print(f\"Found {len(all_files)} location result files\")\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(\"❌ No location result files found!\")\n",
    "else:\n",
    "    # Sort files for consistent processing order\n",
    "    all_files.sort()\n",
    "    \n",
    "    # Limit processing for demonstration (remove this line to process all files)\n",
    "    # all_files = all_files[:20]  # Process only first 20 files for testing\n",
    "    \n",
    "    # Process each file\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    analysis_results = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ANALYZING TOP TOKEN CHANGES FOR EACH LOCATION SENTENCE\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    for i, file_path in enumerate(all_files):\n",
    "        print(f\"\\n{'='*20} Processing File {i+1}/{len(all_files)} {'='*20}\")\n",
    "        print(f\"File: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Try to load count_increase vector first\n",
    "            vector_info = load_specific_interference_vector(file_path, vector_type='count_increase')\n",
    "            \n",
    "            if vector_info is None:\n",
    "                # Try prob_increase if count_increase failed\n",
    "                vector_info = load_specific_interference_vector(file_path, vector_type='prob_increase')\n",
    "            \n",
    "            if vector_info is None:\n",
    "                print(f\"❌ Could not load valid vector from {os.path.basename(file_path)}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Get the sentence\n",
    "            sentence = vector_info['sentence']\n",
    "            \n",
    "            if not sentence or sentence == 'Unknown sentence':\n",
    "                print(f\"❌ No valid sentence found in {os.path.basename(file_path)}\")\n",
    "                error_count += 1\n",
    "                continue\n",
    "            \n",
    "            # Analyze this sentence with the interference vector\n",
    "            result = compare_top_tokens_before_after(llama, tokenizer, sentence, vector_info, top_k=10)\n",
    "            \n",
    "            if result:\n",
    "                analysis_results.append({\n",
    "                    'file_name': vector_info['file_name'],\n",
    "                    'sentence': sentence,\n",
    "                    'vector_info': vector_info,\n",
    "                    'analysis_result': result\n",
    "                })\n",
    "            \n",
    "            processed_count += 1\n",
    "            \n",
    "            # Clean up memory periodically\n",
    "            if (i + 1) % 5 == 0:\n",
    "                clean_up_memory()\n",
    "                print(f\"\\n💾 Memory cleanup completed after {i+1} files\")\n",
    "            \n",
    "            # Optional: Add a small delay to prevent overwhelming output\n",
    "            # import time\n",
    "            # time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {os.path.basename(file_path)}: {e}\")\n",
    "            error_count += 1\n",
    "            continue\n",
    "    \n",
    "    # Final summary statistics\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"FINAL PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Total files found: {len(all_files)}\")\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Errors encountered: {error_count}\")\n",
    "    print(f\"Processing success rate: {processed_count/(len(all_files))*100:.1f}%\")\n",
    "    \n",
    "    if analysis_results:\n",
    "        # Calculate summary statistics across all processed files\n",
    "        top_token_changes = sum(1 for r in analysis_results if r['analysis_result']['top_token_changed'])\n",
    "        avg_prob_change = np.mean([r['analysis_result']['total_prob_change'] for r in analysis_results])\n",
    "        avg_new_tokens = np.mean([r['analysis_result']['new_tokens'] for r in analysis_results])\n",
    "        avg_lost_tokens = np.mean([r['analysis_result']['lost_tokens'] for r in analysis_results])\n",
    "        \n",
    "        print(f\"\\nOVERALL ANALYSIS STATISTICS:\")\n",
    "        print(f\"  Files with top token changes: {top_token_changes} / {len(analysis_results)} ({top_token_changes/len(analysis_results)*100:.1f}%)\")\n",
    "        print(f\"  Average total probability change: {avg_prob_change:.6f}\")\n",
    "        print(f\"  Average new tokens in top-10: {avg_new_tokens:.2f}\")\n",
    "        print(f\"  Average lost tokens from top-10: {avg_lost_tokens:.2f}\")\n",
    "        \n",
    "        # Find files with the most significant changes\n",
    "        sorted_by_change = sorted(analysis_results, key=lambda x: x['analysis_result']['total_prob_change'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTOP 5 FILES WITH MOST SIGNIFICANT TOKEN CHANGES:\")\n",
    "        for i, item in enumerate(sorted_by_change[:5]):\n",
    "            result = item['analysis_result']\n",
    "            print(f\"{i+1}. {item['file_name']}\")\n",
    "            print(f\"   Total prob change: {result['total_prob_change']:.6f}\")\n",
    "            print(f\"   Top token changed: {'Yes' if result['top_token_changed'] else 'No'}\")\n",
    "            print(f\"   New/Lost tokens: +{result['new_tokens']}/-{result['lost_tokens']}\")\n",
    "    \n",
    "    # Final memory cleanup\n",
    "    clean_up_memory()\n",
    "    \n",
    "    print(f\"\\n✅ Analysis completed! Check the detailed output above for individual file results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8b8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp-arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
