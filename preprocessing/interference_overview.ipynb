{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "from utils.utils_data import *\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def cosine_similarity_matrix(X, Y):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity matrix between two tensor matrices\n",
    "    X: [n, d], Y: [m, d]\n",
    "    Returns: [n, m]\n",
    "    \"\"\"\n",
    "    X_norm = torch.nn.functional.normalize(X, p=2, dim=1)\n",
    "    Y_norm = torch.nn.functional.normalize(Y, p=2, dim=1)\n",
    "    return torch.mm(X_norm, Y_norm.t())\n",
    "\n",
    "def create_range_masks(decoder_sim_matrix, similarity_ranges):\n",
    "    \"\"\"\n",
    "    Create mask matrices for all similarity ranges\n",
    "    \"\"\"\n",
    "    range_masks = {}\n",
    "    for range_min, range_max in similarity_ranges:\n",
    "        if range_max == 1.0:\n",
    "            range_mask = (decoder_sim_matrix >= range_min) & (decoder_sim_matrix <= range_max)\n",
    "        else:\n",
    "            range_mask = (decoder_sim_matrix >= range_min) & (decoder_sim_matrix < range_max)\n",
    "        \n",
    "        # Exclude diagonal elements\n",
    "        range_mask.fill_diagonal_(False)\n",
    "        range_masks[f\"{range_min:.1f}-{range_max:.1f}\"] = range_mask\n",
    "    \n",
    "    return range_masks\n",
    "\n",
    "def extract_interference_features_on_cpu(combined_masks_cpu, qualified_feature_positions_cpu, \n",
    "                                        range_keys, valid_indices, feature_explanations):\n",
    "    \"\"\"\n",
    "    Extract interference features on CPU for fast processing\n",
    "    \"\"\"\n",
    "    qualified_features = {}\n",
    "    \n",
    "    if len(qualified_feature_positions_cpu) == 0:\n",
    "        return qualified_features\n",
    "    \n",
    "    print(f\"    Moving data to CPU for feature ID extraction...\")\n",
    "    \n",
    "    # Process each qualifying feature on CPU\n",
    "    for pos in tqdm(qualified_feature_positions_cpu, desc=\"Extracting interference features\"):\n",
    "        feature_idx = valid_indices[pos]\n",
    "        feature_interference = {}\n",
    "        \n",
    "        # Find interference features for each range\n",
    "        for range_idx, range_key in enumerate(range_keys):\n",
    "            # Get interference mask for this feature in this range\n",
    "            interference_mask = combined_masks_cpu[range_idx, pos]\n",
    "            interference_positions = np.nonzero(interference_mask)[0]\n",
    "            \n",
    "            # Convert to feature IDs\n",
    "            interference_feature_ids = [valid_indices[p] for p in interference_positions]\n",
    "            feature_interference[range_key] = interference_feature_ids\n",
    "        \n",
    "        qualified_features[feature_idx] = {\n",
    "            'explanation': feature_explanations[feature_idx],\n",
    "            'interference_features': feature_interference\n",
    "        }\n",
    "    \n",
    "    return qualified_features\n",
    "\n",
    "def fully_vectorized_interference_analysis(decoder_sim_matrix, explanation_sim_matrix, \n",
    "                                         semantic_thresholds, similarity_ranges, \n",
    "                                         valid_indices, feature_explanations, device):\n",
    "    \"\"\"\n",
    "    Fully vectorized interference feature analysis (GPU filtering + CPU extraction)\n",
    "    \"\"\"\n",
    "    print(f\"    Starting GPU vectorized filtering...\")\n",
    "    n_features = decoder_sim_matrix.shape[0]\n",
    "    \n",
    "    # 1. Create all range masks (bool type)\n",
    "    range_masks = create_range_masks(decoder_sim_matrix, similarity_ranges)\n",
    "    range_keys = list(range_masks.keys())\n",
    "    \n",
    "    # 2. Stack all range masks into 3D tensor [n_ranges, n_features, n_features]\n",
    "    range_masks_tensor = torch.stack([range_masks[key] for key in range_keys])\n",
    "    \n",
    "    # Release range_masks dictionary\n",
    "    del range_masks\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"    Range mask tensor shape: {range_masks_tensor.shape}\")\n",
    "    \n",
    "    # 3. Process each threshold in batch\n",
    "    results_by_threshold = {}\n",
    "    \n",
    "    for threshold in semantic_thresholds:\n",
    "        print(f\"    Processing threshold {threshold} on GPU...\")\n",
    "        \n",
    "        # Create semantic mask matrix [n_features, n_features] - keep bool type\n",
    "        semantic_mask = (explanation_sim_matrix < threshold)\n",
    "        semantic_mask.fill_diagonal_(False)  # Exclude self\n",
    "        \n",
    "        # 4. Calculate combined masks in batch [n_ranges, n_features, n_features]\n",
    "        # Use bool AND operation: [n_ranges, n_features, n_features] & [1, n_features, n_features]\n",
    "        combined_masks = range_masks_tensor & semantic_mask.unsqueeze(0)\n",
    "        \n",
    "        # 5. Check if each feature has interference features in each range\n",
    "        # For each range, check if each row (each feature) has any interference features\n",
    "        has_interference_per_range = combined_masks.any(dim=2)  # [n_ranges, n_features]\n",
    "        \n",
    "        # 6. Find features that have interference features in all ranges\n",
    "        # Check if each feature has at least one interference feature in all ranges\n",
    "        has_interference_all_ranges = has_interference_per_range.all(dim=0)  # [n_features]\n",
    "        \n",
    "        # 7. Get indices of qualifying features\n",
    "        qualified_feature_positions = torch.nonzero(has_interference_all_ranges, as_tuple=True)[0]\n",
    "        \n",
    "        print(f\"    GPU filtering complete, found {len(qualified_feature_positions)} qualifying features\")\n",
    "        \n",
    "        # 8. Move data to CPU for feature ID extraction\n",
    "        if len(qualified_feature_positions) > 0:\n",
    "            # Move GPU data to CPU\n",
    "            combined_masks_cpu = combined_masks.cpu().numpy()\n",
    "            qualified_feature_positions_cpu = qualified_feature_positions.cpu().numpy()\n",
    "            \n",
    "            # Extract specific interference feature IDs on CPU\n",
    "            qualified_features = extract_interference_features_on_cpu(\n",
    "                combined_masks_cpu, qualified_feature_positions_cpu, \n",
    "                range_keys, valid_indices, feature_explanations\n",
    "            )\n",
    "        else:\n",
    "            qualified_features = {}\n",
    "        \n",
    "        results_by_threshold[threshold] = qualified_features\n",
    "        print(f\"    Threshold {threshold}: final confirmed {len(qualified_features)} features\")\n",
    "        \n",
    "        # Clean up temporary data for current threshold\n",
    "        del semantic_mask, combined_masks, has_interference_per_range, has_interference_all_ranges\n",
    "        del qualified_feature_positions\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Clean up range-related data\n",
    "    del range_masks_tensor\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return results_by_threshold\n",
    "\n",
    "def save_single_file(model_name, layer_type, layer_idx, threshold, features, output_dir=\"./interference_results\"):\n",
    "    \"\"\"\n",
    "    Save single file: model_layertype_layeridx_threshold.json\n",
    "    \"\"\"\n",
    "    if len(features) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Convert feature data format\n",
    "    cleaned_features = {}\n",
    "    for feature_id, feature_data in features.items():\n",
    "        cleaned_features[str(feature_id)] = {\n",
    "            'explanation': feature_data['explanation'],\n",
    "            'interference_features': feature_data['interference_features']\n",
    "        }\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = f\"{model_name}_{layer_type}_{layer_idx}_{threshold:.2f}.json\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    \n",
    "    # Save file\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cleaned_features, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"    Saved file: {filename} ({len(features)} features)\")\n",
    "    return filename\n",
    "\n",
    "def analyze_model_interference(model_name, layer_types, num_layers, \n",
    "                              similarity_ranges=None, semantic_thresholds=None,\n",
    "                              output_dir=\"./interference_results\"):\n",
    "    \"\"\"\n",
    "    Analyze interference features for a given model\n",
    "    \n",
    "    Args:\n",
    "        model_name: 'pythia' or 'gpt2'\n",
    "        layer_types: list of layer types to analyze\n",
    "        num_layers: number of layers in the model\n",
    "        similarity_ranges: list of (min, max) tuples for similarity ranges\n",
    "        semantic_thresholds: list of semantic similarity thresholds\n",
    "        output_dir: directory to save results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Default parameters if not provided\n",
    "    if similarity_ranges is None:\n",
    "        similarity_ranges = [\n",
    "            (0.0, 0.1),\n",
    "            (0.1, 0.2), \n",
    "            (0.2, 0.3),\n",
    "            (0.3, 0.4),\n",
    "            (0.4, 1.0)\n",
    "        ]\n",
    "    \n",
    "    if semantic_thresholds is None:\n",
    "        semantic_thresholds = [0.4, 0.3, 0.2, 0.15, 0.1]\n",
    "    \n",
    "    print(f\"Starting interference feature analysis for {model_name.upper()} model\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Layer types: {layer_types}\")\n",
    "    print(f\"Number of layers: {num_layers} (0-{num_layers-1})\")\n",
    "    print(f\"Similarity ranges: {similarity_ranges}\")\n",
    "    print(f\"Semantic thresholds: {semantic_thresholds}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    # Record all saved files\n",
    "    saved_files = []\n",
    "    \n",
    "    # Process each layer\n",
    "    for layer_idx in range(num_layers):\n",
    "        print(f\"\\nProcessing layer {layer_idx}...\")\n",
    "        \n",
    "        # Process each layer type\n",
    "        for layer_type in layer_types:\n",
    "            print(f\"  Processing {layer_type} type...\")\n",
    "            \n",
    "            try:\n",
    "                # Clear GPU memory\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "                # 1. Get all necessary data\n",
    "                print(f\"    Loading data...\")\n",
    "                active_features = get_sae_features_by_layer(model_name, layer_type, layer_idx, active_only=True)\n",
    "                if not active_features:\n",
    "                    print(f\"    No active features found\")\n",
    "                    continue\n",
    "                \n",
    "                decoder_weights = get_sae_decoder_weights_from_local(model_name, layer_type, layer_idx)\n",
    "                explanation_embeddings_dict = get_feature_explanation_embeddings_by_layer(model_name, layer_type, layer_idx)\n",
    "                feature_explanations = get_feature_explanations_by_layer(model_name, layer_type, layer_idx)\n",
    "                \n",
    "                # 2. Filter features with complete information\n",
    "                valid_indices = [\n",
    "                    idx for idx in active_features.keys()\n",
    "                    if idx in explanation_embeddings_dict and idx in feature_explanations\n",
    "                ]\n",
    "                \n",
    "                if not valid_indices:\n",
    "                    print(f\"    No features with complete information found\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"    Valid features count: {len(valid_indices)}\")\n",
    "                \n",
    "                # 3. Build matrices (on GPU, using float32)\n",
    "                print(f\"    Building weight matrices (float32)...\")\n",
    "                valid_decoder_weights = decoder_weights[valid_indices].to(device).float()\n",
    "                explanation_embeddings_list = [explanation_embeddings_dict[idx] for idx in valid_indices]\n",
    "                explanation_embeddings = torch.stack(explanation_embeddings_list).to(device).float()\n",
    "                \n",
    "                # Release original data immediately\n",
    "                del decoder_weights\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                # 4. Calculate similarity matrices (on GPU, float32)\n",
    "                print(f\"    Computing similarity matrices (float32)...\")\n",
    "                decoder_sim_matrix = cosine_similarity_matrix(valid_decoder_weights, valid_decoder_weights)\n",
    "                explanation_sim_matrix = cosine_similarity_matrix(explanation_embeddings, explanation_embeddings)\n",
    "                \n",
    "                # Release weight matrices immediately\n",
    "                del valid_decoder_weights, explanation_embeddings\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                print(f\"    Matrix size: {decoder_sim_matrix.shape}, data type: {decoder_sim_matrix.dtype}\")\n",
    "                \n",
    "                # 5. GPU filtering + CPU extraction\n",
    "                threshold_results = fully_vectorized_interference_analysis(\n",
    "                    decoder_sim_matrix, explanation_sim_matrix, semantic_thresholds, \n",
    "                    similarity_ranges, valid_indices, feature_explanations, device\n",
    "                )\n",
    "                \n",
    "                # 6. Save results for each threshold and clean up memory\n",
    "                for threshold in semantic_thresholds:\n",
    "                    features = threshold_results[threshold]\n",
    "                    if len(features) > 0:\n",
    "                        filename = save_single_file(model_name, layer_type, layer_idx, threshold, features, output_dir)\n",
    "                        if filename:\n",
    "                            saved_files.append(filename)\n",
    "                    \n",
    "                    # Clean up results for this threshold\n",
    "                    del threshold_results[threshold]\n",
    "                \n",
    "                # Clean up all data\n",
    "                del threshold_results\n",
    "                del decoder_sim_matrix, explanation_sim_matrix\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing layer {layer_idx} {layer_type}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                \n",
    "                # Clean up GPU memory on error\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "                continue\n",
    "        \n",
    "        # Memory cleanup after each layer\n",
    "        print(f\"\\n  Layer {layer_idx} processing complete, cleaning memory...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Display final results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Analysis complete! File statistics:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Collect file statistics\n",
    "    file_stats = {}\n",
    "    total_features = 0\n",
    "    \n",
    "    for filename in saved_files:\n",
    "        try:\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            feature_count = len(data)\n",
    "            total_features += feature_count\n",
    "            \n",
    "            # Parse filename to get information\n",
    "            parts = filename.replace('.json', '').split('_')\n",
    "            threshold = parts[-1]\n",
    "            \n",
    "            if threshold not in file_stats:\n",
    "                file_stats[threshold] = []\n",
    "            \n",
    "            file_stats[threshold].append((filename, feature_count))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {filename}: {e}\")\n",
    "    \n",
    "    # Display statistics by threshold\n",
    "    for threshold in sorted(file_stats.keys()):\n",
    "        print(f\"\\nThreshold {threshold}:\")\n",
    "        threshold_total = 0\n",
    "        for filename, count in file_stats[threshold]:\n",
    "            print(f\"  {filename}: {count} features\")\n",
    "            threshold_total += count\n",
    "        print(f\"  Subtotal: {threshold_total} features\")\n",
    "    \n",
    "    print(f\"\\nTotal summary:\")\n",
    "    print(f\"  Number of files: {len(saved_files)}\")\n",
    "    print(f\"  Total features: {total_features}\")\n",
    "    \n",
    "    return saved_files, file_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_model_interference(\n",
    "    model_name='pythia',\n",
    "    layer_types=['att', 'mlp', 'res'],\n",
    "    num_layers=6,\n",
    "    semantic_thresholds=[0.4, 0.3, 0.2, 0.15],\n",
    "    output_dir=\"./interference_results/pythia\"\n",
    ")\n",
    "\n",
    "analyze_model_interference(\n",
    "    model_name='gpt2',\n",
    "    layer_types=['att', 'res_mid', 'mlp', 'res_post'],\n",
    "    num_layers=12,\n",
    "    semantic_thresholds=[0.4, 0.3, 0.2, 0.15],\n",
    "    output_dir=\"./interference_results/gpt2\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp-arena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
